Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.34 at 0x103017950>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.core.vector_memory'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Vector Memory Manager - High-level memory management for creative writing

Provides intelligent context retrieval and memory organization for long-form
novel writing with support for:
- Recent context (last N tasks)
- Semantic search (vector similarity)
- Chapter-scoped memory
- Task-specific memory
"""

import asyncio
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List, Optional, Set
from collections import deque

from loguru import logger

from creative_autogpt.storage.vector_store import (
    VectorStore,
    VectorMemoryItem,
    MemoryType,
    SearchResult,
)


@dataclass
class MemoryContext:
    """Context information for a task"""

    task_id: str
    task_type: str
    recent_results: List[Dict[str, Any]] = field(default_factory=list)
    relevant_memories: List[Dict[str, Any]] = field(default_factory=list)
    chapter_context: List[Dict[str, Any]] = field(default_factory=list)
    task_memories: List[Dict[str, Any]] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "task_type": self.task_type,
            "recent_results": self.recent_results,
            "relevant_memories": self.relevant_memories,
            "chapter_context": self.chapter_context,
            "task_memories": self.task_memories,
        }


@dataclass
class TaskResult:
    """Result of a completed task"""

    task_id: str
    task_type: str
    content: str
    memory_type: MemoryType
    metadata: Dict[str, Any] = field(default_factory=dict)
    chapter_index: Optional[int] = None
    created_at: datetime = field(default_factory=datetime.utcnow)
    evaluation: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "task_type": self.task_type,
            "content": self.content,
            "memory_type": self.memory_type.value,
            "metadata": self.metadata,
            "chapter_index": self.chapter_index,
            "created_at": self.created_at.isoformat(),
            "evaluation": self.evaluation,
        }


class VectorMemoryManager:
    """
    High-level memory manager for creative writing

    Manages:
    - Short-term memory (recent task results)
    - Long-term memory (vector-based semantic storage)
    - Context retrieval for tasks
    - Chapter-scoped memory
    """

    def __init__(
        self,
        vector_store: Optional[VectorStore] = None,
        short_term_size: int = 10,
    ):
        """
        Initialize memory manager

        Args:
            vector_store: VectorStore instance (created if None)
            short_term_size: Number of recent results to keep in memory
        """
        self.vector_store = vector_store or VectorStore()
        self.short_term_size = short_term_size

        # Short-term memory (deque for efficient pops)
        self._short_term: deque = deque(maxlen=short_term_size)

        # Task results cache (task_id -> TaskResult)
        self._task_results: Dict[str, TaskResult] = {}

        # Current chapter index
        self._current_chapter: Optional[int] = None

        logger.info(
            f"VectorMemoryManager initialized (short_term_size={short_term_size})"
        )

    async def store(
        self,
        content: str,
        task_id: str,
        task_type: str,
        memory_type: MemoryType = MemoryType.GENERAL,
        metadata: Optional[Dict[str, Any]] = None,
        chapter_index: Optional[int] = None,
        evaluation: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Store a result in both short-term and long-term memory

        Args:
            content: The content to store
            task_id: Associated task ID
            task_type: Type of task
            memory_type: Type of memory
            metadata: Additional metadata
            chapter_index: Associated chapter index
            evaluation: Evaluation results

        Returns:
            The ID of the stored item
        """
        # Create task result
        result = TaskResult(
            task_id=task_id,
            task_type=task_type,
            content=content,
            memory_type=memory_type,
            metadata=metadata or {},
            chapter_index=chapter_index,
            evaluation=evaluation,
        )

        # Store in short-term memory
        self._short_term.append(result)
        self._task_results[task_id] = result

        # Store in vector store
        vector_metadata = {
            "task_type": task_type,
            **metadata,
        }

        if evaluation:
            import json
            vector_metadata["evaluation"] = json.dumps(evaluation, ensure_ascii=False)

        item_id = await self.vector_store.add(
            content=content,
            memory_type=memory_type,
            metadata=vector_metadata,
            task_id=task_id,
            chapter_index=chapter_index,
        )

        logger.debug(
            f"Stored result for task {task_id} (type: {task_type}, "
            f"memory_type: {memory_type.value})"
        )

        return item_id

    async def get_context(
        self,
        task_id: str,
        task_type: str,
        query: Optional[str] = None,
        chapter_index: Optional[int] = None,
        top_k: int = 5,
        recent_count: int = 3,
        include_chapter_context: bool = True,
    ) -> MemoryContext:
        """
        Get context for a task from memory

        Args:
            task_id: The task ID
            task_type: Type of task
            query: Search query for relevant memories (uses task_type if None)
            chapter_index: Chapter index for scoped context
            top_k: Number of relevant memories to retrieve
            recent_count: Number of recent results to include
            include_chapter_context: Whether to include chapter-scoped context

        Returns:
            MemoryContext with all relevant information
        """
        context = MemoryContext(task_id=task_id, task_type=task_type)

        # 1. Recent results from short-term memory
        recent = list(self._short_term)[-recent_count:]
        context.recent_results = [r.to_dict() for r in recent if r.task_id != task_id]

        # 2. Semantically relevant memories
        search_query = query or task_type
        relevant_results = await self.vector_store.search(
            query=search_query,
            top_k=top_k,
            chapter_index=chapter_index if include_chapter_context else None,
        )
        context.relevant_memories = [
            {
                "content": r.item.content,
                "memory_type": r.item.memory_type.value,
                "score": r.score,
                "task_id": r.item.task_id,
            }
            for r in relevant_results
            if r.item.task_id != task_id
        ]

        # 3. Chapter-specific context
        if include_chapter_context and chapter_index is not None:
            chapter_results = await self.vector_store.search(
                query=search_query,
                top_k=3,
                chapter_index=chapter_index,
            )
            context.chapter_context = [
                {
                    "content": r.item.content,
                    "memory_type": r.item.memory_type.value,
                    "score": r.score,
                }
                for r in chapter_results
            ]

        # 4. Task-specific memories (if this is a retry)
        if task_id in self._task_results:
            context.task_memories = [self._task_results[task_id].to_dict()]

        logger.debug(
            f"Retrieved context for task {task_id}: "
            f"{len(context.recent_results)} recent, "
            f"{len(context.relevant_memories)} relevant, "
            f"{len(context.chapter_context)} chapter"
        )

        return context

    async def get_task_result(self, task_id: str) -> Optional[TaskResult]:
        """
        Get a stored task result

        Args:
            task_id: The task ID

        Returns:
            TaskResult if found, None otherwise
        """
        return self._task_results.get(task_id)

    async def get_recent_results(
        self,
        limit: Optional[int] = None,
    ) -> List[TaskResult]:
        """
        Get recent task results

        Args:
            limit: Maximum number to return (all if None)

        Returns:
            List of recent results
        """
        results = list(reversed(self._short_term))
        if limit:
            return results[:limit]
        return results

    async def search(
        self,
        query: str,
        top_k: int = 5,
        memory_type: Optional[MemoryType] = None,
        chapter_index: Optional[int] = None,
    ) -> List[SearchResult]:
        """
        Search vector memory

        Args:
            query: Search query
            top_k: Number of results
            memory_type: Filter by memory type
            chapter_index: Filter by chapter

        Returns:
            List of search results
        """
        return await self.vector_store.search(
            query=query,
            top_k=top_k,
            memory_type=memory_type,
            chapter_index=chapter_index,
        )

    async def get_by_memory_type(
        self,
        memory_type: MemoryType,
        limit: int = 20,
    ) -> List[VectorMemoryItem]:
        """
        Get all memories of a specific type

        Args:
            memory_type: The memory type
            limit: Maximum number to return

        Returns:
            List of memory items
        """
        results = await self.vector_store.search(
            query="",  # Empty query to get all
            top_k=limit,
            memory_type=memory_type,
        )
        return [r.item for r in results]

    async def get_chapter_memories(
        self,
        chapter_index: int,
        memory_type: Optional[MemoryType] = None,
    ) -> List[VectorMemoryItem]:
        """
        Get all memories for a specific chapter

        Args:
            chapter_index: The chapter index
            memory_type: Optional filter by memory type

        Returns:
            List of memory items
        """
        results = await self.vector_store.search(
            query="",
            top_k=100,
            chapter_index=chapter_index,
            memory_type=memory_type,
        )
        return [r.item for r in results]

    async def update_task_result(
        self,
        task_id: str,
        content: Optional[str] = None,
        evaluation: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        Update an existing task result

        Args:
            task_id: The task ID
            content: New content (optional)
            evaluation: New evaluation (optional)

        Returns:
            True if successful
        """
        if task_id not in self._task_results:
            return False

        result = self._task_results[task_id]

        if content:
            result.content = content

        if evaluation:
            result.evaluation = evaluation

        # Update in vector store
        await self.vector_store.update(
            item_id=task_id,
            content=content,
            metadata={"evaluation": evaluation} if evaluation else None,
        )

        return True

    async def delete_task(self, task_id: str) -> bool:
        """
        Delete all memories associated with a task

        Args:
            task_id: The task ID

        Returns:
            True if successful
        """
        # Remove from short-term memory
        self._short_term = deque(
            [r for r in self._short_term if r.task_id != task_id],
            maxlen=self.short_term_size,
        )

        # Remove from cache
        self._task_results.pop(task_id, None)

        # Remove from vector store
        count = await self.vector_store.delete_by_task(task_id)

        logger.info(f"Deleted task {task_id} and {count} associated memories")
        return True

    async def clear_short_term(self) -> None:
        """Clear short-term memory"""
        self._short_term.clear()
        logger.info("Cleared short-term memory")

    async def clear_all(self) -> bool:
        """
        Clear all memory (both short-term and long-term)

        Returns:
            True if successful
        """
        self._short_term.clear()
        self._task_results.clear()
        return await self.vector_store.clear()

    def get_stats(self) -> Dict[str, Any]:
        """Get memory statistics"""
        return {
            "short_term_size": len(self._short_term),
            "short_term_max": self.short_term_size,
            "cached_results": len(self._task_results),
            "vector_store_count": self.vector_store.count(),
            "current_chapter": self._current_chapter,
        }

    def set_current_chapter(self, chapter_index: int) -> None:
        """Set the current chapter index"""
        self._current_chapter = chapter_index
        logger.debug(f"Set current chapter to {chapter_index}")

    def get_current_chapter(self) -> Optional[int]:
        """Get the current chapter index"""
        return self._current_chapter

    async def get_character_memories(self) -> List[VectorMemoryItem]:
        """Get all character-related memories"""
        return await self.get_by_memory_type(MemoryType.CHARACTER)

    async def get_plot_memories(self) -> List[VectorMemoryItem]:
        """Get all plot-related memories"""
        return await self.get_by_memory_type(MemoryType.PLOT)

    async def get_worldview_memories(self) -> List[VectorMemoryItem]:
        """Get all worldview-related memories"""
        return await self.get_by_memory_type(MemoryType.WORLDVIEW)

    async def get_foreshadow_memories(self) -> List[VectorMemoryItem]:
        """Get all foreshadow-related memories"""
        return await self.get_by_memory_type(MemoryType.FORESHADOW)

    async def export_memories(
        self,
        chapter_index: Optional[int] = None,
        memory_types: Optional[List[MemoryType]] = None,
    ) -> List[Dict[str, Any]]:
        """
        Export memories in a structured format

        Args:
            chapter_index: Filter by chapter (None for all)
            memory_types: Filter by memory types (None for all)

        Returns:
            List of exported memory dictionaries
        """
        exports = []

        # Get all recent results
        for result in self._task_results.values():
            if chapter_index is not None and result.chapter_index != chapter_index:
                continue
            if memory_types and result.memory_type not in memory_types:
                continue

            exports.append(result.to_dict())

        return exports

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.34 at 0x103017950>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.core.vector_memory'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.25 at 0x1037a5c70>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.core.prompt_evolver'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Prompt Evolver - 提示词自我迭代进化系统

根据评估结果自动优化提示词，实现自我学习和改进。
"""

import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from loguru import logger


@dataclass
class PromptVersion:
    """提示词版本"""
    task_type: str
    version: int
    prompt_template: str
    avg_score: float
    usage_count: int
    improvements: List[str]  # 相比上一版本的改进点
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_type": self.task_type,
            "version": self.version,
            "prompt_template": self.prompt_template,
            "avg_score": self.avg_score,
            "usage_count": self.usage_count,
            "improvements": self.improvements,
            "created_at": self.created_at,
        }


@dataclass
class PromptPerformance:
    """提示词性能记录"""
    task_type: str
    prompt_version: int
    score: float
    feedback: List[str]  # 改进建议
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())


class PromptEvolver:
    """
    提示词进化器
    
    功能：
    1. 记录每个提示词版本的表现
    2. 根据评估反馈自动优化提示词
    3. A/B 测试不同版本的提示词
    4. 保留最佳版本
    """
    
    # 提示词优化触发阈值
    OPTIMIZATION_THRESHOLD = 10  # 收集10次评估后考虑优化
    SCORE_THRESHOLD = 75  # 低于75分触发优化
    
    def __init__(
        self,
        llm_client=None,
        data_dir: Optional[str] = None,
    ):
        """
        初始化提示词进化器
        
        Args:
            llm_client: LLM客户端
            data_dir: 数据存储目录
        """
        self.llm_client = llm_client
        
        # 设置数据目录
        if data_dir:
            self.data_dir = Path(data_dir)
        else:
            self.data_dir = Path.cwd() / "data" / "prompt_evolution"
        
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # 当前活跃的提示词版本
        self.active_prompts: Dict[str, PromptVersion] = {}
        
        # 所有版本历史
        self.version_history: Dict[str, List[PromptVersion]] = {}
        
        # 性能记录
        self.performance_records: Dict[str, List[PromptPerformance]] = {}
        
        # 加载数据
        self._load_data()
        
        logger.info(f"PromptEvolver initialized, data dir: {self.data_dir}")
    
    def _load_data(self) -> None:
        """加载保存的数据"""
        # 加载活跃提示词
        active_file = self.data_dir / "active_prompts.json"
        if active_file.exists():
            try:
                with open(active_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    for task_type, prompt_data in data.items():
                        self.active_prompts[task_type] = PromptVersion(**prompt_data)
                logger.info(f"Loaded {len(self.active_prompts)} active prompts")
            except Exception as e:
                logger.warning(f"Failed to load active prompts: {e}")
        
        # 加载性能记录
        perf_file = self.data_dir / "performance_records.json"
        if perf_file.exists():
            try:
                with open(perf_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    for task_type, records in data.items():
                        self.performance_records[task_type] = [
                            PromptPerformance(**r) for r in records
                        ]
            except Exception as e:
                logger.warning(f"Failed to load performance records: {e}")
    
    def _save_data(self) -> None:
        """保存数据"""
        # 保存活跃提示词
        active_file = self.data_dir / "active_prompts.json"
        try:
            with open(active_file, "w", encoding="utf-8") as f:
                json.dump(
                    {k: v.to_dict() for k, v in self.active_prompts.items()},
                    f,
                    ensure_ascii=False,
                    indent=2,
                )
        except Exception as e:
            logger.warning(f"Failed to save active prompts: {e}")
        
        # 保存性能记录（只保留最近100条）
        perf_file = self.data_dir / "performance_records.json"
        try:
            with open(perf_file, "w", encoding="utf-8") as f:
                data = {}
                for task_type, records in self.performance_records.items():
                    data[task_type] = [
                        {
                            "task_type": r.task_type,
                            "prompt_version": r.prompt_version,
                            "score": r.score,
                            "feedback": r.feedback,
                            "timestamp": r.timestamp,
                        }
                        for r in records[-100:]
                    ]
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"Failed to save performance records: {e}")
    
    def save_all_data(self) -> None:
        """保存所有数据（公共方法）"""
        self._save_data()
    
    def record_performance(
        self,
        task_type: str,
        score: float,
        feedback: str,
        prompt: Optional[str] = None,
    ) -> None:
        """
        记录提示词的表现
        
        Args:
            task_type: 任务类型
            score: 评估分数
            feedback: 改进建议（字符串格式）
            prompt: 使用的提示词（可选，用于后续分析）
        """
        # 获取当前版本
        current_version = 1
        if task_type in self.active_prompts:
            current_version = self.active_prompts[task_type].version
        
        # 将字符串格式的 feedback 转换为列表
        feedback_list = [feedback] if isinstance(feedback, str) else feedback
        
        # 记录性能
        record = PromptPerformance(
            task_type=task_type,
            prompt_version=current_version,
            score=score,
            feedback=feedback_list,
        )
        
        if task_type not in self.performance_records:
            self.performance_records[task_type] = []
        self.performance_records[task_type].append(record)
        
        # 更新活跃提示词的统计
        if task_type in self.active_prompts:
            prompt = self.active_prompts[task_type]
            prompt.usage_count += 1
            # 更新平均分（指数移动平均）
            alpha = 0.2
            prompt.avg_score = alpha * score + (1 - alpha) * prompt.avg_score
        
        self._save_data()
        
        logger.debug(f"Recorded performance for {task_type}: score={score}")
    
    def should_evolve(self, task_type: str) -> bool:
        """
        判断是否应该进化提示词
        
        Args:
            task_type: 任务类型
            
        Returns:
            是否应该进化
        """
        if task_type not in self.performance_records:
            return False
        
        records = self.performance_records[task_type]
        
        # 检查是否有足够的数据
        if len(records) < self.OPTIMIZATION_THRESHOLD:
            return False
        
        # 计算最近的平均分
        recent_records = records[-self.OPTIMIZATION_THRESHOLD:]
        avg_score = sum(r.score for r in recent_records) / len(recent_records)
        
        # 如果平均分低于阈值，需要优化
        if avg_score < self.SCORE_THRESHOLD:
            logger.info(f"Task {task_type} needs optimization: avg_score={avg_score:.1f}")
            return True
        
        return False
    
    async def evolve_prompt(
        self,
        task_type: str,
        current_prompt: str,
        force: bool = False,
    ) -> Tuple[str, List[str]]:
        """
        进化提示词
        
        Args:
            task_type: 任务类型
            current_prompt: 当前提示词
            force: 是否强制进化
            
        Returns:
            (新提示词, 改进点列表)
        """
        if not self.llm_client:
            return current_prompt, []
        
        if not force and not self.should_evolve(task_type):
            return current_prompt, []
        
        # 收集反馈
        feedback_list = []
        if task_type in self.performance_records:
            for record in self.performance_records[task_type][-20:]:
                feedback_list.extend(record.feedback)
        
        # 去重并统计频率
        from collections import Counter
        feedback_counts = Counter(feedback_list)
        top_feedback = [f for f, _ in feedback_counts.most_common(10)]
        
        # 构建优化提示词
        prompt = self._build_evolution_prompt(task_type, current_prompt, top_feedback)
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                task_type="提示词优化",
                temperature=0.7,
                max_tokens=4000,
            )
            
            new_prompt, improvements = self._parse_evolution_response(response.content)
            
            if new_prompt:
                # 保存新版本
                self._save_new_version(task_type, new_prompt, improvements)
                logger.info(f"Evolved prompt for {task_type}, improvements: {improvements}")
                return new_prompt, improvements
            
        except Exception as e:
            logger.error(f"Failed to evolve prompt: {e}")
        
        return current_prompt, []
    
    def _build_evolution_prompt(
        self,
        task_type: str,
        current_prompt: str,
        feedback: List[str],
    ) -> str:
        """构建提示词优化的提示"""
        
        feedback_text = "\n".join([f"- {f}" for f in feedback])
        
        return f"""## 任务：优化提示词

你是一个提示词工程专家。请根据用户反馈，优化以下提示词。

### 当前提示词
```
{current_prompt[:3000]}
```

### 用户反馈（按频率排序）
{feedback_text}

### 优化目标

1. **解决用户反馈中的问题**
2. **保持提示词的核心功能**
3. **让生成的内容更加**：
   - 通俗易懂（白话文）
   - 有故事性和吸引力
   - 避免学术化
   - 符合小说的风格

### 优化原则

1. 不要过度修改，只针对反馈中的问题进行优化
2. 保留原有提示词中有效的部分
3. 增加更明确的约束和示例
4. 使用更具体、更易懂的指令

### 输出格式

请输出优化后的提示词，并列出改进点：

```
【改进点】
1. ...
2. ...
3. ...

【优化后的提示词】
...
```
"""
    
    def _parse_evolution_response(self, response: str) -> Tuple[Optional[str], List[str]]:
        """解析进化响应"""
        improvements = []
        new_prompt = None
        
        try:
            # 提取改进点
            if "【改进点】" in response:
                imp_start = response.find("【改进点】") + len("【改进点】")
                imp_end = response.find("【优化后的提示词】")
                if imp_end > imp_start:
                    imp_text = response[imp_start:imp_end].strip()
                    improvements = [
                        line.strip().lstrip("0123456789.-) ")
                        for line in imp_text.split("\n")
                        if line.strip() and not line.strip().startswith("【")
                    ]
            
            # 提取新提示词
            if "【优化后的提示词】" in response:
                prompt_start = response.find("【优化后的提示词】") + len("【优化后的提示词】")
                new_prompt = response[prompt_start:].strip()
                
                # 清理可能的代码块标记
                if new_prompt.startswith("```"):
                    new_prompt = new_prompt[3:]
                if new_prompt.endswith("```"):
                    new_prompt = new_prompt[:-3]
                new_prompt = new_prompt.strip()
                
        except Exception as e:
            logger.warning(f"Failed to parse evolution response: {e}")
        
        return new_prompt, improvements
    
    def _save_new_version(
        self,
        task_type: str,
        new_prompt: str,
        improvements: List[str],
    ) -> None:
        """保存新版本"""
        # 获取当前版本号
        current_version = 0
        if task_type in self.active_prompts:
            current_version = self.active_prompts[task_type].version
        
        new_version = PromptVersion(
            task_type=task_type,
            version=current_version + 1,
            prompt_template=new_prompt,
            avg_score=75.0,  # 初始分数
            usage_count=0,
            improvements=improvements,
        )
        
        # 保存到历史
        if task_type not in self.version_history:
            self.version_history[task_type] = []
        self.version_history[task_type].append(new_version)
        
        # 设为活跃版本
        self.active_prompts[task_type] = new_version
        
        # 保存历史版本文件
        history_file = self.data_dir / f"{task_type}_history.json"
        try:
            with open(history_file, "w", encoding="utf-8") as f:
                json.dump(
                    [v.to_dict() for v in self.version_history[task_type]],
                    f,
                    ensure_ascii=False,
                    indent=2,
                )
        except Exception as e:
            logger.warning(f"Failed to save version history: {e}")
        
        self._save_data()
    
    def get_best_prompt(self, task_type: str) -> Optional[str]:
        """
        获取任务类型的最佳提示词
        
        Args:
            task_type: 任务类型
            
        Returns:
            最佳提示词模板，如果没有则返回 None
        """
        if task_type in self.active_prompts:
            return self.active_prompts[task_type].prompt_template
        return None
    
    def get_evolution_stats(self, task_type: str) -> Dict[str, Any]:
        """
        获取提示词进化统计
        
        Args:
            task_type: 任务类型
            
        Returns:
            统计信息
        """
        stats = {
            "task_type": task_type,
            "current_version": 0,
            "total_versions": 0,
            "avg_score": 0,
            "usage_count": 0,
            "recent_improvements": [],
        }
        
        if task_type in self.active_prompts:
            prompt = self.active_prompts[task_type]
            stats["current_version"] = prompt.version
            stats["avg_score"] = round(prompt.avg_score, 1)
            stats["usage_count"] = prompt.usage_count
            stats["recent_improvements"] = prompt.improvements
        
        if task_type in self.version_history:
            stats["total_versions"] = len(self.version_history[task_type])
        
        return stats


# 全局实例（延迟初始化）
_prompt_evolver: Optional[PromptEvolver] = None


def get_prompt_evolver(llm_client=None) -> PromptEvolver:
    """获取全局 PromptEvolver 实例"""
    global _prompt_evolver
    if _prompt_evolver is None:
        _prompt_evolver = PromptEvolver(llm_client=llm_client)
    return _prompt_evolver

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.25 at 0x1037a5c70>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.core.prompt_evolver'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.58 at 0x103bdea20>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.core.task_planner'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Task Planner - Plans and schedules creative writing tasks

Defines task types, dependencies, and execution order for novel creation.
Implements the DAG-based task scheduling from the architecture.
"""

import uuid
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Set

from loguru import logger


class NovelTaskType(str, Enum):
    """Task types for novel creation"""

    # Phase 0: Creative Brainstorm (创意脑暴阶段 - 新增)
    CREATIVE_BRAINSTORM = "创意脑暴"  # 产生多个故事点子
    STORY_CORE = "故事核心"  # 确定核心冲突和主角目标

    # Planning phase
    STYLE_ELEMENTS = "风格元素"
    THEME_CONFIRMATION = "主题确认"
    MARKET_POSITIONING = "市场定位"
    OUTLINE = "大纲"

    # Element creation phase
    CHARACTER_DESIGN = "人物设计"
    WORLDVIEW_RULES = "世界观规则"
    EVENTS = "事件"
    SCENES_ITEMS_CONFLICTS = "场景物品冲突"
    FORESHADOW_LIST = "伏笔列表"

    # Consistency phase
    CONSISTENCY_CHECK = "一致性检查"

    # Chapter generation phase
    CHAPTER_OUTLINE = "章节大纲"
    SCENE_GENERATION = "场景生成"
    CHAPTER_CONTENT = "章节内容"
    CHAPTER_POLISH = "章节润色"

    # Evaluation phase
    EVALUATION = "评估"

    # Revision phase
    REVISION = "修订"


@dataclass
class TaskDefinition:
    """Definition of a task in the novel creation pipeline"""

    task_type: NovelTaskType
    description: str
    depends_on: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)
    optional: bool = False
    can_parallel: bool = False
    is_foundation: bool = False  # 🔥 新增：是否是基础任务（章节创作必须参考）

    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_type": self.task_type.value,
            "description": self.description,
            "depends_on": self.depends_on,
            "metadata": self.metadata,
            "optional": self.optional,
            "can_parallel": self.can_parallel,
            "is_foundation": self.is_foundation,
        }


@dataclass
class Task:
    """An instance of a task ready for execution"""

    task_id: str
    task_type: NovelTaskType
    description: str
    status: str = "pending"  # pending, ready, running, completed, failed, skipped
    depends_on: List[str] = field(default_factory=list)
    dependencies_met: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)
    optional: bool = False
    can_parallel: bool = False
    result: Optional[str] = None
    error: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    
    # 🔥 新增：任务统计字段
    started_at: Optional[str] = None  # ISO 格式时间字符串
    completed_at: Optional[str] = None  # ISO 格式时间字符串
    execution_time_seconds: float = 0.0  # 执行时间（秒）
    total_tokens: int = 0  # 总 token 数
    prompt_tokens: int = 0  # 提示词 token 数
    completion_tokens: int = 0  # 生成的 token 数
    cost_usd: float = 0.0  # 费用（美元）
    failed_attempts: int = 0  # 🔥 失败尝试次数
    is_foundation: bool = False  # 🔥 是否是基础任务（章节创作必须参考）

    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_id": self.task_id,
            "task_type": self.task_type.value,
            "description": self.description,
            "status": self.status,
            "depends_on": self.depends_on,
            "dependencies_met": self.dependencies_met,
            "metadata": self.metadata,
            "optional": self.optional,
            "can_parallel": self.can_parallel,
            "is_foundation": self.is_foundation,
            "result": self.result,
            "error": self.error,
            "retry_count": self.retry_count,
            # 🔥 新增统计字段
            "started_at": self.started_at,
            "completed_at": self.completed_at,
            "execution_time_seconds": self.execution_time_seconds,
            "total_tokens": self.total_tokens,
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "cost_usd": self.cost_usd,
            "failed_attempts": self.failed_attempts,
        }


class TaskPlanner:
    """
    Plans and schedules tasks for novel creation

    🎯 顶级作家创作流程（布兰登·桑德森式 - 微调版）：
    
    ════════════════════════════════════════════════════════════════
    📋 任务分类说明
    ════════════════════════════════════════════════════════════════
    
    【基础任务】- is_foundation=True - 章节创作必须参考，存入向量库
    ├── 故事核心：一句话概括，最重要的锚点
    ├── 大纲：故事骨架，章节规划  
    ├── 世界观规则：世界运作的限制
    └── 人物设计：角色设定
    
    【风格任务】- 影响写作方式
    ├── 主题确认（可选）
    ├── 风格元素
    └── 市场定位
    
    【细节任务】- 丰富故事，也存入向量库
    ├── 事件：具体发生什么
    ├── 场景物品冲突：在哪里发生，用什么
    └── 伏笔列表：埋线和回收
    
    ════════════════════════════════════════════════════════════════
    📈 执行流程
    ════════════════════════════════════════════════════════════════
    
    Phase 0: 创意脑暴 → 故事核心 🔴基础
    Phase 1: 大纲（骨架版）🔴基础
    Phase 2: 世界观规则 🔴基础
    Phase 3: 人物设计 🔴基础
    Phase 4: 主题确认 → 风格元素 → 市场定位
    Phase 5: 事件 → 场景物品冲突 → 伏笔列表 🟡细节
    Phase 6: 一致性检查 → 章节创作
    
    章节创作时会从向量库检索：故事核心、大纲、世界观、人物、事件、伏笔
    确保不会跑偏！
    """

    # Default task definitions for novel creation
    DEFAULT_TASK_DEFINITIONS: List[TaskDefinition] = [
        # ============ Phase 0: 创意脑暴（灵感阶段）============
        TaskDefinition(
            task_type=NovelTaskType.CREATIVE_BRAINSTORM,
            description="像顶级作家一样进行创意脑暴，产生3-5个有吸引力的故事点子，每个点子包含：核心冲突、独特卖点、情感钩子",
            depends_on=[],
            is_foundation=False,  # 脑暴不是基础，故事核心才是
        ),
        TaskDefinition(
            task_type=NovelTaskType.STORY_CORE,
            description="从脑暴结果中选择最佳点子，确定故事核心：一句话概括（主角是谁+想要什么+面临什么阻碍+为什么读者会在意）",
            depends_on=["创意脑暴"],
            is_foundation=True,  # 🔴 基础任务！所有创作的锚点
        ),

        # ============ Phase 1: 大纲设计（结构阶段 - 先搭骨架）============
        TaskDefinition(
            task_type=NovelTaskType.OUTLINE,
            description="基于故事核心，设计完整的故事大纲。包括：开端→发展→高潮→结局。确定每一章的核心事件和转折点",
            depends_on=["故事核心"],
            is_foundation=True,  # 🔴 基础任务！章节创作的蓝图
        ),

        # ============ Phase 2: 世界观规则（规则阶段 - 建立限制）============
        TaskDefinition(
            task_type=NovelTaskType.WORLDVIEW_RULES,
            description="根据大纲需要，构建让故事能够发生的世界。定义世界运作的核心规则、限制和可能性",
            depends_on=["大纲"],
            is_foundation=True,  # 🔴 基础任务！人物和事件都要遵守
        ),

        # ============ Phase 3: 人物设计（角色阶段 - 在规则内设计）============
        TaskDefinition(
            task_type=NovelTaskType.CHARACTER_DESIGN,
            description="根据大纲和世界观规则，设计能够推动故事发展的人物。主角的目标、缺陷、成长弧线都要服务于大纲",
            depends_on=["世界观规则"],
            is_foundation=True,  # 🔴 基础任务！所有对话和行为的依据
        ),

        # ============ Phase 4: 主题与风格（从故事中提炼）============
        TaskDefinition(
            task_type=NovelTaskType.THEME_CONFIRMATION,
            description="回顾大纲、世界观和人物，提炼故事的深层主题。主题应该从人物的选择和成长中自然涌现",
            depends_on=["人物设计"],
            optional=True,
            is_foundation=False,  # 主题是提炼出来的，不是硬性约束
        ),
        TaskDefinition(
            task_type=NovelTaskType.STYLE_ELEMENTS,
            description="根据故事类型、世界观和目标读者，确定最适合的叙事风格、语言风格和节奏",
            depends_on=["人物设计"],
            is_foundation=False,  # 风格影响写法，但不是内容约束
        ),
        TaskDefinition(
            task_type=NovelTaskType.MARKET_POSITIONING,
            description="综合以上所有元素，确定目标读者群和市场定位",
            depends_on=["风格元素"],
            is_foundation=False,
        ),

        # ============ Phase 5: 细节填充（为大纲添加血肉）============
        TaskDefinition(
            task_type=NovelTaskType.EVENTS,
            description="细化大纲中的每个章节，设计具体的事件序列。每个事件都要符合世界观规则，由人物性格驱动",
            depends_on=["市场定位"],
            is_foundation=True,  # 🔴 基础任务！具体发生什么
        ),
        TaskDefinition(
            task_type=NovelTaskType.SCENES_ITEMS_CONFLICTS,
            description="为每个事件设计具体场景、重要道具和冲突细节。场景要体现世界观，道具要有叙事功能",
            depends_on=["事件"],
            is_foundation=True,  # 🔴 基础任务！场景描写的依据
        ),
        TaskDefinition(
            task_type=NovelTaskType.FORESHADOW_LIST,
            description="设计伏笔和铺垫，让故事有层次感。伏笔要埋得自然，揭示时让读者恍然大悟",
            depends_on=["场景物品冲突"],
            is_foundation=True,  # 🔴 基础任务！章节要埋设和回收伏笔
        ),

        # ============ Phase 6: 一致性检查 ============
        TaskDefinition(
            task_type=NovelTaskType.CONSISTENCY_CHECK,
            description="从顶级作家的视角审视整个创作：大纲逻辑是否通顺？人物行为是否符合性格和世界观规则？伏笔是否能回收？",
            depends_on=["伏笔列表"],
            is_foundation=False,  # 检查任务，不是创作依据
        ),

        # Phase 7: Chapter Generation - defined per chapter dynamically
    ]

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize task planner

        Args:
            config: Optional configuration
        """
        self.config = config or {}
        self.task_definitions: Dict[str, TaskDefinition] = {}
        self.tasks: Dict[str, Task] = {}

        # Register default task definitions
        for definition in self.DEFAULT_TASK_DEFINITIONS:
            self.register_task_definition(definition)

        logger.info(f"TaskPlanner initialized with {len(self.task_definitions)} definitions")

    def register_task_definition(self, definition: TaskDefinition) -> None:
        """
        Register a task definition

        Args:
            definition: The task definition to register
        """
        self.task_definitions[definition.task_type.value] = definition
        logger.debug(f"Registered task definition: {definition.task_type.value}")

    async def plan(
        self,
        goal: Dict[str, Any],
        chapter_count: Optional[int] = None,
    ) -> List[Task]:
        """
        Generate a task plan based on the creation goal

        Args:
            goal: Creation goal with style, theme, length, etc.
            chapter_count: Number of chapters to create

        Returns:
            List of tasks ready for execution
        """
        logger.info(f"Planning tasks for goal: {goal.get('title', 'Untitled')}")

        # Clear previous tasks
        self.tasks = {}
        
        # 根据章节数量决定使用简化还是完整流程
        is_short_novel = chapter_count is not None and chapter_count <= 3
        
        if is_short_novel:
            # 短篇小说简化流程（布兰登·桑德森式）：
            # 创意脑暴 → 故事核心 → 大纲 → 世界观规则 → 人物设计
            short_novel_definitions = [
                self.DEFAULT_TASK_DEFINITIONS[0],  # 创意脑暴
                self.DEFAULT_TASK_DEFINITIONS[1],  # 故事核心
                self.DEFAULT_TASK_DEFINITIONS[2],  # 大纲
                self.DEFAULT_TASK_DEFINITIONS[3],  # 世界观规则（在人物之前！）
                self.DEFAULT_TASK_DEFINITIONS[4],  # 人物设计（基于世界观规则）
            ]
            
            # 创建任务（依赖关系已在定义中正确设置）
            for definition in short_novel_definitions:
                task = self._create_task_from_definition(definition, goal)
                self.tasks[task.task_id] = task
            
            logger.info(f"Using simplified flow for short novel ({chapter_count} chapters): 5 base tasks")
        else:
            # 完整流程
            for definition in self.DEFAULT_TASK_DEFINITIONS:
                task = self._create_task_from_definition(definition, goal)
                self.tasks[task.task_id] = task

        # Create chapter tasks if chapter count specified
        if chapter_count:
            await self._create_chapter_tasks(chapter_count, goal)

        # Resolve dependencies
        self._resolve_dependencies()

        # Mark ready tasks
        self._update_ready_tasks()

        logger.info(f"Generated {len(self.tasks)} tasks")
        return list(self.tasks.values())

    def _create_task_from_definition(
        self,
        definition: TaskDefinition,
        goal: Dict[str, Any],
    ) -> Task:
        """Create a Task instance from a TaskDefinition"""
        task_id = str(uuid.uuid4())

        # Copy metadata from definition and add goal info
        metadata = definition.metadata.copy()
        metadata["goal_style"] = goal.get("style")
        metadata["goal_theme"] = goal.get("theme")
        metadata["goal_length"] = goal.get("length")

        return Task(
            task_id=task_id,
            task_type=definition.task_type,
            description=definition.description,
            depends_on=definition.depends_on.copy(),
            metadata=metadata,
            optional=definition.optional,
            can_parallel=definition.can_parallel,
            is_foundation=definition.is_foundation,  # 🔴 复制基础任务标志
        )

    async def _create_chapter_tasks(
        self,
        chapter_count: int,
        goal: Dict[str, Any],
    ) -> None:
        """
        Create chapter-specific tasks

        对于短篇小说（1-3章），简化流程：
        1. 章节大纲
        2. 章节内容（直接包含场景生成）
        
        对于中长篇（4章以上），完整流程：
        1. 章节大纲
        2. 章节内容
        3. 章节润色
        """
        logger.info(f"Creating tasks for {chapter_count} chapters")
        
        # 短篇小说简化流程
        is_short_novel = chapter_count <= 3

        for chapter_index in range(1, chapter_count + 1):
            chapter_prefix = f"第{chapter_index}章"
            
            # 上一章的任务ID（用于章节间依赖）
            prev_chapter_content_id = None
            if chapter_index > 1:
                # 找到上一章的章节内容任务
                for task_id, task in self.tasks.items():
                    if (task.task_type == NovelTaskType.CHAPTER_CONTENT and 
                        task.metadata.get("chapter_index") == chapter_index - 1):
                        prev_chapter_content_id = task_id
                        break

            # Chapter Outline - 依赖大纲或一致性检查（取决于流程）
            # 检查是否有一致性检查任务
            has_consistency_check = any(
                task.task_type == NovelTaskType.CONSISTENCY_CHECK 
                for task in self.tasks.values()
            )
            base_dep = "一致性检查" if has_consistency_check else "大纲"
            
            outline_deps = [base_dep]
            if prev_chapter_content_id:
                outline_deps.append(prev_chapter_content_id)
                
            outline_task = Task(
                task_id=str(uuid.uuid4()),
                task_type=NovelTaskType.CHAPTER_OUTLINE,
                description=f"Create outline for {chapter_prefix}",
                depends_on=outline_deps,
                metadata={"chapter_index": chapter_index},
            )
            self.tasks[outline_task.task_id] = outline_task

            # Chapter Content（直接依赖章节大纲，跳过场景生成）
            content_task = Task(
                task_id=str(uuid.uuid4()),
                task_type=NovelTaskType.CHAPTER_CONTENT,
                description=f"Generate content for {chapter_prefix}",
                depends_on=[outline_task.task_id],
                metadata={"chapter_index": chapter_index},
            )
            self.tasks[content_task.task_id] = content_task

            # 短篇小说跳过润色、评估、修订
            if not is_short_novel:
                # Chapter Polish
                polish_task = Task(
                    task_id=str(uuid.uuid4()),
                    task_type=NovelTaskType.CHAPTER_POLISH,
                    description=f"Polish and refine {chapter_prefix}",
                    depends_on=[content_task.task_id],
                    metadata={"chapter_index": chapter_index},
                )
                self.tasks[polish_task.task_id] = polish_task

        tasks_per_chapter = 2 if is_short_novel else 3
        logger.debug(f"Created {chapter_count * tasks_per_chapter} chapter-specific tasks (short={is_short_novel})")

    def _resolve_dependencies(self) -> None:
        """Resolve task dependencies by task_id"""
        # Build a map of task_type to task_ids
        type_to_ids: Dict[str, List[str]] = {}
        for task_id, task in self.tasks.items():
            task_type = task.task_type.value
            if task_type not in type_to_ids:
                type_to_ids[task_type] = []
            type_to_ids[task_type].append(task_id)

        # Resolve each task's depends_on list
        for task in self.tasks.values():
            resolved_deps = []
            for dep in task.depends_on:
                if dep in type_to_ids:
                    # Use the first task of this type
                    resolved_deps.append(type_to_ids[dep][0])
                elif dep in self.tasks:
                    # Direct task ID reference
                    resolved_deps.append(dep)
            task.depends_on = resolved_deps

        logger.debug("Resolved all task dependencies")

    def _update_ready_tasks(self) -> None:
        """Update tasks whose dependencies are met"""
        for task in self.tasks.values():
            if task.status == "pending":
                task.dependencies_met = self._check_dependencies_met(task)
                if task.dependencies_met:
                    task.status = "ready"

        ready_count = sum(1 for t in self.tasks.values() if t.status == "ready")
        logger.debug(f"Updated ready tasks: {ready_count} ready")

    def _check_dependencies_met(self, task: Task) -> bool:
        """Check if all dependencies of a task are completed"""
        for dep_id in task.depends_on:
            if dep_id not in self.tasks:
                logger.warning(f"Task {task.task_id} depends on unknown task {dep_id}")
                return False

            dep_task = self.tasks[dep_id]
            if dep_task.status != "completed":
                return False

        return True

    def get_next_task(self) -> Optional[Task]:
        """
        Get the next task ready for execution

        Returns:
            The next ready task, or None if no tasks are ready
        """
        # Prefer non-parallel tasks first (to maintain order)
        for task in self.tasks.values():
            if task.status == "ready" and not task.can_parallel:
                return task

        # Then parallel tasks
        for task in self.tasks.values():
            if task.status == "ready":
                return task

        return None

    def get_ready_tasks(self, max_count: Optional[int] = None) -> List[Task]:
        """
        Get all tasks ready for execution

        Args:
            max_count: Maximum number of tasks to return

        Returns:
            List of ready tasks
        """
        ready_tasks = [t for t in self.tasks.values() if t.status == "ready"]
        ready_tasks.sort(key=lambda t: not t.can_parallel)

        if max_count:
            return ready_tasks[:max_count]
        return ready_tasks

    def update_task_status(
        self,
        task_id: str,
        status: str,
        result: Optional[str] = None,
        error: Optional[str] = None,
    ) -> None:
        """
        Update the status of a task

        Args:
            task_id: The task ID
            status: New status
            result: Task result (if completed)
            error: Error message (if failed)
        """
        if task_id not in self.tasks:
            logger.warning(f"Unknown task ID: {task_id}")
            return

        task = self.tasks[task_id]
        task.status = status

        if result is not None:
            task.result = result

        if error is not None:
            task.error = error

        # Update dependent tasks
        if status == "completed":
            self._update_ready_tasks()

        logger.debug(f"Updated task {task_id} status to {status}")

    def get_task(self, task_id: str) -> Optional[Task]:
        """Get a task by ID"""
        return self.tasks.get(task_id)

    def get_tasks_by_status(self, status: str) -> List[Task]:
        """Get all tasks with a specific status"""
        return [t for t in self.tasks.values() if t.status == status]

    def get_tasks_by_type(self, task_type: NovelTaskType) -> List[Task]:
        """Get all tasks of a specific type"""
        return [t for t in self.tasks.values() if t.task_type == task_type]

    def get_progress(self) -> Dict[str, Any]:
        """
        Get overall progress information

        Returns:
            Dictionary with progress stats
        """
        total = len(self.tasks)
        completed = sum(1 for t in self.tasks.values() if t.status == "completed")
        failed = sum(1 for t in self.tasks.values() if t.status == "failed")
        running = sum(1 for t in self.tasks.values() if t.status == "running")
        ready = sum(1 for t in self.tasks.values() if t.status == "ready")
        
        # Get current running task
        current_task = None
        current_task_retry_count = 0
        current_task_started_at = None
        running_tasks = [t for t in self.tasks.values() if t.status == "running"]
        if running_tasks:
            current_task = running_tasks[0].task_type.value
            # 获取重试次数
            current_task_retry_count = running_tasks[0].metadata.get("retry_count", 0)
            # 获取任务开始时间
            current_task_started_at = running_tasks[0].metadata.get("started_at")
        
        # 检查是否全部完成
        is_completed = self.is_complete() and failed == 0

        return {
            "total_tasks": total,
            "completed_tasks": completed,
            "failed_tasks": failed,
            "running_tasks": running,
            "ready_tasks": ready,
            "pending_tasks": total - completed - failed - running - ready,
            "percentage": (completed / total * 100) if total > 0 else 0,
            "current_task": current_task,
            "retry_count": current_task_retry_count,
            "task_started_at": current_task_started_at,
            "is_completed": is_completed,
        }

    def is_complete(self) -> bool:
        """Check if all tasks are complete"""
        return all(
            t.status in ("completed", "failed", "skipped")
            for t in self.tasks.values()
        )

    def get_failed_tasks(self) -> List[Task]:
        """Get all failed tasks"""
        return self.get_tasks_by_status("failed")

    def retry_task(self, task_id: str) -> bool:
        """
        Retry a failed task

        Args:
            task_id: The task to retry

        Returns:
            True if task can be retried
        """
        task = self.tasks.get(task_id)
        if not task:
            return False

        if task.status != "failed":
            return False

        if task.retry_count >= task.max_retries:
            logger.warning(f"Task {task_id} has reached max retries")
            return False

        task.retry_count += 1
        task.status = "ready"
        task.error = None

        logger.info(f"Retrying task {task_id} (attempt {task.retry_count})")
        return True

    def reset(self) -> None:
        """Reset all tasks to pending state"""
        for task in self.tasks.values():
            task.status = "pending"
            task.result = None
            task.error = None
            task.retry_count = 0
            task.dependencies_met = False

        self._update_ready_tasks()
        logger.info("Reset all tasks to pending state")

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.58 at 0x103bdea20>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.core.task_planner'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.23 at 0x1041a6c60>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.core.self_evaluator'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Self Evaluator - 自我评估系统

用 LLM 评估生成的内容质量，并给出改进建议。
支持记录评估历史，用于提示词自我迭代优化。
"""

import json
import os
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger


@dataclass
class EvaluationResult:
    """评估结果"""
    task_type: str
    overall_score: float  # 0-100
    dimensions: Dict[str, float]  # 各维度评分
    strengths: List[str]  # 优点
    weaknesses: List[str]  # 缺点
    suggestions: List[str]  # 改进建议
    prompt_improvements: List[str]  # 提示词改进建议
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "task_type": self.task_type,
            "overall_score": self.overall_score,
            "dimensions": self.dimensions,
            "strengths": self.strengths,
            "weaknesses": self.weaknesses,
            "suggestions": self.suggestions,
            "prompt_improvements": self.prompt_improvements,
            "timestamp": self.timestamp,
        }


class SelfEvaluator:
    """
    内容自我评估器
    
    功能：
    1. 评估生成内容的质量
    2. 给出改进建议
    3. 提供提示词优化建议
    4. 记录评估历史用于学习
    """
    
    # 评估维度定义
    EVALUATION_DIMENSIONS = {
        "coherence": "关联性 - 与前置任务的关联是否紧密，是否服务于整体故事",
        "readability": "可读性 - 内容是否通俗易懂、白话文",
        "storytelling": "故事性 - 是否有吸引力、有代入感、像个会讲故事的人写的",
        "consistency": "一致性 - 与前文设定是否一致，有没有自相矛盾",
        "creativity": "创意性 - 是否有新意、不落俗套、有独特的想法",
        "completeness": "完整性 - 是否覆盖了要求的所有内容",
        "structure": "结构性 - 组织是否清晰、逻辑是否通顺",
        "literary": "文学性 - 是否像小说而不是论文，有温度有画面",
    }
    
    # 任务类型特定的评估重点
    TASK_EVALUATION_FOCUS = {
        "创意脑暴": ["creativity", "storytelling", "completeness"],
        "故事核心": ["coherence", "storytelling", "completeness"],
        "风格元素": ["coherence", "readability", "completeness", "literary"],
        "主题确认": ["coherence", "readability", "storytelling", "completeness"],
        "人物设计": ["coherence", "creativity", "completeness", "consistency", "literary"],
        "世界观规则": ["coherence", "readability", "creativity", "completeness"],
        "大纲": ["coherence", "structure", "completeness", "storytelling"],
        "章节大纲": ["coherence", "structure", "consistency", "completeness"],
        "章节内容": ["coherence", "readability", "storytelling", "creativity", "consistency", "literary"],
    }
    
    def __init__(
        self,
        llm_client=None,
        history_dir: Optional[str] = None,
    ):
        """
        初始化评估器
        
        Args:
            llm_client: LLM客户端，用于评估
            history_dir: 评估历史存储目录
        """
        self.llm_client = llm_client
        
        # 设置历史目录
        if history_dir:
            self.history_dir = Path(history_dir)
        else:
            self.history_dir = Path.cwd() / "data" / "evaluation_history"
        
        self.history_dir.mkdir(parents=True, exist_ok=True)
        
        # 加载历史评估数据
        self.evaluation_history: List[EvaluationResult] = []
        self._load_history()
        
        logger.info(f"SelfEvaluator initialized, history dir: {self.history_dir}")
    
    def _load_history(self) -> None:
        """加载历史评估数据"""
        history_file = self.history_dir / "evaluation_history.json"
        if history_file.exists():
            try:
                with open(history_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    for item in data:
                        self.evaluation_history.append(EvaluationResult(**item))
                logger.info(f"Loaded {len(self.evaluation_history)} evaluation records")
            except Exception as e:
                logger.warning(f"Failed to load evaluation history: {e}")
    
    def _save_history(self) -> None:
        """保存评估历史"""
        history_file = self.history_dir / "evaluation_history.json"
        try:
            with open(history_file, "w", encoding="utf-8") as f:
                json.dump(
                    [r.to_dict() for r in self.evaluation_history[-1000:]],  # 只保留最近1000条
                    f,
                    ensure_ascii=False,
                    indent=2,
                )
        except Exception as e:
            logger.warning(f"Failed to save evaluation history: {e}")
    
    async def evaluate(
        self,
        content: str,
        task_type: str,
        context: Optional[Dict[str, Any]] = None,
        goal: Optional[Dict[str, Any]] = None,
    ) -> EvaluationResult:
        """
        评估生成的内容
        
        Args:
            content: 生成的内容
            task_type: 任务类型
            context: 上下文信息
            goal: 创作目标
            
        Returns:
            EvaluationResult 评估结果
        """
        if not self.llm_client:
            return self._basic_evaluation(content, task_type)
        
        # 构建评估提示词
        prompt = self._build_evaluation_prompt(content, task_type, context, goal)
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                task_type="评估",
                temperature=0.3,  # 低温度，更稳定的评估
                max_tokens=2000,
            )
            
            result = self._parse_evaluation_response(response.content, task_type)
            
            # 保存到历史
            self.evaluation_history.append(result)
            self._save_history()
            
            return result
            
        except Exception as e:
            logger.error(f"Evaluation failed: {e}")
            return self._basic_evaluation(content, task_type)
    
    def _build_evaluation_prompt(
        self,
        content: str,
        task_type: str,
        context: Optional[Dict[str, Any]] = None,
        goal: Optional[Dict[str, Any]] = None,
    ) -> str:
        """构建评估提示词 - 顶级作家视角"""
        
        # 获取该任务类型的评估重点
        focus_dimensions = self.TASK_EVALUATION_FOCUS.get(
            task_type, 
            list(self.EVALUATION_DIMENSIONS.keys())
        )
        
        dimensions_desc = "\n".join([
            f"- {dim}: {self.EVALUATION_DIMENSIONS[dim]}"
            for dim in focus_dimensions
        ])
        
        goal_info = ""
        if goal:
            goal_info = f"""
### 创作目标
- 类型: {goal.get('genre', '未知')}
- 字数: {goal.get('word_count', '未知')}
- 章节: {goal.get('chapter_count', '未知')}
- 风格: {goal.get('style', '未知')}
"""

        # 构建前置任务上下文（用于检查关联性）
        context_summary = ""
        if context and isinstance(context, dict):
            recent = context.get('recent_results', [])
            if recent:
                context_summary = "\n### 前置任务成果\n"
                for r in recent[-3:]:  # 最近3个任务
                    context_summary += f"- **{r.get('task_type', '未知')}**: {r.get('content', '')[:200]}...\n"

        prompt = f"""## 顶级作家评估

🎭 **角色设定**：你现在是一位获得过茅盾文学奖、雨果奖的顶级作家，同时也是资深出版社编辑。
你见过太多平庸的作品，对好作品有极高的标准。

### 你的评估原则

作为顶级作家，你知道：
1. **人物是灵魂**：没有活的人物，故事就是死的
2. **故事核心要清晰**：读者在任何时候都要知道"这个故事讲什么"
3. **每个任务都要服务整体**：各部分之间必须紧密关联，不能各自为政
4. **通俗不等于肤浅**：最好的故事人人都看得懂，但有深度
5. **拒绝学术腔**：小说不是论文，要有温度、有画面

### 任务类型
{task_type}
{goal_info}
{context_summary}

### 待评估内容
```
{content[:5000]}  
```
{f'（内容过长，已截断，共{len(content)}字）' if len(content) > 5000 else ''}

### 评估维度
{dimensions_desc}

### 评估要点

**作为顶级作家，你要特别关注：**

1. **与前置任务的关联性**（非常重要！）
   - 当前内容是否充分利用了前面任务的成果？
   - 是否与整体故事核心保持一致？
   - 有没有"另起炉灶"、脱离前文的问题？

2. **内容质量**
   - 是否有血有肉，而不是干巴巴的清单？
   - 是否像个会讲故事的人写的，而不是AI生成的模板？
   - 读者会被吸引吗？

3. **专业性**
   - 是否避免了学术论文腔？
   - 是否做到了"通俗易懂"？
   - 是否有小说家的笔触？

### 输出格式

请以 JSON 格式输出：

```json
{{
  "overall_score": 85,
  "dimensions": {{
    "readability": 80,
    "storytelling": 90,
    ...
  }},
  "strengths": [
    "优点1",
    "优点2"
  ],
  "weaknesses": [
    "缺点1",
    "缺点2"
  ],
  "suggestions": [
    "内容改进建议1",
    "内容改进建议2"
  ],
  "prompt_improvements": [
    "提示词改进建议1：...",
    "提示词改进建议2：..."
  ]
}}
```

请直接输出 JSON，不要其他内容。
"""
        return prompt
    
    def _parse_evaluation_response(
        self, 
        response: str, 
        task_type: str
    ) -> EvaluationResult:
        """解析评估响应"""
        try:
            # 提取 JSON
            json_start = response.find("{")
            json_end = response.rfind("}") + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                data = json.loads(json_str)
                
                return EvaluationResult(
                    task_type=task_type,
                    overall_score=data.get("overall_score", 70),
                    dimensions=data.get("dimensions", {}),
                    strengths=data.get("strengths", []),
                    weaknesses=data.get("weaknesses", []),
                    suggestions=data.get("suggestions", []),
                    prompt_improvements=data.get("prompt_improvements", []),
                )
        except Exception as e:
            logger.warning(f"Failed to parse evaluation response: {e}")
        
        return self._basic_evaluation("", task_type)
    
    def _basic_evaluation(self, content: str, task_type: str) -> EvaluationResult:
        """基础评估（不使用 LLM）"""
        # 简单的基于规则的评估
        score = 70
        strengths = []
        weaknesses = []
        suggestions = []
        
        # 检查长度
        if len(content) > 500:
            strengths.append("内容有一定篇幅")
        else:
            weaknesses.append("内容较短")
            suggestions.append("增加更多细节")
        
        # 检查是否有学术化倾向
        academic_words = ["综上所述", "本文", "研究表明", "数据显示", "实验证明"]
        if any(word in content for word in academic_words):
            weaknesses.append("存在学术化表达")
            suggestions.append("使用更通俗的语言")
        
        return EvaluationResult(
            task_type=task_type,
            overall_score=score,
            dimensions={},
            strengths=strengths,
            weaknesses=weaknesses,
            suggestions=suggestions,
            prompt_improvements=[],
        )
    
    def get_improvement_insights(self, task_type: str) -> Dict[str, Any]:
        """
        根据历史评估数据，获取改进洞察
        
        Args:
            task_type: 任务类型
            
        Returns:
            改进洞察
        """
        # 筛选该任务类型的历史数据
        task_history = [
            r for r in self.evaluation_history 
            if r.task_type == task_type
        ]
        
        if not task_history:
            return {
                "message": "暂无历史数据",
                "optimization_recommended": False,
            }
        
        # 计算平均分
        avg_score = sum(r.overall_score for r in task_history) / len(task_history)
        
        # 收集所有弱点和建议
        all_weaknesses = []
        all_improvements = []
        for r in task_history[-20:]:  # 最近20条
            all_weaknesses.extend(r.weaknesses)
            all_improvements.extend(r.prompt_improvements)
        
        # 统计最常见的问题
        from collections import Counter
        weakness_counts = Counter(all_weaknesses)
        improvement_counts = Counter(all_improvements)
        
        # 判断是否应该触发优化
        # 条件：至少10条评估记录，且平均分低于75
        optimization_recommended = (
            len(task_history) >= 10 and avg_score < 75
        )
        
        # 判断趋势
        trend = "stable"
        if len(task_history) > 5:
            recent_avg = sum(r.overall_score for r in task_history[-5:]) / 5
            if recent_avg > avg_score + 5:
                trend = "improving"
            elif recent_avg < avg_score - 5:
                trend = "declining"
        
        return {
            "task_type": task_type,
            "total_evaluations": len(task_history),
            "average_score": round(avg_score, 1),
            "common_weaknesses": weakness_counts.most_common(5),
            "common_improvements": improvement_counts.most_common(5),
            "trend": trend,
            "optimization_recommended": optimization_recommended,
        }

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.23 at 0x1041a6c60>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.core.self_evaluator'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.87 at 0x1041130e0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-27.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.core.loop_engine'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Loop Engine - Core execution engine for creative writing

Implements the AutoGPT-inspired agent loop:
Think → Plan → Execute → Evaluate → Memory

Coordinates all components for automated novel creation.
"""

import asyncio
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Callable

from loguru import logger

from creative_autogpt.core.task_planner import (
    TaskPlanner,
    NovelTaskType,
    Task,
)
from creative_autogpt.core.evaluator import (
    EvaluationEngine,
    EvaluationResult,
)
from creative_autogpt.core.vector_memory import (
    VectorMemoryManager,
    MemoryContext,
    MemoryType,
)
from creative_autogpt.core.self_evaluator import SelfEvaluator
from creative_autogpt.core.prompt_evolver import PromptEvolver, get_prompt_evolver
from creative_autogpt.utils.llm_client import (
    MultiLLMClient,
    LLMResponse,
)
from creative_autogpt.storage.vector_store import MemoryType as VectorMemoryType


class ExecutionStatus(str, Enum):
    """Status of loop engine execution"""

    IDLE = "idle"
    PLANNING = "planning"
    RUNNING = "running"
    PAUSED = "paused"
    WAITING_APPROVAL = "waiting_approval"  # Waiting for user to approve task result
    COMPLETED = "completed"
    FAILED = "failed"
    STOPPED = "stopped"


@dataclass
class ExecutionStats:
    """Statistics about execution"""

    total_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    skipped_tasks: int = 0
    retried_tasks: int = 0
    total_time: float = 0.0
    llm_calls: int = 0
    tokens_used: int = 0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "total_tasks": self.total_tasks,
            "completed_tasks": self.completed_tasks,
            "failed_tasks": self.failed_tasks,
            "skipped_tasks": self.skipped_tasks,
            "retried_tasks": self.retried_tasks,
            "total_time": self.total_time,
            "llm_calls": self.llm_calls,
            "tokens_used": self.tokens_used,
        }


@dataclass
class ExecutionResult:
    """Result of loop engine execution"""

    status: ExecutionStatus
    stats: ExecutionStats
    outputs: Dict[str, str] = field(default_factory=dict)
    error: Optional[str] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "status": self.status.value,
            "stats": self.stats.to_dict(),
            "outputs": self.outputs,
            "error": self.error,
            "started_at": self.started_at.isoformat() if self.started_at else None,
            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
        }


class LoopEngine:
    """
    Core execution engine for creative writing

    AutoGPT-style agent loop specialized for novel creation:
    1. Plan - Generate task DAG from goals
    2. Execute - Run tasks in dependency order
    3. Evaluate - Assess quality of results
    4. Rewrite - Retry if quality insufficient
    5. Memory - Store results for context
    """

    def __init__(
        self,
        session_id: str,
        llm_client: MultiLLMClient,
        memory: VectorMemoryManager,
        evaluator: EvaluationEngine,
        config: Optional[Dict[str, Any]] = None,
    ):
        """
        Initialize loop engine

        Args:
            session_id: Unique session identifier
            llm_client: Multi-LLM client for generation
            memory: Vector memory manager
            evaluator: Quality evaluation engine
            config: Optional configuration
        """
        self.session_id = session_id
        self.llm_client = llm_client
        self.memory = memory
        self.evaluator = evaluator
        self.config = config or {}

        # Create task planner
        self.planner = TaskPlanner(config=config)
        
        # 自我评估和提示词进化系统
        self.self_evaluator = SelfEvaluator(llm_client=llm_client)
        self.prompt_evolver = get_prompt_evolver(llm_client=llm_client)
        
        # 是否启用自我进化（默认启用）
        self.enable_self_evolution = config.get('enable_self_evolution', True)

        # Execution state
        self.status = ExecutionStatus.IDLE
        self.is_running = False
        self.is_paused = False
        self.current_task: Optional[Task] = None

        # Approval mode settings (enabled by default to allow user review)
        self.approval_mode = config.get('approval_mode', True)  # Default to require approval
        self.is_waiting_approval = False
        self.approval_result: Optional[Dict[str, Any]] = None
        self._approval_event = asyncio.Event()

        # Statistics
        self.stats = ExecutionStats()
        
        # 🎯 高分内容示例存储（用于后续任务的参考）
        # 结构: {task_type: {genre: {"score": float, "content": str, "reason": str}}}
        self.best_examples: Dict[str, Dict[str, Dict[str, Any]]] = {}
        # 最低高分阈值（只有超过这个分数的内容才会被记录为示例）
        self.high_score_threshold = config.get('high_score_threshold', 85)

        # Event callbacks
        self._on_task_start: Optional[Callable] = None
        self._on_task_complete: Optional[Callable] = None
        self._on_task_fail: Optional[Callable] = None
        self._on_progress: Optional[Callable] = None
        self._on_task_approval_needed: Optional[Callable] = None

        logger.info(f"LoopEngine initialized for session {session_id}")

    def set_callbacks(
        self,
        on_task_start: Optional[Callable] = None,
        on_task_complete: Optional[Callable] = None,
        on_task_fail: Optional[Callable] = None,
        on_progress: Optional[Callable] = None,
        on_task_approval_needed: Optional[Callable] = None,
    ) -> None:
        """Set event callbacks for execution monitoring"""
        self._on_task_start = on_task_start
        self._on_task_complete = on_task_complete
        self._on_task_fail = on_task_fail
        self._on_progress = on_progress
        self._on_task_approval_needed = on_task_approval_needed

    async def run(
        self,
        goal: Dict[str, Any],
        chapter_count: Optional[int] = None,
    ) -> ExecutionResult:
        """
        Main execution loop

        Args:
            goal: Creation goal with style, theme, length, etc.
            chapter_count: Number of chapters to create

        Returns:
            ExecutionResult with outputs and statistics
        """
        start_time = time.time()
        started_at = datetime.utcnow()

        self.status = ExecutionStatus.RUNNING
        self.is_running = True
        self.stats = ExecutionStats()

        logger.info(f"Starting execution for session {self.session_id}")
        logger.info(f"Goal: {goal.get('title', 'Untitled')}")

        try:
            # Phase 1: Planning
            self.status = ExecutionStatus.PLANNING
            logger.info("Planning phase: generating task DAG")

            tasks = await self.planner.plan(
                goal=goal,
                chapter_count=chapter_count,
            )

            self.stats.total_tasks = len(tasks)
            logger.info(f"Generated {len(tasks)} tasks")

            # Phase 2: Execute tasks
            self.status = ExecutionStatus.RUNNING

            while self.is_running:
                # Check for pause
                while self.is_paused:
                    await asyncio.sleep(0.1)
                    if not self.is_running:
                        break

                # Get next task
                task = self.planner.get_next_task()
                if task is None:
                    # Check if all tasks are complete
                    if self.planner.is_complete():
                        logger.info("All tasks completed")
                        break
                    # No ready tasks, wait a bit
                    await asyncio.sleep(0.5)
                    continue

                # Execute task
                await self._execute_task(task, goal)

                # Update progress
                if self._on_progress:
                    progress = self.planner.get_progress()
                    await self._safe_callback(
                        self._on_progress,
                        progress,
                    )

            # Phase 3: Complete
            self.status = ExecutionStatus.COMPLETED
            self.stats.total_time = time.time() - start_time

            result = ExecutionResult(
                status=self.status,
                stats=self.stats,
                outputs=self._collect_outputs(),
                started_at=started_at,
                completed_at=datetime.utcnow(),
            )

            logger.info(
                f"Execution completed: {self.stats.completed_tasks}/{self.stats.total_tasks} tasks, "
                f"{self.stats.total_time:.1f}s"
            )

            return result

        except Exception as e:
            logger.error(f"Execution failed: {e}", exc_info=True)
            self.status = ExecutionStatus.FAILED
            self.stats.total_time = time.time() - start_time

            return ExecutionResult(
                status=self.status,
                stats=self.stats,
                error=str(e),
                started_at=started_at,
                completed_at=datetime.utcnow(),
            )

        finally:
            self.is_running = False

    async def _execute_task(
        self,
        task: Task,
        goal: Dict[str, Any],
    ) -> None:
        """
        Execute a single task

        Args:
            task: The task to execute
            goal: Original creation goals
        """
        self.current_task = task
        task.status = "running"
        
        # 🔥 记录任务开始时间（用于统计）
        start_time = datetime.utcnow()
        task.started_at = start_time.isoformat()
        task.metadata["started_at"] = task.started_at
        
        # 🔥 初始化 token 和费用统计
        task_total_tokens = 0
        task_prompt_tokens = 0
        task_completion_tokens = 0
        task_cost = 0.0

        logger.info(f"Executing task {task.task_id}: {task.task_type.value}")

        # Determine which provider will be used (for UI display)
        selected_provider = self.llm_client._select_provider(task.task_type.value)
        task.metadata["llm_provider"] = selected_provider.value

        if self._on_task_start:
            await self._safe_callback(self._on_task_start, task)

        try:
            # 1. Get context from memory
            context = await self.memory.get_context(
                task_id=task.task_id,
                task_type=task.task_type.value,
                chapter_index=task.metadata.get("chapter_index"),
            )

            # 2. Build prompt for the task
            prompt = await self._build_prompt(task, context, goal)

            # 3. Call LLM to generate content
            response = await self.llm_client.generate(
                prompt=prompt,
                task_type=task.task_type.value,
                temperature=self._get_temperature_for_task(task.task_type),
                max_tokens=self._get_max_tokens_for_task(task.task_type),
            )

            # Update actual provider and model used (may differ due to fallback)
            task.metadata["llm_provider"] = response.provider.value
            task.metadata["llm_model"] = response.model

            self.stats.llm_calls += 1
            self.stats.tokens_used += response.usage.total_tokens
            
            # 🔥 累计 token 和费用
            task_total_tokens += response.usage.total_tokens
            task_prompt_tokens += response.usage.prompt_tokens
            task_completion_tokens += response.usage.completion_tokens
            task_cost += self._calculate_cost(response.provider.value, response.model, response.usage)

            # 4. Evaluate quality
            evaluation = await self.evaluator.evaluate(
                task_type=task.task_type.value,
                content=response.content,
                context=context.to_dict(),
                goal=goal,
            )

            # 4.5 总览检查：确保任务输出与前面任务保持一致
            consistency_check = await self._check_task_consistency(
                task=task,
                content=response.content,
                context=context,
                goal=goal,
            )
            
            if not consistency_check.get("passed", True):
                logger.warning(
                    f"Task {task.task_id} failed consistency check: {consistency_check.get('issues', [])}"
                )
                # 将一致性问题添加到评估原因和建议中
                issues = consistency_check.get('issues', [])
                suggestions = consistency_check.get('suggestions', [])
                continuity_issues = consistency_check.get('continuity_issues', [])
                
                # 🔥 将完整的一致性检查结果存储到任务元数据中，供重写时使用
                task.metadata["consistency_check_result"] = consistency_check
                
                # 添加到评估原因（区分一致性问题和连贯性问题）
                if issues:
                    evaluation.reasons.append(f"【一致性问题】{chr(10).join(issues)}")
                if continuity_issues:
                    evaluation.reasons.append(f"【章节连贯性问题】{chr(10).join(continuity_issues)}")
                
                # 添加建议
                if suggestions:
                    evaluation.suggestions.extend(suggestions)
                
                evaluation.passed = False

            # 5. Handle evaluation result
            final_content = response.content
            if not evaluation.passed:
                logger.warning(
                    f"Task {task.task_id} failed evaluation (score: {evaluation.score:.3f})"
                )
                # 🔥 传递当前的 token 统计用于累计
                rewrite_token_stats = {
                    "total_tokens": task_total_tokens,
                    "prompt_tokens": task_prompt_tokens,
                    "completion_tokens": task_completion_tokens,
                    "cost": task_cost,
                }
                final_content, rewrite_token_stats = await self._attempt_rewrite(
                    task=task,
                    content=response.content,
                    evaluation=evaluation,
                    context=context,
                    goal=goal,
                    token_stats=rewrite_token_stats,
                )
                # 🔥 更新统计
                task_total_tokens = rewrite_token_stats["total_tokens"]
                task_prompt_tokens = rewrite_token_stats["prompt_tokens"]
                task_completion_tokens = rewrite_token_stats["completion_tokens"]
                task_cost = rewrite_token_stats["cost"]

            # 6. Store in memory
            memory_type = self._get_memory_type_for_task(task.task_type)
            await self.memory.store(
                content=final_content,
                task_id=task.task_id,
                task_type=task.task_type.value,
                memory_type=memory_type,
                metadata=task.metadata,
                chapter_index=task.metadata.get("chapter_index"),
                evaluation=evaluation.to_dict(),
            )
            
            # 6.5 🎯 检查是否为高分内容，记录为示例
            await self._check_and_save_high_score_example(
                task_type=task.task_type.value,
                genre=goal.get('genre', '通用'),
                content=final_content,
                score=evaluation.score,
                evaluation=evaluation,
            )

            # 7. Check if approval is needed
            # 创意脑暴任务始终需要等待用户选择
            requires_approval = self.approval_mode or task.task_type.value == "创意脑暴"
            
            if requires_approval:
                # 为创意脑暴添加特殊标记，告诉前端需要用户选择点子
                is_brainstorm = task.task_type.value == "创意脑暴"
                
                logger.info(f"Task {task.task_id} waiting for approval" + 
                           (" (requires idea selection)" if is_brainstorm else ""))
                self.status = ExecutionStatus.WAITING_APPROVAL
                self.is_waiting_approval = True
                
                # 设置任务元数据，标记需要选择
                if is_brainstorm:
                    task.metadata["requires_selection"] = True
                    task.metadata["selection_type"] = "idea"
                    task.metadata["selection_count"] = 4  # 4个点子供选择
                
                # Notify frontend that approval is needed
                if self._on_task_approval_needed:
                    await self._safe_callback(
                        self._on_task_approval_needed,
                        task,
                        final_content,
                        evaluation,
                    )
                
                # Wait for approval
                self._approval_event.clear()
                await self._approval_event.wait()
                
                # Check approval result
                if not self.approval_result or self.approval_result.get('action') != 'approve':
                    if self.approval_result and self.approval_result.get('action') == 'reject':
                        # User rejected, mark as failed and skip
                        task.status = "skipped"
                        task.error = "Rejected by user"
                        self.planner.update_task_status(task.task_id, "skipped")
                        self.stats.skipped_tasks += 1
                        self.is_waiting_approval = False
                        self.status = ExecutionStatus.RUNNING
                        return
                    elif self.approval_result and self.approval_result.get('action') == 'regenerate':
                        # User wants to regenerate, retry the task
                        logger.info(f"Regenerating task {task.task_id}")
                        self.is_waiting_approval = False
                        self.status = ExecutionStatus.RUNNING
                        await self._execute_task(task, goal)
                        return
                
                # 处理创意脑暴的点子选择
                if is_brainstorm and self.approval_result:
                    selected_idea = self.approval_result.get('selected_idea')
                    if selected_idea:
                        logger.info(f"User selected idea {selected_idea} for brainstorm task")
                        # 将选择的点子编号存入任务元数据，供后续故事核心任务使用
                        task.metadata["selected_idea"] = selected_idea
                        # 更新内存中的内容，标记选中的点子
                        final_content = f"【用户选择】点子{selected_idea}\n\n{final_content}"
                        # 重新存储更新后的内容
                        await self.memory.store(
                            content=final_content,
                            task_id=task.task_id,
                            task_type=task.task_type.value,
                            memory_type=memory_type,
                            metadata=task.metadata,
                            chapter_index=task.metadata.get("chapter_index"),
                            evaluation=evaluation.to_dict(),
                        )
                
                self.is_waiting_approval = False
                self.status = ExecutionStatus.RUNNING

            # 8. Update task status
            task.status = "completed"
            task.result = final_content
            
            # 🔥 记录任务完成时间和统计信息
            end_time = datetime.utcnow()
            task.completed_at = end_time.isoformat()
            task.execution_time_seconds = (end_time - start_time).total_seconds()
            task.total_tokens = task_total_tokens
            task.prompt_tokens = task_prompt_tokens
            task.completion_tokens = task_completion_tokens
            task.cost_usd = task_cost
            
            # 也更新到 metadata 中（方便前端访问）
            task.metadata["completed_at"] = task.completed_at
            task.metadata["execution_time_seconds"] = task.execution_time_seconds
            task.metadata["total_tokens"] = task.total_tokens
            task.metadata["prompt_tokens"] = task.prompt_tokens
            task.metadata["completion_tokens"] = task.completion_tokens
            task.metadata["cost_usd"] = round(task.cost_usd, 6)
            task.metadata["failed_attempts"] = task.failed_attempts
            
            self.planner.update_task_status(
                task.task_id,
                "completed",
                result=final_content,
            )

            self.stats.completed_tasks += 1

            logger.info(
                f"Task {task.task_id} completed: {len(final_content)} chars, "
                f"tokens: {task_total_tokens}, time: {task.execution_time_seconds:.1f}s, cost: ${task.cost_usd:.4f}"
            )

            # 9. 自我评估和提示词进化（异步执行，不阻塞主流程）
            if self.enable_self_evolution:
                asyncio.create_task(
                    self._self_evolution_pipeline(
                        task=task,
                        content=final_content,
                        prompt=prompt,
                        evaluation_score=evaluation.score,
                        context=context,
                        goal=goal,
                    )
                )

            if self._on_task_complete:
                await self._safe_callback(
                    self._on_task_complete,
                    task,
                    final_content,
                    evaluation,
                )

        except Exception as e:
            logger.error(f"Task {task.task_id} failed: {e}", exc_info=True)

            task.status = "failed"
            task.error = str(e)
            self.planner.update_task_status(
                task.task_id,
                "failed",
                error=str(e),
            )

            self.stats.failed_tasks += 1

            if self._on_task_fail:
                await self._safe_callback(
                    self._on_task_fail,
                    task,
                    str(e),
                )

            # Check if we should continue on error
            if not self.config.get("continue_on_error", False):
                raise

    async def _self_evolution_pipeline(
        self,
        task: Task,
        content: str,
        prompt: str,
        evaluation_score: float,
        context: MemoryContext,
        goal: Dict[str, Any],
    ) -> None:
        """
        自我进化管道：评估内容质量并优化提示词
        
        这是一个后台任务，不会阻塞主流程。
        
        Pipeline 步骤：
        1. 使用 SelfEvaluator 对生成内容进行深度评估
        2. 将评估结果记录到 PromptEvolver
        3. 如果满足条件，触发提示词优化
        
        Args:
            task: 当前任务
            content: 生成的内容
            prompt: 使用的提示词
            evaluation_score: 初步评估分数
            context: 任务上下文
            goal: 创作目标
        """
        task_type = task.task_type.value
        
        try:
            # 1. 深度自我评估
            logger.info(f"🔍 开始自我评估任务: {task_type}")
            
            self_eval_result = await self.self_evaluator.evaluate(
                task_type=task_type,
                content=content,
                context=context.to_dict() if hasattr(context, 'to_dict') else {},
                goal=goal,
            )
            
            # 2. 记录提示词性能
            # 合并初步评估分数和深度评估分数
            combined_score = (evaluation_score * 0.4 + self_eval_result.overall_score / 100 * 0.6)
            
            # 构建反馈信息
            feedback = self._build_evolution_feedback(self_eval_result)
            
            self.prompt_evolver.record_performance(
                task_type=task_type,
                prompt=prompt,
                score=combined_score * 100,  # 转为百分制
                feedback=feedback,
            )
            
            logger.info(
                f"📊 评估完成: {task_type}, 综合分数: {combined_score * 100:.1f}, "
                f"优点: {len(self_eval_result.strengths)}, 不足: {len(self_eval_result.weaknesses)}"
            )
            
            # 3. 检查是否需要触发提示词优化
            # 只在分数较低时考虑优化
            if combined_score < 0.75:
                logger.info(f"⚠️ {task_type} 任务分数较低 ({combined_score * 100:.1f})，考虑优化提示词")
                
                # 获取改进见解
                insights = self.self_evaluator.get_improvement_insights(task_type)
                
                if insights.get("optimization_recommended"):
                    logger.info(f"🚀 触发提示词优化: {task_type}")
                    await self.prompt_evolver.evolve_prompt(
                        task_type=task_type,
                        current_prompt=prompt,
                    )
            
            # 4. 将评估历史保存（用于后续分析）
            # 评估结果在 evaluate() 方法中已自动保存
            self.prompt_evolver.save_all_data()
            
        except Exception as e:
            # 自我进化失败不应该影响主流程
            logger.warning(f"⚠️ 自我进化管道异常: {e}", exc_info=True)

    def _build_evolution_feedback(self, eval_result) -> str:
        """
        根据评估结果构建进化反馈
        
        Args:
            eval_result: SelfEvaluator 的评估结果
            
        Returns:
            结构化的反馈文本，用于提示词优化
        """
        feedback_parts = []
        
        # 添加维度分数
        if eval_result.dimensions:
            score_summary = "维度分数: " + ", ".join(
                f"{k}={v:.0f}" for k, v in eval_result.dimensions.items()
            )
            feedback_parts.append(score_summary)
        
        # 添加优点（简化）
        if eval_result.strengths:
            feedback_parts.append(f"优点: {'; '.join(eval_result.strengths[:3])}")
        
        # 添加不足（更详细，因为这是需要改进的）
        if eval_result.weaknesses:
            feedback_parts.append(f"不足: {'; '.join(eval_result.weaknesses)}")
        
        # 添加改进建议
        if eval_result.suggestions:
            feedback_parts.append(f"建议: {'; '.join(eval_result.suggestions[:3])}")
        
        return "\n".join(feedback_parts)

    async def _check_task_consistency(
        self,
        task: Task,
        content: str,
        context: MemoryContext,
        goal: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        检查任务输出与前面任务的一致性
        使用Qwen的长上下文能力进行全面检查，确保没有偏离已有设定
        
        关键增强：
        1. 利用Qwen 128K上下文能力，带入更多参考内容
        2. 对于章节内容，带入章节大纲和前面章节内容进行对比
        3. 返回详细的问题描述和修改建议
        
        Returns:
            dict with keys: passed (bool), issues (list of str), suggestions (list of str)
        """
        task_type = task.task_type.value
        chapter_index = task.metadata.get("chapter_index", None)
        
        # 不需要一致性检查的任务
        # - 创意脑暴：第一个任务，没有前置内容可参照
        # - 故事核心：基于脑暴结果选择，用户已经手动选择了
        if task_type in ["创意脑暴", "故事核心"]:
            return {"passed": True, "issues": [], "suggestions": []}
        
        # 获取前置任务内容
        predecessor_contents = self._get_predecessor_contents(task_type, context)
        
        if not predecessor_contents:
            return {"passed": True, "issues": [], "suggestions": []}
        
        # 🔥 对于章节相关任务，额外获取章节大纲和前面章节内容
        chapter_context = ""
        if task_type in ["章节内容", "章节润色"] and chapter_index and isinstance(chapter_index, int):
            # 获取前面的章节
            previous_chapters = await self._get_previous_chapters(chapter_index, context, max_chapters=3)
            outline_content = predecessor_contents.get("大纲", "")
            
            # 构建章节上下文（用于一致性检查）
            chapter_context = self._build_consistency_check_context(
                chapter_index,
                previous_chapters,
                outline_content,
                task_type,
            )
        
        # 构建一致性检查提示词
        check_prompt = f"""## 任务一致性检查 🔍

你是一位**顶级畅销小说**的资深编辑，负责确保创作内容的严格一致性。

⚠️ **这是一个关键检查点**：任何与前面任务不一致的内容都会破坏整个故事的完整性！

### 当前任务
- 任务类型：{task_type}
{f"- 章节：第{chapter_index}章" if chapter_index else ""}

### 当前任务的输出内容
```
{content[:8000]}{"..." if len(content) > 8000 else ""}
```

{chapter_context}

### 前面任务的核心成果（必须严格保持一致）
"""
        # 按重要性添加前置内容
        priority_list = ["故事核心", "人物设计", "世界观规则", "风格元素", "大纲", "伏笔列表", "事件", "场景物品冲突"]
        for pred_type in priority_list:
            if pred_type in predecessor_contents:
                pred_content = predecessor_contents[pred_type]
                # 对于关键内容给予更多空间
                max_len = 4000 if pred_type in ["故事核心", "人物设计", "大纲"] else 2000
                check_prompt += f"\n#### {pred_type}\n```\n{pred_content[:max_len]}{'...' if len(pred_content) > max_len else ''}\n```\n"
        
        check_prompt += f"""

### 检查要求（请严格执行！）

请检查当前任务的输出是否与前面的任务**严格保持一致**，重点检查：

1. **故事核心一致性**（最重要！）
   - 是否紧扣【故事核心】中定义的主角目标和核心冲突？
   - 是否服务于故事的核心情感钩子？

2. **人物一致性**
   - 如果涉及人物，是否使用了【人物设计】中已有的角色？
   - 人物的性格、背景、目标是否与设计一致？
   - 有没有凭空出现的新角色（应该避免）？

3. **世界观一致性**
   - 是否符合【世界观规则】中的设定？
   - 有没有违反已设定的规则？
   - 新增的设定是否与已有设定冲突？

4. **风格一致性**
   - 写作风格是否符合【风格元素】的要求？
   - 语言调性是否统一？

5. **主题一致性**
   - 是否围绕【故事核心】和【主题确认】的核心主题展开？
   - 有没有偏离主题、跑题的内容？

6. **逻辑一致性**
   - 与前面的内容是否存在逻辑矛盾？
   - 时间线是否合理？

{f'''7. **章节连贯性**（针对第{chapter_index}章）
   - 本章开头是否自然衔接上一章结尾？
   - 人物状态、位置、情绪是否延续？
   - 时间线是否连贯？
   - 有没有像独立短篇，与前面脱节？
''' if chapter_index and chapter_index > 1 else ''}

### ⚠️ 评判标准（请严格执行）
- 只要发现**任何一个**上述问题，就必须将 `passed` 设为 `false`
- 评分标准：0.9+（完全一致）、0.7-0.9（小问题）、0.7以下（严重问题）
- 章节连贯性问题必须严格判定！脱节的章节必须判为不通过！

### 输出格式
请严格按照以下JSON格式输出：
```json
{{
  "passed": true/false,
  "score": 0.0-1.0,
  "issues": ["具体问题描述1", "具体问题描述2"],
  "suggestions": ["如何修改的具体建议1", "如何修改的具体建议2"],
  "continuity_issues": ["章节连贯性问题1", "章节连贯性问题2"]
}}
```

如果没有发现问题，passed为true，issues为空数组。
如果发现问题，passed为false，列出**具体的**问题和**可操作的**修改建议。

请直接输出JSON，不要有其他内容。
"""
        
        try:
            # 🔥 使用 Qwen-long 进行评估（利用其128K上下文能力）
            # 通过指定 model_type 为 LONG_CONTEXT 来确保使用 Qwen
            response = await self.llm_client.generate(
                prompt=check_prompt,
                task_type="一致性检查",  # 会路由到支持长上下文的模型
                temperature=0.2,  # 降低温度，让检查更严格
                max_tokens=2000,  # 增加token，确保能输出完整的问题描述
            )
            
            # 解析响应
            import json
            import re
            
            # 尝试从响应中提取 JSON
            json_match = re.search(r'\{[\s\S]*\}', response.content)
            if json_match:
                result = json.loads(json_match.group())
                return {
                    "passed": result.get("passed", True),
                    "score": result.get("score", 1.0),
                    "issues": result.get("issues", []),
                    "suggestions": result.get("suggestions", []),
                    "continuity_issues": result.get("continuity_issues", []),
                }
            else:
                logger.warning(f"Could not parse consistency check response: {response.content[:200]}")
                return {"passed": True, "issues": [], "suggestions": []}
                
        except Exception as e:
            logger.error(f"Consistency check failed: {e}")
            # 如果检查失败，默认通过（不阻塞流程）
            return {"passed": True, "issues": [], "suggestions": []}

    def _get_predecessor_contents(
        self,
        task_type: str,
        context: MemoryContext,
    ) -> Dict[str, str]:
        """
        获取当前任务所需的前置任务内容
        
        Args:
            task_type: 当前任务类型
            context: 任务上下文，包含前面任务的结果
            
        Returns:
            前置任务内容的字典，key 是任务类型，value 是任务输出内容
        """
        # 定义每个任务需要的前置任务（布兰登·桑德森式流程）
        # 流程：创意脑暴 → 故事核心 → 大纲 → 世界观规则 → 人物设计 → 主题确认/风格元素 → 市场定位 → 事件 → 场景物品冲突 → 伏笔列表 → 一致性检查
        task_dependencies = {
            # Phase 0: 创意脑暴阶段
            "创意脑暴": [],  # 第一个任务，无依赖
            "故事核心": ["创意脑暴"],  # 必须基于脑暴结果
            
            # Phase 1: 大纲设计（结构优先！）
            "大纲": ["故事核心"],  # 🔥 大纲紧跟故事核心，先搭骨架
            
            # Phase 2: 世界观规则（在人物之前！）
            # 布兰登·桑德森的方法：先建立世界规则，人物才能在规则内行动
            "世界观规则": ["故事核心", "大纲"],  # 世界观服务于大纲
            
            # Phase 3: 人物设计（基于大纲和世界观）
            "人物设计": ["故事核心", "大纲", "世界观规则"],  # 人物在世界规则内完成大纲
            
            # Phase 4: 主题与风格（从故事中提炼）
            "主题确认": ["故事核心", "大纲", "世界观规则", "人物设计"],  # 主题从人物选择中涌现
            "风格元素": ["故事核心", "大纲", "世界观规则", "人物设计"],  # 风格服务于故事
            "市场定位": ["故事核心", "大纲", "人物设计", "风格元素"],  # 综合所有元素
            
            # Phase 5: 细节填充（为大纲添加血肉）
            "事件": ["故事核心", "大纲", "世界观规则", "人物设计", "市场定位"],
            "场景物品冲突": ["故事核心", "大纲", "世界观规则", "人物设计", "事件"],
            "伏笔列表": ["故事核心", "大纲", "人物设计", "事件", "场景物品冲突"],
            
            # Phase 6: 一致性检查
            "一致性检查": ["故事核心", "大纲", "世界观规则", "人物设计", "事件", "场景物品冲突", "伏笔列表"],
            
            # Phase 7: 章节创作 - 🔴 必须包含所有基础设定 + 风格元素！
            # 基础设定 = 故事核心 + 大纲 + 世界观规则 + 人物设计 + 事件 + 场景物品冲突 + 伏笔列表
            # 上一章内容通过 _get_previous_chapters() 单独获取
            "章节大纲": ["故事核心", "大纲", "世界观规则", "人物设计", "风格元素", "事件", "场景物品冲突", "伏笔列表"],
            "场景生成": ["故事核心", "大纲", "世界观规则", "人物设计", "风格元素", "事件", "场景物品冲突", "伏笔列表"],
            "章节内容": ["故事核心", "大纲", "世界观规则", "人物设计", "风格元素", "事件", "场景物品冲突", "伏笔列表"],
            "章节润色": ["故事核心", "大纲", "世界观规则", "人物设计", "风格元素", "事件", "场景物品冲突", "伏笔列表"],
        }
        
        needed_tasks = task_dependencies.get(task_type, [])
        predecessor_contents = {}
        
        # 从 recent_results 中提取前置任务内容
        if context.recent_results:
            for result in context.recent_results:
                result_type = result.get("task_type", "")
                if result_type in needed_tasks:
                    predecessor_contents[result_type] = result.get("content", "")
        
        # 从 relevant_memories 中补充
        if context.relevant_memories:
            for mem in context.relevant_memories:
                # 尝试从 content 中识别任务类型
                mem_type = mem.get("memory_type", "")
                content = mem.get("content", "")
                # 检查是否是需要的任务类型（通过 memory_type 或内容匹配）
                for needed in needed_tasks:
                    if needed not in predecessor_contents and needed.lower() in mem_type.lower():
                        predecessor_contents[needed] = content
        
        return predecessor_contents

    async def _analyze_context_needs(
        self,
        task: Task,
        goal: Dict[str, Any],
        predecessor_contents: Dict[str, str],
    ) -> Dict[str, Any]:
        """
        使用LLM动态分析当前任务需要哪些上下文信息
        
        让LLM自己决定需要参考哪些内容，而不是使用固定规则。
        这样可以更智能地选择相关上下文，避免信息过载。
        
        Args:
            task: 当前任务
            goal: 创作目标
            predecessor_contents: 所有可用的前置任务内容
            
        Returns:
            包含选择的上下文和理由的字典：
            {
                "selected_contexts": ["故事核心", "人物设计", ...],
                "context_focus": {"故事核心": "需要关注主角动机", ...},
                "reasoning": "选择理由"
            }
        """
        task_type = task.task_type.value
        chapter_index = task.metadata.get("chapter_index", None)
        
        # 构建可用上下文列表
        available_contexts = list(predecessor_contents.keys())
        if not available_contexts:
            return {
                "selected_contexts": [],
                "context_focus": {},
                "reasoning": "没有可用的前置任务内容"
            }
        
        # 构建分析提示词
        analysis_prompt = f"""
你是一位经验丰富的小说创作顾问。你正在帮助一位作家完成创作任务。

## 当前任务信息
- **任务类型**: {task_type}
- **章节**: {f"第{chapter_index}章" if chapter_index else "非章节任务"}
- **创作目标**: {goal.get('theme', '未指定主题')}

## 可用的参考资料

以下是你可以参考的前置任务成果（按重要性排序）：

{chr(10).join([f"- **{name}**: {len(content)}字" for name, content in predecessor_contents.items()])}

## 你的任务

请分析当前任务（{task_type}）最需要参考哪些内容，以及需要重点关注什么。

**注意**：
1. 不要选择所有内容！只选择**真正必要**的
2. 对于章节创作，前面章节的内容和大纲是必需的
3. 说明每个选择需要关注的**具体方面**

请用JSON格式输出：
```json
{{
    "selected_contexts": ["需要的内容1", "需要的内容2"],
    "context_focus": {{
        "需要的内容1": "需要关注的具体方面",
        "需要的内容2": "需要关注的具体方面"
    }},
    "reasoning": "为什么选择这些内容的简短理由"
}}
```
"""
        
        try:
            # 使用LLM进行分析
            response = await self.llm_client.generate(
                prompt=analysis_prompt,
                task_type="上下文分析",
                temperature=0.3,  # 低温度，更确定性
                max_tokens=1000,
            )
            
            # 解析JSON响应
            import re
            import json
            
            response_text = response.content  # 从 LLMResponse 对象获取内容
            
            # 尝试提取JSON
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(1))
            else:
                # 尝试直接解析整个响应
                result = json.loads(response_text)
            
            # 验证选择的上下文是否有效
            valid_contexts = [ctx for ctx in result.get("selected_contexts", []) if ctx in predecessor_contents]
            result["selected_contexts"] = valid_contexts
            
            logger.info(f"🧠 动态上下文分析完成: 选择了 {len(valid_contexts)} 个上下文 - {valid_contexts}")
            
            return result
            
        except Exception as e:
            logger.warning(f"⚠️ 动态上下文分析失败，使用默认规则: {e}")
            # 失败时返回所有内容（降级策略）
            return {
                "selected_contexts": list(predecessor_contents.keys()),
                "context_focus": {},
                "reasoning": f"分析失败，使用全部内容: {str(e)}"
            }

    def _build_focused_context_section(
        self,
        predecessor_contents: Dict[str, str],
        context_analysis: Dict[str, Any],
    ) -> str:
        """
        根据动态分析结果构建聚焦的上下文部分
        
        Args:
            predecessor_contents: 所有前置任务内容
            context_analysis: 动态分析结果
            
        Returns:
            聚焦的上下文提示词
        """
        selected = context_analysis.get("selected_contexts", [])
        focus = context_analysis.get("context_focus", {})
        reasoning = context_analysis.get("reasoning", "")
        
        if not selected:
            return ""
        
        sections = []
        
        sections.append(f"""
╔══════════════════════════════════════════════════════════════════╗
║  🎯 聚焦参考资料 - 经过智能分析后的必要信息                     ║
╚══════════════════════════════════════════════════════════════════╝

📝 **选择理由**: {reasoning}

---

""")
        
        # 按选择顺序展示内容
        for ctx_name in selected:
            if ctx_name not in predecessor_contents:
                continue
                
            content = predecessor_contents[ctx_name]
            focus_point = focus.get(ctx_name, "")
            
            # 根据是否有焦点来决定展示多少内容
            if focus_point:
                # 有明确焦点，截取更短
                max_len = 1500
                sections.append(f"\n### 📌 {ctx_name}\n")
                sections.append(f"**关注重点**: {focus_point}\n\n")
            else:
                # 没有明确焦点，展示更多
                max_len = 2500
                sections.append(f"\n### {ctx_name}\n")
            
            # 截取内容
            if len(content) > max_len:
                content = content[:max_len] + "\n...\n（内容已截断，请聚焦上述要点）"
            
            sections.append(f"```\n{content}\n```\n")
        
        sections.append("""
---

💡 **使用指南**：
- 以上是经过分析后认为对当前任务最重要的参考资料
- 请特别关注标注的"关注重点"
- 确保你的创作与这些内容保持一致

""")
        
        return "".join(sections)

    async def _get_previous_chapters(
        self,
        current_chapter: int,
        context: MemoryContext,
        max_chapters: int = 3,
    ) -> Dict[int, Dict[str, str]]:
        """
        获取前面章节的内容，用于保持故事连贯性
        
        Args:
            current_chapter: 当前章节号
            context: 记忆上下文
            max_chapters: 最多获取多少章（默认前3章，避免上下文过长）
            
        Returns:
            字典，key是章节号，value是包含outline和content的字典
        """
        previous_chapters = {}
        
        # 从 recent_results 中查找前面章节
        if context.recent_results:
            for result in context.recent_results:
                task_type = result.get("task_type", "")
                chapter_index = result.get("chapter_index")
                
                if chapter_index is not None and chapter_index < current_chapter:
                    if chapter_index not in previous_chapters:
                        previous_chapters[chapter_index] = {}
                    
                    if task_type == "章节大纲":
                        previous_chapters[chapter_index]["outline"] = result.get("content", "")
                    elif task_type in ("章节内容", "章节润色"):
                        # 优先使用润色后的内容
                        if task_type == "章节润色" or "content" not in previous_chapters[chapter_index]:
                            previous_chapters[chapter_index]["content"] = result.get("content", "")
        
        # 从 relevant_memories 中补充
        if context.relevant_memories:
            for mem in context.relevant_memories:
                chapter_index = mem.get("chapter_index")
                mem_type = mem.get("memory_type", "").lower()
                
                if chapter_index is not None and chapter_index < current_chapter:
                    if chapter_index not in previous_chapters:
                        previous_chapters[chapter_index] = {}
                    
                    content = mem.get("content", "")
                    if "章节大纲" in mem_type and "outline" not in previous_chapters[chapter_index]:
                        previous_chapters[chapter_index]["outline"] = content
                    elif ("章节内容" in mem_type or "章节润色" in mem_type) and "content" not in previous_chapters[chapter_index]:
                        previous_chapters[chapter_index]["content"] = content
        
        # 只保留最近的 max_chapters 章
        if len(previous_chapters) > max_chapters:
            sorted_chapters = sorted(previous_chapters.keys(), reverse=True)[:max_chapters]
            previous_chapters = {k: previous_chapters[k] for k in sorted_chapters}
        
        return previous_chapters

    def _build_chapter_continuity_context(
        self,
        current_chapter: int,
        previous_chapters: Dict[int, Dict[str, str]],
        outline_content: str,
    ) -> str:
        """
        构建章节连贯性上下文
        
        Args:
            current_chapter: 当前章节号
            previous_chapters: 前面章节的内容
            outline_content: 总大纲内容
            
        Returns:
            连贯性上下文字符串
        """
        if not previous_chapters and not outline_content:
            return ""
        
        sections = []
        
        sections.append("""
╔══════════════════════════════════════════════════════════════════╗
║  🔗 故事连贯性约束 - 必须与前面章节紧密衔接！                  ║
╚══════════════════════════════════════════════════════════════════╝

⚠️ **核心要求**：
- 当前章节必须**承接前面的情节**，不能像独立的小故事
- 人物状态、情感、位置必须**延续**前一章结尾
- 悬念、伏笔必须**有回应**或**继续铺垫**
- 时间线必须**连贯**，不能出现跳跃或矛盾

""")
        
        # 添加总大纲摘要（帮助理解整体走向）
        if outline_content:
            sections.append(f"""
### 📋 故事总大纲（参考整体走向）

```
{outline_content[:2000]}{"..." if len(outline_content) > 2000 else ""}
```

""")
        
        # 添加前面章节的内容
        if previous_chapters:
            sorted_chapters = sorted(previous_chapters.keys())
            
            for chapter_num in sorted_chapters:
                chapter_data = previous_chapters[chapter_num]
                
                sections.append(f"""
### 📖 第{chapter_num}章 回顾

""")
                
                if chapter_data.get("outline"):
                    sections.append(f"""
**章节大纲**：
```
{chapter_data["outline"][:800]}{"..." if len(chapter_data.get("outline", "")) > 800 else ""}
```

""")
                
                if chapter_data.get("content"):
                    content = chapter_data["content"]
                    # 提取结尾部分（最后500字左右），这对衔接最重要
                    ending = content[-800:] if len(content) > 800 else content
                    sections.append(f"""
**章节结尾**（必须从这里衔接！）：
```
{ending}
```

""")
        
        # 添加连贯性检查清单
        sections.append(f"""
### ✅ 连贯性检查清单（写作时必须确认）

- [ ] **人物状态**：第{current_chapter}章开头的人物状态是否与前一章结尾一致？
- [ ] **时间连续**：时间是否连贯？如有跳跃是否交代清楚？
- [ ] **空间连续**：人物位置是否合理过渡？
- [ ] **情节承接**：是否回应了前面的悬念/冲突？
- [ ] **情感延续**：人物情绪是否有合理的延续或转变？
- [ ] **伏笔处理**：是否有伏笔需要揭示或继续铺垫？

""")
        
        return "\n".join(sections)

    def _build_consistency_check_context(
        self,
        current_chapter: int,
        previous_chapters: Dict[int, Dict[str, str]],
        outline_content: str,
        task_type: str,
    ) -> str:
        """
        构建一致性检查专用的上下文
        
        与 _build_chapter_continuity_context 类似，但专门用于一致性检查，
        会包含更详细的内容以便检查连贯性问题。
        
        Args:
            current_chapter: 当前章节号
            previous_chapters: 前面章节的内容
            outline_content: 总大纲内容
            task_type: 当前任务类型
            
        Returns:
            一致性检查上下文字符串
        """
        if not previous_chapters and not outline_content:
            return ""
        
        sections = []
        
        sections.append(f"""
### 🔗 章节连贯性检查参考（针对第{current_chapter}章）

""")
        
        # 添加总大纲（完整版，利用 Qwen 的长上下文）
        if outline_content:
            sections.append(f"""
#### 📋 故事总大纲
```
{outline_content[:6000]}{"..." if len(outline_content) > 6000 else ""}
```

""")
        
        # 添加前面章节的内容（尽量完整）
        if previous_chapters:
            sorted_chapters = sorted(previous_chapters.keys())
            
            for chapter_num in sorted_chapters:
                chapter_data = previous_chapters[chapter_num]
                
                sections.append(f"""
#### 📖 第{chapter_num}章

""")
                
                if chapter_data.get("outline"):
                    outline = chapter_data["outline"]
                    sections.append(f"""
**大纲**：
```
{outline[:1500]}{"..." if len(outline) > 1500 else ""}
```

""")
                
                if chapter_data.get("content"):
                    content = chapter_data["content"]
                    # 对于一致性检查，给更多内容（特别是前一章的结尾部分）
                    if chapter_num == current_chapter - 1:
                        # 前一章，给更多结尾内容
                        ending = content[-2000:] if len(content) > 2000 else content
                        sections.append(f"""
**结尾部分**（必须衔接）：
```
{ending}
```

""")
                    else:
                        # 更早的章节，给简短摘要
                        ending = content[-800:] if len(content) > 800 else content
                        sections.append(f"""
**结尾摘要**：
```
{ending}
```

""")
        
        sections.append(f"""
#### ⚠️ 一致性检查重点

请特别检查第{current_chapter}章：
1. **开头衔接**：是否自然承接第{current_chapter - 1}章的结尾？
2. **人物状态**：人物的位置、情绪、状态是否延续？
3. **时间线**：时间是否连贯，有无跳跃或矛盾？
4. **情节连贯**：是否像一个完整故事的一部分，而非独立短篇？

""")
        
        return "\n".join(sections)

    def _build_foundation_reference(
        self,
        predecessor_contents: Dict[str, str],
        task_type: str,
    ) -> str:
        """
        构建基础设定参考部分 - 章节创作必看！
        
        基础设定（is_foundation=True的任务）是整个故事的锚点：
        - 故事核心：一句话概括，不能偏离
        - 大纲：故事骨架，必须按此推进
        - 世界观规则：世界运作的限制，不能违反
        - 人物设计：角色设定，行为必须符合性格
        - 事件：具体发生什么
        - 场景物品冲突：在哪里发生，用什么
        - 伏笔列表：埋设和回收，必须遵守
        
        Args:
            predecessor_contents: 前置任务内容
            task_type: 当前任务类型
            
        Returns:
            基础设定参考字符串
        """
        if not predecessor_contents:
            return ""
        
        # 定义基础设定任务（与 task_planner.py 中 is_foundation=True 的任务对应）
        foundation_tasks = ["故事核心", "大纲", "世界观规则", "人物设计", "事件", "场景物品冲突", "伏笔列表"]
        
        # 提取存在的基础设定内容
        foundation_contents = {
            k: v for k, v in predecessor_contents.items() 
            if k in foundation_tasks
        }
        
        if not foundation_contents:
            return ""
        
        sections = []
        
        sections.append("""
╔══════════════════════════════════════════════════════════════════════════════╗
║  🔴 【基础设定参考 - 绝对不能违反！】                                        ║
╠══════════════════════════════════════════════════════════════════════════════╣
║  以下内容是整个故事的"宪法"，章节创作必须严格遵守！                         ║
║  任何偏离都会导致故事不连贯、人物崩坏、世界观矛盾！                         ║
╚══════════════════════════════════════════════════════════════════════════════╝

⚠️ 警告：写作前请仔细阅读以下基础设定，写作中请反复对照确认！

""")
        
        # 按重要程度排序展示基础设定
        priority_order = [
            ("故事核心", "🎯 故事核心（最重要的锚点）", "所有创作必须围绕这个核心展开"),
            ("大纲", "📋 故事大纲（章节规划）", "本章内容必须符合大纲中的规划"),
            ("世界观规则", "🌍 世界观规则（运作限制）", "所有行为和事件必须符合世界规则"),
            ("人物设计", "👤 人物设计（角色设定）", "人物言行必须符合性格，不能崩人设"),
            ("事件", "⚡ 事件（具体发生什么）", "本章应包含相应的事件"),
            ("场景物品冲突", "🏠 场景物品冲突（在哪里发生）", "场景描写要符合设定"),
            ("伏笔列表", "🔮 伏笔列表（埋设和回收）", "本章应埋设或回收相应伏笔"),
        ]
        
        for task_name, title, tip in priority_order:
            if task_name in foundation_contents:
                content = foundation_contents[task_name]
                # 基础设定内容要尽量完整，利用长上下文
                max_len = 3500 if task_name in ["故事核心", "大纲", "人物设计", "世界观规则"] else 2000
                if len(content) > max_len:
                    content = content[:max_len] + "\n...\n（内容已截断，核心要点如上）"
                
                sections.append(f"""
### {title}

💡 **使用提示**：{tip}

```
{content}
```

""")
        
        sections.append(f"""
═══════════════════════════════════════════════════════════════════════════════

📌 **创作检查清单**（写完后请逐一确认）：

✅ 本章内容是否紧扣【故事核心】？
✅ 本章是否按照【大纲】规划推进？
✅ 人物言行是否符合【人物设计】的性格？
✅ 世界运作是否符合【世界观规则】？
✅ 本章是否正确处理了【伏笔】（埋设或回收）？
✅ 场景描写是否符合【场景物品冲突】设定？

❌ **绝对禁止**：
- 禁止偏离故事核心，写成另一个故事
- 禁止让人物做出不符合性格的行为
- 禁止违反世界观规则
- 禁止遗忘已埋设的伏笔
- 禁止与前面章节脱节

═══════════════════════════════════════════════════════════════════════════════

""")
        
        return "".join(sections)

    def _build_dynamic_context_section(
        self,
        task_type: str,
        predecessor_contents: Dict[str, str],
        goal: Dict[str, Any],
    ) -> str:
        """
        根据前置任务内容动态构建上下文部分
        
        Args:
            task_type: 当前任务类型
            predecessor_contents: 前置任务内容
            goal: 创作目标
            
        Returns:
            动态生成的上下文提示词
        """
        if not predecessor_contents:
            return ""
        
        sections = []
        
        # 强调关联性的开头
        sections.append("""
╔══════════════════════════════════════════════════════════════════╗
║  📚 前置任务成果 - 你必须基于这些内容创作，保持紧密关联！      ║
╚══════════════════════════════════════════════════════════════════╝

⚠️ **重要提醒**：
- 当前任务必须与以下内容**紧密关联**
- 不要"另起炉灶"，要在前面的基础上**延伸和深化**
- 评估时会检查你与前置任务的**关联程度**

""")
        
        # 按新的重要程度排序展示前置内容（故事核心最重要）
        priority_order = [
            "创意脑暴", "故事核心",  # 最重要的根基
            "人物设计", "世界观规则",  # 核心元素
            "主题确认", "风格元素", "市场定位",  # 风格定位
            "事件", "场景物品冲突", "伏笔列表",  # 情节元素
            "大纲"  # 整合
        ]
        
        for task_name in priority_order:
            if task_name in predecessor_contents:
                content = predecessor_contents[task_name]
                # 截取合理长度（避免超长）
                max_len = 2500 if task_name in ["故事核心", "大纲", "人物设计", "世界观规则"] else 1200
                if len(content) > max_len:
                    content = content[:max_len] + "...\n（内容已截断，请参考要点）"
                
                # 为重要任务添加特殊标记
                if task_name in ["故事核心", "人物设计"]:
                    sections.append(f"\n### 🎯 {task_name}（核心参考）\n")
                else:
                    sections.append(f"\n### {task_name}\n")
                sections.append(f"{content}\n")
        
        sections.append("""
---

📌 **你的任务**：在以上基础上继续创作，确保：
1. 与【故事核心】保持一致
2. 人物行为符合【人物设计】
3. 世界运作符合【世界观规则】
4. 风格符合【风格元素】（如已确定）

""")
        
        return "".join(sections)

    async def _build_prompt(
        self,
        task: Task,
        context: MemoryContext,
        goal: Dict[str, Any],
    ) -> str:
        """Build prompt for a task"""

        # Base prompt sections
        sections = []
        
        # Get task type value for matching
        task_type = task.task_type.value
        
        # 🔥 首先构建配置约束部分 - 所有任务都需要看到这些硬性约束
        word_count = goal.get("word_count", 50000)
        chapter_count = goal.get("chapter_count", 10)
        words_per_chapter = word_count // max(chapter_count, 1)
        genre = goal.get("genre", "")
        style = goal.get("style", "")
        
        # 根据字数显示不同格式
        if word_count >= 10000:
            word_display = f"{word_count // 10000}万字"
        else:
            word_display = f"{word_count}字"
        
        config_constraints = f"""
════════════════════════════════════════════════════════════════
📋 【核心配置约束 - 必须严格遵守】
════════════════════════════════════════════════════════════════

🎯 总字数限制：{word_display}（这是硬性要求，不能超出！）
📚 章节数量：{chapter_count}章（严格按此规划，不多不少！）
📝 每章字数：约{words_per_chapter}字

⚠️ 重要：所有规划、设计、创作都必须在这个框架内进行！
   不要超出字数限制，不要规划超出指定的章节数！

════════════════════════════════════════════════════════════════

"""
        sections.append(config_constraints)
        
        # 🎯 添加类型特定的创作指南（仙侠、科幻、言情等各不相同）
        genre_guide = self.get_genre_specific_guide(genre)
        sections.append(genre_guide)

        # Determine if this is a planning/analysis task or a content generation task
        planning_tasks = ["风格元素", "主题确认", "市场定位"]
        element_tasks = ["人物设计", "世界观规则", "事件设定", "场景物品冲突", "伏笔列表", "事件"]
        content_tasks = ["大纲", "章节大纲", "章节内容", "场景生成", "章节润色"]
        
        # 通用的白话文写作风格要求（所有任务都适用）
        colloquial_style_guide = """
🚨 **核心写作要求：白话文、接地气、通俗易懂**

你是一位擅长讲故事的作家，不是在写学术论文！
请像和朋友聊天一样写作，让高中生也能轻松看懂。

✅ **正确示范（白话文）**：
- ❌ "该角色具有内向型人格特质，在社交场合中呈现回避性行为模式"
- ✅ "他不太爱说话，人多的时候总喜欢躲在角落"

- ❌ "此设定构建了一个以科技发展为核心驱动力的叙事框架"
- ✅ "这个世界因为科技发达，发生了很多有意思的变化"

- ❌ "主角的内在驱动力源于童年创伤所形成的心理补偿机制"
- ✅ "他小时候受过伤，所以长大后特别想证明自己"

🚫 **绝对禁止（这些词看到就改！）**：
- 禁止用词："驱动力"、"机制"、"框架"、"模式"、"特质"、"维度"、"层面"、"范畴"
- 禁止用词："呈现"、"构建"、"探讨"、"阐述"、"论述"、"概述"、"综述"
- 禁止用词："基于"、"鉴于"、"关于"、"就...而言"、"从...角度"
- 禁止用词："具有...特征"、"表现出...倾向"、"体现了...精神"
- 禁止格式：一、二、三的正式大纲格式（可以用但不要过度）
- 禁止格式："首先...其次...最后..."的论文式写法

✅ **推荐写法**：
- 说人话：用"因为...所以..."而不是"鉴于...因此..."
- 用比喻：复杂概念用生活中的例子解释
- 讲故事：用叙事的方式而不是说明文的方式
- 接地气：想象你在给朋友讲一个好玩的故事

"""
        
        # Build goal section based on task type
        if task_type in planning_tasks:
            # Planning/analysis tasks - structured output
            goal_section = f"""## 任务背景

你正在为一部小说做**前期规划和分析**工作。
这个阶段的任务是帮助明确小说的方向，而不是直接写小说内容。

{colloquial_style_guide}
"""
        elif task_type in element_tasks:
            # Element creation tasks - semi-structured output  
            goal_section = f"""## 任务背景

你正在为一部小说**设计创作元素**。
这些元素将用于后续的章节创作，需要既有结构性又有文学性。

{colloquial_style_guide}
"""
        else:
            # Content generation tasks - narrative output
            goal_section = f"""## 创作目标

⚠️ 核心要求：你正在创作一部**小说**，请使用小说的叙事语言和文学手法。

{colloquial_style_guide}

📚 写作标准（参考《三体》《流浪地球》等大众科幻作品）：
✅ 必须做到：
- 故事性优先：一切设定服务于故事情节
- **通俗易懂**：面向大众读者，用白话文写作，让普通人都能看懂
- 文学性强：使用生动的叙事语言和文学手法
- 科学融入：科技设定通过对话、情节自然呈现，不堆砌术语
- 沉浸感：让读者身临其境，而不是在读技术文档
- **接地气**：用日常生活中的语言和比喻来解释复杂概念

❌ 严格禁止：
- 学术论文格式（摘要、引言、方法论、参考文献等）
- 纯公式推导或数学方程式罗列
- 面向专业研究者的学术写作风格
- 科研报告式的技术叙述
- 大量术语堆砌而不解释
- **看不懂的专业名词**（如果必须用，要用通俗语言解释）

💡 科幻小说要点：
- 科学设定要用故事讲出来（像刘慈欣的写法）
- 技术细节融入对话、情节、场景描写中
- 复杂概念用通俗易懂的方式解释
- 你的目标读者是科幻爱好者，不是物理学家

"""

        if goal.get("title"):
            goal_section += f"小说标题: {goal['title']}\n"
        if goal.get("genre"):
            goal_section += f"小说类型: {goal['genre']}\n"
        if goal.get("theme"):
            goal_section += f"小说主题: {goal['theme']}\n"
        if goal.get("style"):
            goal_section += f"写作风格: {goal['style']}\n"
        if goal.get("length"):
            goal_section += f"预计篇幅: {goal['length']}\n"
        if goal.get("word_count"):
            word_count = goal['word_count']
            if word_count >= 10000:
                goal_section += f"目标字数: {word_count // 10000}万字\n"
            else:
                goal_section += f"目标字数: {word_count}字\n"
        if goal.get("chapter_count"):
            goal_section += f"章节数量: {goal['chapter_count']}章\n"
        sections.append(goal_section)

        # 🔥 动态获取前置任务内容并构建上下文
        predecessor_contents = self._get_predecessor_contents(task_type, context)
        
        # 🧠 对于复杂任务（章节相关），使用动态上下文选择
        chapter_related_tasks = ["章节大纲", "章节内容", "章节润色", "场景生成"]
        use_dynamic_context = (
            predecessor_contents 
            and task_type in chapter_related_tasks
            and self.config.get("dynamic_context_selection", True)  # 配置开关，默认开启
        )
        
        # 🔴 对于章节相关任务，首先添加基础设定参考（最重要！）
        if task_type in chapter_related_tasks and predecessor_contents:
            foundation_reference = self._build_foundation_reference(predecessor_contents, task_type)
            if foundation_reference:
                sections.append(foundation_reference)
                logger.info(f"🔴 已添加基础设定参考到 {task_type} 的 prompt 中")
        
        if use_dynamic_context:
            # 动态分析需要哪些上下文
            try:
                context_analysis = await self._analyze_context_needs(task, goal, predecessor_contents)
                dynamic_context = self._build_focused_context_section(predecessor_contents, context_analysis)
                logger.info(f"🧠 使用动态上下文选择: 从{len(predecessor_contents)}个上下文中选择了{len(context_analysis.get('selected_contexts', []))}个")
            except Exception as e:
                logger.warning(f"⚠️ 动态上下文选择失败，使用默认方式: {e}")
                dynamic_context = self._build_dynamic_context_section(task_type, predecessor_contents, goal)
            sections.append(dynamic_context)
        elif predecessor_contents:
            # 对于其他任务，使用原有的固定规则
            dynamic_context = self._build_dynamic_context_section(task_type, predecessor_contents, goal)
            sections.append(dynamic_context)

        # Task-specific instruction based on task type
        # ============ Phase 0: 创意脑暴阶段 ============
        if task_type == "创意脑暴":
            genre = goal.get('genre', '科幻')
            task_section = f"""
## 当前任务：{task_type} 🎯

你现在是一个**顶级畅销小说家**，正在为新书进行创意脑暴。

📌 **脑暴目标**：为一部{genre}小说产生 **4 个独特的故事点子**，并从中推荐最佳的一个

### 每个点子必须包含：

1. **故事概念**（2-3句话）
   - 用"如果...会怎样"的方式描述
   - 必须有一个独特的、吸引人的核心设定

2. **核心冲突**
   - 主角面对什么困境/挑战？
   - 什么东西阻止主角得到他想要的？

3. **情感钩子**
   - 这个故事能触动读者什么情感？
   - 为什么读者会在意这个故事？

4. **独特卖点**
   - 这个故事与市面上其他{genre}小说有什么不同？
   - 一句话能让人记住的特点是什么？

5. **潜力评估**（简短）
   - 这个点子适合发展成多长的小说？
   - 可能的受众是谁？

### 脑暴原则

✅ **要做到**：
- 点子要大胆、新奇，不要老套
- 每个点子之间要有差异性，不要太相似
- 想想读者看到这个设定会不会眼前一亮
- 考虑故事的"可展开性"——能支撑起完整的小说吗？

❌ **要避免**：
- 不要写成长篇大纲，每个点子控制在 200-300 字
- 不要学术化，用讲故事的语气
- 不要太平庸，那种"一看就知道结局"的故事不要

### 输出格式

请用以下格式输出（**必须严格按照此格式**）：

---
## 💡 点子一：[一句话概念]

**故事设定**：...

**核心冲突**：...

**情感钩子**：...

**独特卖点**：...

**潜力评估**：...

---
## 💡 点子二：[一句话概念]

**故事设定**：...

**核心冲突**：...

**情感钩子**：...

**独特卖点**：...

**潜力评估**：...

---
## 💡 点子三：[一句话概念]

**故事设定**：...

**核心冲突**：...

**情感钩子**：...

**独特卖点**：...

**潜力评估**：...

---
## 💡 点子四：[一句话概念]

**故事设定**：...

**核心冲突**：...

**情感钩子**：...

**独特卖点**：...

**潜力评估**：...

---
## 🏆 AI推荐

**推荐点子**：点子[X]

**推荐理由**：
（从以下维度分析为什么这个点子最有潜力：新颖程度、情感共鸣、市场潜力、可展开性）

---

⚠️ **重要**：用户将从这4个点子中选择一个作为后续创作的基础，请确保每个点子都有足够的质量和差异性！
"""
        elif task_type == "故事核心":
            # 获取用户选择的点子编号
            selected_idea_info = ""
            if predecessor_contents.get("创意脑暴"):
                brainstorm_content = predecessor_contents["创意脑暴"]
                # 从内容开头提取用户选择的点子
                if brainstorm_content.startswith("【用户选择】点子"):
                    import re
                    match = re.search(r"【用户选择】点子(\d+)", brainstorm_content)
                    if match:
                        selected_num = match.group(1)
                        selected_idea_info = f"""
---
### ⚠️ 重要：用户已选择点子{selected_num}

用户在上一轮创意脑暴中已经选择了「点子{selected_num}」作为本小说的基础。
**你必须基于点子{selected_num}来发展故事核心，不要选择其他点子！**

---
"""
            
            task_section = f"""
## 当前任务：{task_type} 🎯

你是一位畅销小说家，正在进行创作前最关键的一步：**确定故事核心**。

> "每一个伟大的故事都可以用一句话概括。如果你做不到，说明你还不知道自己在写什么。" — 斯蒂芬·金
{selected_idea_info}
---

### 📌 任务说明

基于用户在「创意脑暴」中**选择的点子**，将其打磨成完整的故事核心。

⚠️ **这不是写章节内容！** 这是战略规划阶段，你要确定故事的"心脏"。

---

### 🏆 顶级作家的故事核心法则

**法则一：好故事必须能用一句话说清楚**
- 《教父》：一个黑帮家族的继承人试图让家族合法化，却发现自己变成了比父亲更冷酷的人
- 《三体》：人类发现宇宙并不友善，文明的生存需要做出残酷的选择
- 《肖申克的救赎》：一个被冤枉的银行家用27年证明希望是关不住的

**法则二：故事的动力来自"欲望+阻碍"**
- 主角必须**极度渴望**某样东西
- 必须有**强大的阻碍**让他得不到
- 读者必须**在意**主角能否成功

**法则三：真正抓住读者的是情感，不是设定**
- 科幻设定再酷，没有情感就是技术文档
- 读者记住的是人物的选择和牺牲，不是世界观

---

### 📋 请输出以下内容

#### 一、选择的点子回顾

1. **选中的点子**：[用户选择的点子编号及核心概念]
2. **点子优势**：[这个点子的最大亮点是什么？用 2-3 句话说明]

#### 二、一句话故事（Logline）

用 **30字以内** 概括整个故事，格式：
> "[主角是谁] 必须 [做什么]，否则 [会发生什么后果]，但 [面临什么阻碍]"

写 2-3 个版本，然后选出最好的那个。

#### 三、故事引擎

**1. 主角核心**
| 要素 | 内容 |
|------|------|
| 身份设定 | [简洁说明] |
| 表面欲望 | [故事层面想要什么？] |
| 深层需求 | [主题层面真正需要什么？] |
| 致命缺陷 | [什么弱点会害他？] |

**2. 核心冲突**
- 外部障碍：[谁或什么在阻止主角？]
- 内心挣扎：[主角内心在纠结什么？]
- 赌注是什么：[如果失败会失去什么？这个后果要够重！]

**3. 冲突升级路径**（简述三幕）
- **第一幕**：[打破平衡，进入冒险]
- **第二幕**：[困难加剧，内外交困]
- **第三幕**：[最终抉择，高潮收尾]

#### 四、读者体验设计

1. **情感承诺**：读者读这个故事会体验什么情感？（紧张？感动？震撼？）
2. **核心悬念**：什么问题会让读者一直想知道答案？
3. **共鸣点**：读者会在什么地方产生强烈代入感？

#### 五、主题种子

用一句话描述这个故事想探讨的人生问题：
> "这是一个关于 ______ 的故事"

（例如：关于选择的代价 / 关于人性的复杂 / 关于爱与牺牲）

---

### ❌ 禁止事项

- **禁止写章节内容或正文**，这只是规划阶段
- **禁止长篇大论**，每个部分简洁有力
- **禁止空洞描述**，要具体，让人能"看到"这个故事
- **禁止复制脑暴内容**，要在此基础上深化和聚焦

---

📝 **输出长度**：800-1500字，清晰、结构化、有洞察力
"""
        elif task_type == "风格元素":
            genre = goal.get('genre', '')
            # 科幻类型特别强调通俗易懂
            sci_fi_note = ""
            if genre == "科幻":
                sci_fi_note = """
🔔 **科幻小说特别提醒**：
- 科幻不等于学术论文！要用故事讲科学，不是写科普文章
- 参考《三体》《流浪地球》的写法：科技元素融入情节，而不是堆砌术语
- 让不懂科学的读者也能看懂、也能感动
- 避免大段的技术说明，用对话、情节来展现科技
"""
            
            task_section = f"""
## 当前任务：{task_type} 🎨

你是一位顶级畅销小说家，正在为新书确定**最合适的文学风格**。

> "风格不是装饰，而是讲故事的方式。选错了风格，再好的故事也会被毁掉。" — 斯蒂芬·金

---

### 📌 任务说明

基于前面确定的**故事核心**，定义最能展现这个故事魅力的风格元素。

⚠️ **风格必须服务于故事！** 不同的故事需要不同的讲述方式。

---

### 🏆 顶级作家的风格法则

**法则一：风格要与故事内核匹配**
- 《三体》用冷峻克制的语言讲宇宙的残酷
- 《追风筝的人》用温暖细腻的文字讲救赎
- 《教父》用沉稳老练的笔调讲家族传承

**法则二：风格要考虑目标读者**
- 网文读者喜欢爽快节奏
- 文学读者欣赏精致文字
- 大众读者需要通俗易懂

**法则三：风格要始终如一**
- 一旦确定风格，全书要保持一致
- 风格不一致会让读者出戏
{sci_fi_note}
---

### 📋 请输出以下内容

#### 一、叙事视角选择

1. **选择的视角**：[第几人称？全知/限制/多视角？]
2. **选择理由**：[为什么这个视角最适合讲述这个故事？2-3句话]
3. **参考作品**：[有哪些成功作品用了类似视角？]

#### 二、语言风格定位

1. **风格关键词**：[3个词概括，如"简洁、有力、画面感强"]
2. **具体说明**：
   - 句子长度偏好：长句/短句/混合
   - 用词倾向：口语化/书面化/诗意化
   - 修辞偏好：多用比喻/少用修辞/适度点缀
3. **风格示例**：[写2-3句示例句子，展示这种风格]

⚠️ 必须是**通俗易懂的白话文**！

#### 三、叙事节奏设计

1. **整体节奏**：[快节奏/中速/慢节奏]
2. **节奏变化规律**：
   - 什么时候加速？（紧张场面、动作戏）
   - 什么时候放缓？（情感戏、铺垫）
3. **章节长度倾向**：[长章节/短章节/混合]

#### 四、氛围基调

1. **主导氛围**：[一个词概括，如"紧张""温暖""压抑"]
2. **氛围层次**：
   - 底色氛围：贯穿全书的基调
   - 情绪高点：什么氛围？
   - 情绪低点：什么氛围？

#### 五、文学技巧选择

| 技巧类型 | 使用频率 | 使用场景 |
|---------|---------|---------|
| 对话 | 高/中/低 | 什么时候用？ |
| 内心独白 | 高/中/低 | 什么时候用？ |
| 环境描写 | 高/中/低 | 什么时候用？ |
| 动作场面 | 高/中/低 | 什么时候用？ |
| 闪回/插叙 | 高/中/低 | 什么时候用？ |

---

### ❌ 禁止事项

- 禁止写成小说正文，这是规划阶段
- 禁止堆砌专业术语
- 禁止脱离故事核心空谈风格

📝 **输出长度**：500-800字，清晰、实用
"""
        elif task_type == "主题确认":
            task_section = f"""
## 当前任务：{task_type} 💎

你是一位顶级畅销小说家，正在提炼新书的**核心主题**。

> "主题不是你想讲什么道理，而是故事本身在说什么。好的主题从人物的挣扎中自然涌现。" — 罗伯特·麦基

---

### 📌 任务说明

基于**故事核心、人物和世界观**，提炼这部小说的核心主题。

⚠️ **顶级作家的秘密**：主题不是预设的，而是从故事中**涌现**的。

---

### 🏆 顶级作家的主题法则

**法则一：主题藏在人物的选择里**
- 《教父》主题不是"黑帮"，而是"家族vs个人的挣扎"
- 《三体》主题不是"外星人"，而是"文明的生存选择"
- 《肖申克的救赎》主题是"希望"，通过安迪的行动体现

**法则二：主题要能用一个词/短语概括**
- 复杂的主题不是好主题
- 能一句话说清的主题才有力量

**法则三：主题要引发共鸣，不要说教**
- 让读者自己领悟，而不是灌输
- 通过故事展示，而不是用嘴说

---

### 📋 请输出以下内容

#### 一、主题提炼

1. **核心主题**：用 **5个字以内** 概括
   - 例如：救赎、选择的代价、人性的复杂、爱与牺牲

2. **主题陈述**：用一句话展开（20字以内）
   - 格式："这是一个关于 ______ 的故事"
   - 例如："这是一个关于在绝望中坚守希望的故事"

3. **主题的普世性**
   - 这个主题触及了什么人类共同的困境/渴望？
   - 为什么读者会在意这个主题？

#### 二、主题与故事的关系

1. **主角如何体现主题？**
   - 主角的内心旅程如何与主题呼应？
   - 主角的选择如何揭示主题？

2. **核心冲突如何承载主题？**
   - 冲突的本质与主题有什么关联？

3. **结局如何升华主题？**
   - 故事结局如何回应主题？
   - 读者最终会得到什么启示？

#### 三、主题表达策略

⚠️ **绝对禁止说教！** 主题要通过以下方式自然呈现：

1. **通过人物行动**：哪些行动体现主题？
2. **通过关键对话**：哪些对话触及主题？（不要直接说出主题）
3. **通过场景象征**：哪些场景暗示主题？
4. **通过情节设计**：哪些情节推进主题？

#### 四、主题验证

回答以下问题确认主题成立：
- [ ] 主题是否与故事核心一致？
- [ ] 主题是否能引起读者共鸣？
- [ ] 主题是否避免了说教？
- [ ] 主题是否贯穿了整个故事？

---

### ❌ 禁止事项

- 禁止把主题写成论文观点
- 禁止说教式的表达
- 禁止脱离故事空谈主题

📝 **输出长度**：400-600字
"""
        elif task_type == "市场定位":
            task_section = f"""
## 当前任务：{task_type} 📊

你是一位既懂创作又懂市场的**畅销书作家**，正在为新书做市场定位。

> "写作是艺术，出版是生意。好作家两者都懂。" — 尼尔·盖曼

---

### 📌 任务说明

综合前面所有元素，确定这部小说的**市场定位和商业策略**。

⚠️ **这不是妥协艺术，而是让好故事找到对的读者。**

---

### 🏆 畅销书的市场法则

**法则一：知道你在为谁写**
- 《三体》：硬核科幻爱好者 + 想探索深刻问题的读者
- 《斗破苍穹》：喜欢爽文、追求成长快感的年轻读者
- 《人民的名义》：关注社会现实的中年读者

**法则二：有清晰的卖点**
- 一句话能让人决定是否想看
- 卖点要与众不同

**法则三：了解市场趋势但不盲从**
- 追热点容易过时
- 有独特性才有生命力

---

### 📋 请输出以下内容

#### 一、目标读者画像

1. **核心读者**（最可能喜欢的人）
   - 年龄范围：
   - 性别倾向：
   - 阅读习惯：[网文党/实体书爱好者/碎片化阅读]
   - 阅读场景：[通勤/睡前/周末沉浸]

2. **拓展读者**（可能被吸引的人）
   - 什么人群可能成为潜在读者？

3. **读者需求分析**
   - 他们为什么读这类书？[解压/思考/消遣/寻找共鸣]
   - 他们希望从书中得到什么？

#### 二、市场竞品分析

1. **同类成功作品**（3-5部）
   | 作品名 | 相似点 | 不同点 | 市场表现 |
   |-------|-------|-------|---------|
   | | | | |

2. **本作的差异化优势**
   - 与竞品相比，我们的独特卖点是什么？
   - 读者为什么选我们而不选竞品？

#### 三、卖点提炼

1. **核心卖点**（最打动人的1个）
   - 用一句话概括（15字以内）

2. **支撑卖点**（2-3个）
   - 卖点1：
   - 卖点2：
   - 卖点3：

3. **宣传语设计**
   - 封面宣传语：（一句话，吸引眼球）
   - 简介第一句：（钩子，让人想往下看）

#### 四、发布策略建议

1. **适合的平台/渠道**
   - 首发平台建议：[起点/番茄/微信读书/实体出版...]
   - 理由：

2. **更新节奏建议**（如果是连载）
   - 建议每日/周更新字数：
   - 理由：

3. **营销切入点**
   - 可以借势的话题/热点：
   - 适合的推广方式：

---

### ❌ 禁止事项

- 禁止过度商业化忘记内容
- 禁止不切实际的预期
- 禁止完全脱离已有的故事核心

📝 **输出长度**：500-800字
"""
        elif task_type == "人物设计":
            # 根据字数估算需要的人物数量
            word_count = goal.get("word_count", 50000)
            chapter_count = goal.get("chapter_count", 10)
            genre = goal.get("genre", "通用")
            
            # 根据字数动态调整人物数量 - 长篇需要更多人物来支撑故事
            if word_count >= 1000000:  # 100万字以上
                main_chars = "2-4"
                support_chars = "12-18"
                minor_chars = "25-40"
                char_note = "超长篇需要丰富的人物群像，多条支线需要各自的人物来承载。"
            elif word_count >= 500000:  # 50万字以上
                main_chars = "2-3"
                support_chars = "8-12"
                minor_chars = "15-25"
                char_note = "长篇小说需要足够的人物来支撑复杂的故事线。"
            elif word_count >= 200000:  # 20万字以上
                main_chars = "1-2"
                support_chars = "5-8"
                minor_chars = "10-15"
                char_note = "中长篇需要适量的配角来丰富故事世界。"
            elif word_count >= 100000:  # 10万字以上
                main_chars = "1-2"
                support_chars = "4-6"
                minor_chars = "6-10"
                char_note = "中篇小说人物要精简，每个人物都要有存在价值。"
            else:  # 10万字以下
                main_chars = "1"
                support_chars = "2-4"
                minor_chars = "3-5"
                char_note = "短篇小说人物要少而精，避免角色过多分散焦点。"
            
            task_section = f"""
## 当前任务：{task_type} 🎭

你是一位顶级畅销小说家，正在为新书设计人物。

> "情节是人物的证明。读者不记得情节，但永远记得人物。" — 斯蒂芬·金

---

### 📌 任务说明

⚠️ **重要**：请参考【大纲】中列出的人物列表，为每个人物进行详细设计！

📊 **本书规模**：目标 **{word_count//10000}万字**，共 **{chapter_count}章**
💡 **人物规模建议**：{char_note}

---

### 🏆 顶级作家的人物法则

**法则一：人物即故事**
- 情节不是发生在人物身上的事，而是人物性格导致的必然
- 《教父》的麦克不是被动卷入，是他的性格让他必然成为教父

**法则二：欲望+缺陷=动力**
- 人物必须极度渴望某样东西（欲望）
- 人物必须有阻碍他得到的内在弱点（缺陷）
- 这两者的碰撞产生故事

**法则三：每个人物都认为自己是主角**
- 反派也有他的逻辑和理由
- 配角有自己的人生，不只是主角的工具

---

### 📋 请输出以下内容

---

## 一、主角设计（{main_chars}人）

主角是故事核心的**化身**。设计时必须回答：**为什么必须是他/她来经历这个故事？**

### 主角：[姓名]

#### 1. 基本信息
| 项目 | 内容 |
|-----|------|
| 姓名 | （含名字的含义或由来）|
| 年龄 | |
| 性别 | |
| 身份/职业 | |
| 外貌特征 | （2-3个让人记住的特点）|

#### 2. 性格内核（最重要！）

**人物三角**：
- **想要什么（Want）**：表面目标，故事层面的追求
- **需要什么（Need）**：深层需求，主题层面的真相
- **致命缺陷（Flaw）**：什么性格弱点会阻碍他？

**人物谎言**：
- 主角相信的一个关于世界/自己的错误信念是什么？
- 这个谎言如何影响他的行为？
- 故事中何时/如何打破这个谎言？

#### 3. 人物小传（重要！500-800字）

⚠️ **用故事的方式讲述这个人物的过去**，不要写档案式的条目！

请用叙事的方式描述：
- 他/她的童年是怎样的？（家庭环境、重要经历）
- 什么事件塑造了他/她现在的性格？（关键创伤或转折）
- 在故事开始前，他/她过着怎样的生活？
- 他/她有什么执念或心结？
- 他/她最珍视什么？最害怕什么？

[请写一段500-800字的人物小传，像在讲一个人的故事]

#### 4. 基于世界观的能力（如有）

⚠️ **参考【世界观规则】设计人物能力**，确保能力符合世界规则！

| 项目 | 内容 |
|-----|------|
| 能力名称 | |
| 能力来源 | [根据世界观设定] |
| 能力效果 | |
| 使用限制/代价 | [每个能力都应该有代价] |
| 在故事中的作用 | [这个能力如何推动剧情？] |

**能力设计原则**：
- 能力必须符合世界观规则
- 能力要有明确的限制和代价
- 能力要为故事服务，不是炫技

#### 5. 人物弧光
| 阶段 | 状态 | 触发事件 |
|-----|------|---------|
| 开始 | [性格状态] | - |
| 考验 | [面对什么挑战] | [什么事件] |
| 转变 | [如何改变] | [什么事件] |
| 结局 | [最终状态] | - |

#### 6. 标志性特征
- 口头禅/说话方式：
- 习惯性动作：
- 独特的小细节：

---

## 二、重要配角（{support_chars}人）

⚠️ **配角存在的唯一理由**：推动或阻碍主角的旅程。

### 配角设计模板（每人填写）

**[姓名]** - [一句话定义：身份+与主角的关系]

| 项目 | 内容 |
|-----|------|
| 与主角关系 | [盟友/对手/导师/恋人/镜像] |
| 故事功能 | [这个人物为什么必须存在？] |
| 性格关键词 | [2-3个词] |
| 个人目标 | [他自己想要什么？] |
| 外貌特征 | [1-2个记忆点] |

**人物小传**（200-300字）：
[用叙事方式描述这个人物的背景故事]

**能力设定**（如有，参考世界观规则）：
- 能力：
- 限制/代价：

**配角类型参考**：
- 🤝 **盟友**：帮助主角，但可能有自己的议程
- ⚔️ **对手/反派**：阻碍主角（注意：反派也认为自己是对的）
- 🎓 **导师**：提供智慧或技能，可能需要被超越
- 🪞 **镜像人物**：与主角形成对比，展示另一条路
- 💕 **情感纽带**：给主角提供情感动力

---

## 三、次要人物（{minor_chars}人）

简要列出，每人一行：

| 姓名 | 身份 | 出场章节 | 作用 | 能力（如有）|
|-----|------|---------|-----|----------|
| | | 约第X章 | [一句话说明] | |

---

## 四、人物关系网

用文字描述人物之间的关系：

**主要关系线**：
- [人物A] ←→ [人物B]：[关系性质 + 关系如何变化]
- ...

**隐藏关系**（如果有）：
- [什么关系是隐藏的？什么时候揭示？]

**冲突关系**：
- [谁和谁有冲突？为什么？]

---

## 五、人物出场规划（重要！）

⚠️ **这是给后续章节创作的重要参考**，请认真规划每个人物的出场节奏。

### 章节出场分布表

📊 本书共 **{chapter_count}章**，请规划每个人物在哪些章节出场：

| 人物 | 出场章节（列出所有章节编号） | 首次出场 | 高光章节 | 退场/结局 |
|-----|--------------------------|---------|---------|---------|
| [主角名] | 1-{chapter_count}（全书贯穿） | 第1章 | 第X、X、X章 | 第{chapter_count}章 |
| [配角1] | 第2、5、8、12、...章 | 第2章 | 第X章 | 第X章 |
| [配角2] | 第3、6、9、15章 | 第3章 | 第X章 | - |
| ... | ... | ... | ... | ... |

### 出场规划原则

1. **主角**：应贯穿全书，每章都有出场
2. **重要配角**：出场率约50-70%的章节，要有节奏感
3. **次要人物**：出场率约20-40%的章节，按需出场
4. **过场人物**：仅在必要章节出场

### 人物密度建议

| 章节阶段 | 建议同时在场人物数 | 说明 |
|---------|------------------|-----|
| 开篇（1-3章）| 2-4人 | 建立核心关系 |
| 发展期 | 4-6人 | 逐步引入配角 |
| 高潮期 | 5-8人 | 人物汇聚 |
| 结局 | 3-5人 | 收束 |

---

### ❌ 禁止事项

- 禁止写成档案表格，人物要**活**
- 禁止人物没有缺点（完美人物不真实）
- 禁止配角只是工具人（每个人都有自己的人生）
- 禁止人物数量超出规模建议太多
- 禁止人物出场规划模糊不清（必须明确到具体章节）

📝 **输出长度**：1500-2500字（根据字数规模调整）
"""
        elif task_type == "世界观规则":
            genre = goal.get('genre', '科幻')
            word_count = goal.get("word_count", 50000)
            
            # 根据字数调整世界观复杂度
            if word_count >= 500000:
                complexity = "高复杂度"
                detail_note = "长篇需要完整的世界观体系，但仍需确保读者能理解。"
            elif word_count >= 200000:
                complexity = "中等复杂度"
                detail_note = "中长篇可以有较完整的设定，但要避免设定过载。"
            else:
                complexity = "简洁"
                detail_note = "短中篇世界观要精简，只保留故事必需的设定。"
            
            # 科幻类型特别提醒
            sci_fi_worldview_note = ""
            if genre == "科幻":
                sci_fi_worldview_note = """
🔔 **科幻世界观特别提醒**：
- 世界观是给你自己参考的，不是给读者看的学术论文
- 设定要**能用故事讲出来**，不是干巴巴的规则罗列
- 科技设定要**通俗易懂**，用生活中的比喻来解释
- 参考《三体》：复杂的科学概念用简单的比喻解释（如"二向箔像一张纸"）
"""
            
            task_section = f"""
## 当前任务：{task_type} 🌍

你是一位顶级畅销小说家，正在为新书构建**完整的故事世界**。

> "世界观的目的不是展示你有多聪明，而是让故事发生在一个让人信服的地方。" — 布兰登·桑德森

---

### 📌 任务说明

基于**故事核心和大纲**，构建一个**完整、独特、有特色**的世界。

📊 **本书规模**：{word_count//10000}万字 → 世界观复杂度：**{complexity}**
💡 {detail_note}
{sci_fi_worldview_note}

⚠️ **重要**：
1. 世界观要**完整详细**，是后续人物设计和章节创作的基础！
2. 世界要有**独特/特殊的部分**，让故事有新鲜感！
3. 设计要服务于故事，但也要足够详细，让创作有据可依！

---

### 🏆 顶级作家的世界观法则

**法则一：冰山理论**
- 作者要知道100%，但只展示给读者10-20%
- 设定在后台支撑，不要全部塞给读者

**法则二：设定要能被打破**
- 最精彩的情节往往是打破/利用世界规则
- 《三体》的水滴打破了人类的自信

**法则三：设定通过故事展现**
- 不要写百科全书，要通过人物的经历展示世界
- 读者通过人物的眼睛看世界

---

### 📋 请输出以下内容

---

## 一、世界基础设定

### 1. 时空背景
| 项目 | 设定 | 对故事的影响 |
|-----|------|------------|
| 时代 | [什么年代/纪元] | |
| 地点 | [主要发生在哪里] | |
| 历史背景 | [重要的历史事件] | |
| 与现实的差异 | [一句话说明] | |

### 2. 社会结构
| 项目 | 设定 |
|-----|------|
| 政治体制 | [什么样的政府/统治方式] |
| 社会阶层 | [有哪些阶层？如何划分？] |
| 经济体系 | [使用什么货币？经济模式？] |
| 文化习俗 | [重要的节日、礼仪、禁忌] |

### 3. 主角的位置
- 主角在这个社会中处于什么位置？
- 什么社会因素会成为故事的阻力？

---

## 二、世界的独特/特殊之处（重要！）

⚠️ **这是让你的世界与众不同的关键！** 每个好的世界都有独特的设定。

### 🌟 特殊设定1：[名称]

**设定内容**（详细描述）：
[这个特殊设定是什么？详细说明]

**运作规则**：
- 这个设定是如何运作的？
- 有什么限制和代价？
- 谁可以使用/获得？

**对故事的影响**：
- 这个设定如何推动剧情？
- 主角如何与这个设定互动？

**展示方式**：
- 如何在故事中自然展示这个设定？
- 在哪些章节重点展现？

---

### 🌟 特殊设定2：[名称]

[同上格式]

---

### 🌟 特殊设定3：[名称]

[同上格式]

---

## 三、核心规则体系

### 1. 这个世界与现实的关键差异

| 差异点 | 具体设定 | 如何在故事中呈现 |
|-------|---------|---------------|
| | | 通过什么场景/对话展示 |
| | | |
| | | |

### 2. 能力/魔法/科技体系（如有）

⚠️ **这是人物设计能力的基础！**

| 项目 | 内容 |
|-----|------|
| 体系名称 | |
| 能力来源 | [能力从哪里来？] |
| 激活/获得条件 | [如何获得这种能力？] |
| 能力等级 | [有没有等级划分？] |
| 使用代价 | [使用能力要付出什么？] |
| 能力限制 | [什么是做不到的？] |

**能力分类**（如有多种能力）：
| 能力类型 | 效果 | 获得方式 | 限制 |
|---------|-----|---------|-----|
| | | | |

### 3. 核心规则（最多5条）

每条规则必须回答：
- 规则是什么？
- 为什么需要这条规则？（对故事有什么用）
- 这条规则能怎么被利用/打破？

| 规则 | 内容 | 故事功能 | 可能的破例 |
|-----|------|---------|----------|
| 1 | | | |
| 2 | | | |
| 3 | | | |

---

## 四、日常生活细节

描述普通人在这个世界的日常：

| 方面 | 设定 |
|-----|------|
| 衣 | [人们穿什么？有什么讲究？] |
| 食 | [吃什么？有什么特色食物？] |
| 住 | [住在什么样的地方？] |
| 行 | [如何出行？交通工具？] |
| 娱乐 | [人们如何消遣？] |
| 工作 | [主要的职业有哪些？] |

---

## 五、重要组织/势力

列出故事中会出现的主要势力：

### 势力1：[名称]
| 项目 | 内容 |
|-----|------|
| 性质 | [政府/帮派/公司/门派...] |
| 核心理念/目标 | |
| 实力规模 | |
| 与主角的关系 | |
| 内部结构 | |

### 势力2：[名称]
[同上]

---

## 六、世界观词典

列出这个世界的专有名词（10-20个）：

| 名词 | 解释（用比喻或日常语言） | 首次出现时机 |
|-----|----------------------|------------|
| | | 约第X章 |

---

## 七、与故事核心的关联

请明确说明：

1. **世界观如何服务于核心冲突？**
   - 主角面临的外部阻碍来自这个世界的什么方面？

2. **世界观如何强化主题？**
   - 这个世界的设定如何体现故事想探讨的问题？

3. **世界观如何为人物提供舞台？**
   - 人物如何在这个世界中行动？

---

### ❌ 禁止事项

- ❌ 写成百科全书式的设定集
- ❌ 罗列大量与故事无关的细节
- ❌ 使用学术论文的语气
- ❌ 创造复杂的术语体系让读者困惑
- ❌ 设定没有代价/限制（太完美的设定没有戏剧性）
- ❌ 世界太普通，没有特殊/独特的地方

📝 **输出长度**：1500-3000字（根据复杂度调整）

⚠️ **重要提醒**：
1. 必须详细设计**特殊/独特的世界设定**！
2. 所有设定都要用**白话文**描述！
3. 这份世界观是后续人物能力设计的基础！
"""
        elif task_type in ["事件设定", "事件"]:
            chapter_count = goal.get("chapter_count", 10)
            word_count = goal.get("word_count", 50000)
            
            # 根据章节数调整事件数量
            if chapter_count >= 30:
                event_count = "10-15"
            elif chapter_count >= 15:
                event_count = "7-10"
            else:
                event_count = "5-8"
                
            task_section = f"""
## 当前任务：{task_type} ⚡

你是一位顶级畅销小说家，正在为新书规划**关键转折事件**。

> "故事就是一系列有因果关系的事件，每个事件都让情况变得更好或更糟。" — 罗伯特·麦基

---

### 📌 任务说明

设计推动故事发展的**核心转折事件**。

📊 **本书规模**：{chapter_count}章，约{word_count//10000}万字
💡 **建议事件数**：{event_count}个关键转折点

---

### 🏆 顶级作家的事件法则

**法则一：事件必须改变现状**
- 好的事件让事情变得更好或更糟，不能是无关紧要的
- 每个事件后，人物的处境必须不同于之前

**法则二：事件必须有因果关系**
- 事件A导致事件B，事件B导致事件C
- 不是"然后发生了..."，而是"因为...所以..."

**法则三：事件要考验人物**
- 好的事件迫使人物做出选择
- 选择揭示性格，性格决定命运

---

### 📋 请输出以下内容

---

## 一、核心冲突定义

**主要矛盾**：
1. **冲突本质**：[一句话概括]
2. **冲突双方**：[谁vs谁/什么]
3. **赌注**：[如果失败会失去什么？要够重！]
4. **为何难解**：[为什么不能轻易解决？]

---

## 二、故事结构（三幕式）

### 第一幕：建立 → 进入（约占20%，第1-{max(1, chapter_count//5)}章）

**目标**：建立世界、人物、日常，然后打破日常

| 事件 | 章节 | 功能 | 描述 |
|-----|-----|-----|-----|
| 开场状态 | 第1章 | 展示日常 | |
| 触发事件 | 第X章 | 打破日常 | |
| 跨越门槛 | 第X章 | 进入主线 | |

### 第二幕：对抗 → 升级（约占60%，第{max(2, chapter_count//5+1)}-{max(3, int(chapter_count*0.8))}章）

**目标**：冲突升级，人物成长，困难加剧

| 事件 | 章节 | 功能 | 描述 |
|-----|-----|-----|-----|
| 第一考验 | 第X章 | 初次挫折 | |
| 小胜利 | 第X章 | 虚假希望 | |
| 中点反转 | 约第{chapter_count//2}章 | 重大转折 | |
| 困境加深 | 第X章 | 形势恶化 | |
| 黑暗时刻 | 第X章 | 最低谷 | |

### 第三幕：决战 → 结局（约占20%，第{max(4, int(chapter_count*0.8)+1)}-{chapter_count}章）

| 事件 | 章节 | 功能 | 描述 |
|-----|-----|-----|-----|
| 觉醒/准备 | 第X章 | 重新振作 | |
| 最终对决 | 第X章 | 高潮 | |
| 结局 | 第{chapter_count}章 | 收尾 | |

---

## 三、关键转折事件详解（{event_count}个）

每个事件详细描述：

### 事件1：[事件名称]

| 项目 | 内容 |
|-----|------|
| 发生章节 | 约第X章 |
| 事件类型 | [触发/发展/转折/高潮/结局] |
| 参与人物 | |

**事件描述**（100-150字）：
[具体发生什么]

**因果关系**：
- 因为什么导致这个事件？
- 这个事件导致什么后果？

**人物选择**：
- 主角必须做什么选择？
- 这个选择揭示了什么性格？

**情绪效果**：
- 读者会有什么感受？

---

### 事件2：[事件名称]
[同上格式...]

---

## 四、支线冲突（2-3条）

| 支线 | 涉及人物 | 与主线关系 | 起止章节 |
|-----|---------|----------|---------|
| | | [平行/辅助/对照] | 第X-X章 |

---

## 五、事件时间线总览

| 章节 | 主线事件 | 支线事件 | 情绪曲线 |
|-----|---------|---------|---------|
| 1 | | | ⬛⬛⬛⬜⬜ |
| 2 | | | |
| ... | | | |
| {chapter_count} | | | |

---

### ❌ 禁止事项

- 禁止事件之间没有因果关系
- 禁止事件不改变现状
- 禁止所有事件都是打斗/灾难（要有情感戏）
- 禁止写成小说正文

📝 **输出长度**：1200-2000字
"""
        elif task_type == "伏笔列表":
            chapter_count = goal.get("chapter_count", 10)
            word_count = goal.get("word_count", 50000)
            
            # 根据章节数/字数调整伏笔数量
            if chapter_count >= 30:
                main_foreshadow = "5-8"
                char_foreshadow = "2-3"
            elif chapter_count >= 15:
                main_foreshadow = "4-6"
                char_foreshadow = "1-2"
            else:
                main_foreshadow = "3-4"
                char_foreshadow = "1"
                
            task_section = f"""
## 当前任务：{task_type} 🔮

你是一位顶级畅销小说家，正在为新书设计**伏笔系统**。

> "伏笔是作者与读者之间的秘密游戏——埋下时不动声色，揭晓时恍然大悟。" — 阿加莎·克里斯蒂

---

### 📌 任务说明

设计故事中的**伏笔网络**——那些看似不经意的细节，在后文中会产生重要意义。

📊 **本书规模**：{chapter_count}章，约{word_count//10000}万字
💡 **建议伏笔数**：主线伏笔{main_foreshadow}个，人物伏笔每人{char_foreshadow}个

---

### 🏆 顶级作家的伏笔法则

**法则一：伏笔要"藏在眼皮底下"**
- 最好的伏笔是读者看到了但没当回事
- 可以藏在对话中、环境描写中、角色习惯中
- 例：《哈利波特》中斯内普对莉莉的感情线索

**法则二：揭晓要有"啊哈！"时刻**
- 读者看到揭晓时应该有恍然大悟的感觉
- 回看时能发现所有线索都在那里
- 不能太早揭晓（失去悬念）也不能太晚（读者忘了）

**法则三：伏笔必须回收**
- 埋下的伏笔一定要揭示，否则是欺骗读者
- 每个伏笔的回收要有足够的冲击力
- 多个伏笔可以连锁揭示，制造高潮

---

### 📋 请输出以下内容

---

## 一、主线伏笔（{main_foreshadow}个）

这些伏笔直接关系到故事核心，揭示时会产生重大剧情转折。

### 伏笔1：[伏笔名称]

| 项目 | 内容 |
|-----|------|
| 伏笔内容 | [什么细节/台词/物品/行为] |
| 真正含义 | [这个细节背后的真相是什么] |

**埋设设计**：
- 埋设位置：第X章，[什么场景]
- 埋设方式：[对话/描写/行动/背景]
- 伪装技巧：[如何让读者看到但不起疑]

**揭示设计**：
- 揭示位置：第X章，[什么事件中]
- 揭示方式：[如何揭晓真相]
- 冲击效果：[读者会有什么反应]

**线索链**：
- 第一次暗示（埋设）：第X章
- 第二次呼应（强化）：第X章
- 最终揭示：第X章

---

### 伏笔2：[伏笔名称]
[同上格式...]

---

## 二、人物伏笔

每个主要人物的隐藏信息：

| 人物 | 隐藏内容 | 伏笔类型 | 埋设章节 | 揭示章节 | 揭示影响 |
|-----|---------|---------|---------|---------|---------|
| | | [身份/动机/秘密/能力/关系] | 第X章 | 第X章 | |

**人物伏笔详解**（选2-3个重要的展开）：

### [人物名]的隐藏

**伏笔内容**：
- 隐藏的是什么：
- 为什么要隐藏：

**埋设线索**：
1. 第X章：[什么细节暗示]
2. 第X章：[什么行为可疑]
3. 第X章：[什么对话有深意]

**揭示时刻**：
- 如何揭晓：
- 对其他人物的影响：
- 对剧情的影响：

---

## 三、世界观伏笔（2-3个）

关于设定的隐藏规则，后面会变得重要：

| 伏笔 | 表面理解 | 真正含义 | 埋设/揭示 |
|-----|---------|---------|----------|
| | [读者一开始以为] | [实际上是] | 第X/X章 |

---

## 四、红鲱鱼（1-2个）

故意误导读者的假线索：

| 误导内容 | 让读者以为 | 实际真相 | 揭穿章节 | 设计目的 |
|---------|----------|---------|---------|---------|
| | | | 第X章 | [转移注意力/制造意外] |

---

## 五、伏笔时间线

| 章节 | 埋设的伏笔 | 呼应/强化 | 揭示的伏笔 |
|-----|----------|----------|----------|
| 第1章 | | | |
| 第2章 | | | |
| ... | | | |
| 第{chapter_count}章 | | | |

---

## 六、伏笔关联图

```
伏笔A ─────┐
          ├──→ 揭示X（第Y章）──→ 连锁揭示
伏笔B ─────┘
         ↑
伏笔C ────┘
```

**关联说明**：
- [伏笔A]和[伏笔B]互相印证
- [伏笔C]的揭示触发[伏笔D]的揭示

---

### ❌ 禁止事项

- 禁止伏笔埋了不揭示
- 禁止揭示时机不当（太早或太晚）
- 禁止伏笔太明显（读者一看就猜到）
- 禁止伏笔和主线无关

📝 **输出长度**：1000-1500字
"""
        elif task_type == "场景物品冲突":
            word_count = goal.get("word_count", 50000)
            chapter_count = goal.get("chapter_count", 10)
            # 根据字数估算场景数量
            if word_count >= 500000:
                scene_count = "20-30"
                item_count = "10-15"
                core_scene = "5-8"
            elif word_count >= 200000:
                scene_count = "15-20"
                item_count = "8-12"
                core_scene = "4-6"
            elif word_count >= 100000:
                scene_count = "10-15"
                item_count = "6-10"
                core_scene = "3-5"
            else:
                scene_count = "8-12"
                item_count = "5-8"
                core_scene = "2-4"
                
            task_section = f"""
## 当前任务：{task_type} 🏔️

你是一位顶级畅销小说家，正在为新书设计**场景系统、重要道具和冲突层次**。

> "场景不只是故事发生的地方，它本身就是故事的一部分，像另一个角色一样影响着情节。" — 斯蒂芬·金

---

### 📌 任务说明

设计故事的**舞台**——场景让世界观有血有肉，道具推动剧情发展，冲突制造戏剧张力。

📊 **本书规模**：{chapter_count}章，约{word_count//10000}万字
💡 **建议数量**：核心场景{core_scene}个，总场景{scene_count}个，关键道具{item_count}个

---

### 🏆 顶级作家的场景法则

**法则一：场景要有"性格"**
- 好的场景有自己的气质，影响人物的行为和情绪
- 同一个场景在不同情境下可以呈现不同面貌
- 例：《了不起的盖茨比》中的码头绿灯

**法则二：道具要有"分量"**
- 关键道具应该多次出现，每次出现都有意义
- 道具的归属变化可以推动剧情
- 例：《教父》中的橙子，《哈利波特》中的魂器

**法则三：冲突要有"层次"**
- 外部冲突（人vs人/环境/命运）
- 内部冲突（人vs自己）
- 两种冲突互相影响，层层递进

---

### 📋 请输出以下内容

---

## 一、核心场景（{core_scene}个）

故事最重要的发生地，会反复出现。

### 场景1：[场景名称]

| 项目 | 内容 |
|-----|------|
| 地理位置 | |
| 重要程度 | ⭐⭐⭐⭐⭐ |
| 出现章节 | 第X、X、X章 |

**环境细节**（五感描写）：
- 👁️ 视觉：[看到什么？光线、颜色、布局]
- 👂 听觉：[有什么声音？]
- 👃 嗅觉：[有什么气味？]
- ✋ 触觉：[温度、质感？]
- 🌟 特殊元素：[独特的标志性事物]

**氛围变化**：
| 情境 | 氛围描写 |
|-----|---------|
| 日常状态 | |
| 紧张时刻 | |
| 高潮场景 | |

**叙事功能**：
- 会发生的事件：
- 与人物的关系：
- 象征意义：

---

### 场景2：[场景名称]
[同上格式...]

---

## 二、重要场景（5-8个）

关键事件发生地：

| 场景名 | 简述 | 氛围关键词 | 关联事件 | 出场章节 |
|-------|-----|----------|---------|---------|
| | | | | 第X章 |

**每个场景的一句话描写**：
1. [场景名]：[一句话画面感描写]
2. ...

---

## 三、过渡场景（5-10个）

连接场景、日常场景：

| 场景名 | 场景类型 | 用途 | 简述 |
|-------|---------|-----|-----|
| | [街道/交通/公共场所] | | |

---

## 四、关键道具（{item_count}个）

### 道具1：[道具名称]

| 项目 | 内容 |
|-----|------|
| 外观 | [大小、形状、材质、颜色] |
| 来源 | [从哪来的？有什么历史？] |
| 功能 | [能做什么？有什么限制？] |

**剧情作用**：
- 首次出现：第X章，[情境]
- 关键使用：第X章，[如何推动剧情]
- 归属变化：[谁拥有 → 谁拥有]

**道具时间线**：
| 章节 | 状态 | 持有者 |
|-----|-----|-------|
| 第X章 | 出现 | |
| 第X章 | 使用 | |
| 第X章 | 结局 | |

---

### 道具2：[道具名称]
[同上格式...]

---

## 五、象征物品（2-3个）

| 物品 | 象征含义 | 出场时机 | 与主题关系 |
|-----|---------|---------|----------|
| | | 第X、X章 | |

---

## 六、冲突层次设计

### 外部冲突

**人与人**：
| 冲突方A | 冲突方B | 冲突焦点 | 激化节点 | 解决/结果 |
|--------|--------|---------|---------|----------|
| | | | 第X章 | |

**人与环境**：
- 自然环境挑战：
- 社会环境压力：

**人与命运**：
- 不可抗力：
- 宿命感元素：

### 内部冲突

| 人物 | 内心矛盾 | 外在表现 | 转变节点 |
|-----|---------|---------|---------|
| | [想要A vs 需要B] | | 第X章 |

### 冲突升级曲线

```
第1章 ⬜⬜⬜⬜⬜ 平静
第X章 ⬛⬜⬜⬜⬜ 萌芽
第X章 ⬛⬛⬜⬜⬜ 发展
第X章 ⬛⬛⬛⬜⬜ 激化
第X章 ⬛⬛⬛⬛⬜ 爆发
第X章 ⬛⬛⬛⬛⬛ 高潮
第{chapter_count}章 ⬛⬛⬜⬜⬜ 解决
```

---

## 七、场景-事件-人物对照表

| 事件 | 场景 | 人物 | 道具 | 章节 |
|-----|-----|-----|-----|-----|
| | | | | 第X章 |

---

### ❌ 禁止事项

- 禁止场景描写空洞无特色
- 禁止道具出现后不再使用
- 禁止冲突平铺直叙不升级
- 禁止场景与剧情无关

📝 **输出长度**：1500-2500字
"""
        elif task_type == "大纲":
            chapter_count = goal.get('chapter_count', 20)
            word_count = goal.get('word_count', 50000)
            words_per_chapter = word_count // max(chapter_count, 1)
            
            # 根据字数显示
            if word_count >= 10000:
                word_display = f"{word_count // 10000}万字"
            else:
                word_display = f"{word_count}字"
            
            task_section = f"""
## 当前任务：{task_type} 📋

你是一位顶级畅销小说家，正在为新书创建**完整故事大纲**。

> "大纲是故事的骨架，它决定了一本书能否站起来。好的大纲让写作变得顺畅，差的大纲让写作变成噩梦。" — 詹姆斯·斯科特·贝尔

---

### 📌 重要约束 - 必须遵守

| 项目 | 要求 |
|-----|------|
| 总字数 | **{word_display}** |
| 章节数 | **正好 {chapter_count} 章**（不多不少！） |
| 每章字数 | 约 **{words_per_chapter}** 字 |

⚠️ **你必须规划正好 {chapter_count} 章！**

---

### 🏆 顶级作家的大纲法则

**法则一：每一章都有"钩子"**
- 章节开头要抓住读者，结尾要让读者想继续
- 最好的章节结尾是：问题解决了一半，新问题又来了

**法则二：中点反转是关键**
- 故事中点（约第{chapter_count//2}章）必须有重大转折
- 中点前是"追逐"，中点后是"被追"

**法则三：黑暗时刻必不可少**
- 在高潮前（约第{int(chapter_count*0.75)}章），主角要到最低谷
- 黑暗时刻越深，高潮越有力

---

### 📋 请输出以下内容

---

## 一、故事完整概览（重要！）

### 1. 一句话概括（Logline）
[用一句话概括整个故事：谁+想要什么+面临什么阻碍+赌注是什么]

### 2. 故事梗概（500-800字）
用**吸引人的方式**概述整个故事，从开始到结束。这段话要能让人读完就想看这本书！

**开端**：（100-150字）
[故事开始时的状态，主角是谁，世界是怎样的]

**发展**：（200-300字）
[主角遭遇什么变故，如何一步步深入困境，遇到了谁，经历了什么]

**高潮**：（100-150字）
[最大的冲突如何爆发，主角做出什么选择]

**结局**：（100-150字）
[故事如何收尾，主角最终的命运]

---

## 二、需要的人物列表（重要！人物设计任务将基于此）

⚠️ **请列出这个故事需要的所有人物**，后续【人物设计】任务会基于这个列表详细设计每个人物。

### 主要人物（1-3人）
| 人物代号 | 身份/角色 | 在故事中的作用 | 重要章节 |
|---------|---------|--------------|---------|
| [暂定名/代号] | [是什么人] | [推动什么情节] | 第X-X章 |

### 重要配角（3-8人）
| 人物代号 | 身份/角色 | 与主角关系 | 在故事中的作用 |
|---------|---------|----------|--------------|
| | | | |

### 次要人物（5-15人）
| 人物代号 | 身份 | 出场章节 | 作用 |
|---------|-----|---------|-----|
| | | 约第X章 | |

---

## 三、三幕结构总览

### 第一幕：建立与进入（第1-{max(1, chapter_count//5)}章，约占20%）

| 章节 | 功能 | 一句话描述 |
|-----|------|----------|
| 第1章 | 日常展示 | |
| 第X章 | 触发事件 | |
| 第X章 | 跨越门槛 | |

**第一幕要完成**：
- 读者了解主角是谁
- 读者关心主角的目标
- 故事正式开始

### 第二幕：对抗与发展（第{max(2, chapter_count//5+1)}-{max(3, int(chapter_count*0.8))}章，约占60%）

| 章节 | 功能 | 一句话描述 |
|-----|------|----------|
| 第X章 | 第一考验 | |
| 第X章 | 小胜利 | |
| 第{chapter_count//2}章 | **中点反转** | |
| 第X章 | 困境加深 | |
| 第{int(chapter_count*0.75)}章 | **黑暗时刻** | |

**第二幕要完成**：
- 冲突不断升级
- 人物成长变化
- 赌注越来越高

### 第三幕：高潮与结局（第{max(4, int(chapter_count*0.8)+1)}-{chapter_count}章，约占20%）

| 章节 | 功能 | 一句话描述 |
|-----|------|----------|
| 第X章 | 觉醒/准备 | |
| 第X章 | 最终对决 | |
| 第{chapter_count}章 | 结局 | |

**第三幕要完成**：
- 主要冲突解决
- 主题得到升华
- 人物完成蜕变

---

## 四、详细章节规划

⚠️ **必须规划全部 {chapter_count} 章，每章都要详细！**

### 第1章：[章节标题]

| 项目 | 内容 |
|-----|------|
| 叙事功能 | [这章要完成什么] |
| 情绪曲线 | [平静→紧张/开心→失落...] |

**章节概要**（100-150字）：
[具体发生什么]

**出场人物**：
- 主要：
- 次要：

**场景**：
- 场景1：
- 场景2：

**关键事件**：
-

**伏笔操作**：
- 埋设：
- 揭示：

**章节结尾钩子**：
[留下什么悬念让读者继续？]

---

### 第2章：[章节标题]
[同上格式...]

### 第3章：[章节标题]
[继续...]

...

### 第{chapter_count}章：[章节标题]
[最后一章]

---

## 四、人物出场规划

| 人物 | 首次出场 | 重要章节 | 关键变化 |
|-----|---------|---------|---------|
| | 第X章 | 第X、X、X章 | 第X章[什么变化] |

---

## 五、伏笔埋设与揭示

| 伏笔 | 埋设 | 强化 | 揭示 |
|-----|-----|-----|-----|
| | 第X章 | 第X章 | 第X章 |

---

## 六、情绪节奏图

```
第1章  ⬛⬛⬜⬜⬜ 平静开场
第X章  ⬛⬛⬛⬜⬜ 触发事件
第X章  ⬛⬛⬛⬛⬜ 上升行动
第{chapter_count//2}章  ⬛⬛⬛⬛⬛ 中点高潮
第X章  ⬛⬛⬜⬜⬜ 反转低落
第{int(chapter_count*0.75)}章  ⬛⬜⬜⬜⬜ 黑暗时刻
第X章  ⬛⬛⬛⬛⬜ 重新振作
第{chapter_count}章  ⬛⬛⬛⬛⬛ 最终高潮
```

---

## 七、主题贯穿

| 阶段 | 章节 | 主题如何体现 |
|-----|-----|-------------|
| 提出 | 第X章 | |
| 质疑 | 第X章 | |
| 否定 | 第X章 | |
| 升华 | 第X章 | |

---

### ✅ 检查清单

- [ ] 章节数正好是 **{chapter_count}** 章
- [ ] 每章都有明确的叙事功能
- [ ] 中点反转设计有力
- [ ] 黑暗时刻足够低
- [ ] 所有人物有出场安排
- [ ] 所有伏笔有埋设和揭示
- [ ] 章节之间衔接流畅
- [ ] 整体节奏有起有伏

📝 **输出长度**：2000-4000字（根据章节数调整）
"""
        elif task_type == "章节大纲":
            chapter_index = task.metadata.get("chapter_index", "未知")
            chapter_count = goal.get("chapter_count", 10)
            word_count = goal.get("word_count", 50000)
            words_per_chapter = word_count // max(chapter_count, 1)
            
            # 🔥 获取前面章节内容，构建连贯性上下文
            chapter_continuity = ""
            if isinstance(chapter_index, int) and chapter_index > 1:
                previous_chapters = await self._get_previous_chapters(chapter_index, context, max_chapters=2)
                outline_content = predecessor_contents.get("大纲", "")
                chapter_continuity = self._build_chapter_continuity_context(
                    chapter_index, previous_chapters, outline_content
                )
            
            task_section = f"""
{chapter_continuity}

## 当前任务：第{chapter_index}章 - 详细章节大纲 📝

你是一位顶级畅销小说家，正在为第{chapter_index}章创建**详细写作蓝图**。

> "好的章节像一部微型电影——有开场、有发展、有高潮、有余韵。每一章都应该让读者感到值得。" — 布兰登·桑德森

---

### ⚠️ 连贯性要求（第{chapter_index}章必须做到）

{"**这是第一章**，是故事的开端。需要：引入主角、建立世界、制造钩子。" if chapter_index == 1 else f"**必须承接第{chapter_index-1}章的结尾**！开场要从上一章结束的地方自然过渡，不能像另一个故事。"}

---

### 📌 章节信息

| 项目 | 内容 |
|-----|------|
| 章节位置 | 第 **{chapter_index}** / {chapter_count} 章 |
| 目标字数 | 约 **{words_per_chapter}** 字 |
| 建议场景数 | **4-6** 个场景 |

---

### 🏆 顶级作家的章节法则

**法则一：开头要抓人**
- 前100字必须让读者想继续读
- 可以用悬念、冲突、有趣的画面开场

**法则二：每个场景要有"转变"**
- 进入场景时的状态 ≠ 离开时的状态
- 信息变了、关系变了、或情绪变了

**法则三：结尾要有钩子**
- 章节结尾要让读者舍不得放下书
- 可以用悬念、转折、或情感冲击

---

### 📋 请输出以下内容

---

## 一、章节概览

**章节标题**：[吸引人的标题]

| 项目 | 内容 |
|-----|------|
| 叙事阶段 | [开端/发展/高潮/收尾] |
| 主要POV | [谁的视角] |
| 情绪基调 | [紧张/温馨/压抑/...] |

**本章目标**（必须完成）：
1. 📖 情节目标：[推进什么剧情]
2. 👤 人物目标：[展现/发展谁]
3. 💡 信息目标：[告诉读者什么]
4. 💗 情感目标：[让读者感到什么]

---

## 二、场景分解（4-6个场景）

### 场景1：[场景名/一句话概括]

| 项目 | 内容 |
|-----|------|
| 地点 | [参考【场景物品冲突】] |
| 时间 | [具体时间/天气] |
| 氛围 | [一个词概括] |

**出场人物**：
| 人物 | 状态 | 这场景的目标 |
|-----|-----|-------------|
| | [情绪/状态] | [想要什么] |

**场景内容**（200-300字）：

**开场**：
[如何进入这个场景？第一个画面是什么？]

**发展**：
[发生什么？对话/行动的要点]

**冲突/转变**：
[这个场景的张力点是什么？发生了什么变化？]

**结束**：
[如何过渡到下一场景？]

**关键对话要点**：
- [对话1要传达的信息]
- [对话2要传达的信息]

---

### 场景2：[场景名]
[同上格式...]

### 场景3：[场景名]
[同上格式...]

### 场景4：[场景名]
[同上格式...]

（继续到4-6个场景...）

---

## 三、伏笔操作

**本章埋设**：
| 伏笔 | 埋设方式 | 将在哪揭示 |
|-----|---------|----------|
| | [对话/描写/行动] | 第X章 |

**本章揭示**：
| 伏笔 | 揭示方式 | 读者反应 |
|-----|---------|---------|
| | | [恍然大悟/震惊/感动] |

---

## 四、情绪节奏

**本章情绪曲线**：

```
开头 [情绪] ──→ 场景2 [情绪] ──→ 中间 [情绪] ──→ 场景4 [情绪] ──→ 结尾 [情绪]
         ↗︎              ↘︎                ↗︎              ↘︎
```

**节奏控制**：
| 场景 | 节奏 | 原因 |
|-----|-----|-----|
| 场景1 | 快/中/慢 | |
| 场景2 | | |
| ... | | |

---

## 五、章节衔接

**承上**：
- 时间：[紧接上章/过了X时间]
- 情绪：[延续/转换]
- 信息：[承接什么]

**启下**：
- 悬念：[留下什么钩子]
- 铺垫：[为下章埋什么线]

---

## 六、写作备忘

**必须写好**：
- [本章最重要的场景/对话]

**避免问题**：
- [需要注意的一致性]

---

### ❌ 禁止事项

- 禁止场景之间跳跃突兀
- 禁止章节没有情绪起伏
- 禁止开头平淡无味
- 禁止结尾没有钩子

📝 **输出长度**：800-1200字
"""
        elif task_type == "场景生成":
            chapter_index = task.metadata.get("chapter_index", "未知")
            scene_index = task.metadata.get("scene_index", "未知")
            task_section = f"""
## 当前任务：第{chapter_index}章 - 场景{scene_index} 🎬

你是一位顶级畅销小说家，正在创作第{chapter_index}章的场景{scene_index}。

> "好的场景就像电影画面，读者能'看到'发生了什么。" — 詹姆斯·斯科特·贝尔

---

### 📌 场景写作要求

**核心原则**：让读者身临其境

**必须包含**：
1. **环境渲染**：用五感细节（视/听/嗅/触/味）营造氛围
2. **人物动作**：具体的行动而非笼统的描述
3. **自然对话**：符合人物性格，推动剧情
4. **情绪张力**：场景要有起伏和变化

---

### 🏆 顶级作家的场景法则

**法则一：进入场景要快**
- 直接进入动作或对话
- 不要用大段环境描写开场

**法则二：展示而非告诉**
- ❌ "他很紧张"
- ✅ "他的手指不自觉地敲着桌面，目光在门口和窗户之间来回游移"

**法则三：对话要有潜台词**
- 人物说的不一定是想的
- 对话背后要有情感和目的

---

### ❌ 禁止事项

- 禁止标注"场景X"等标记
- 禁止大段心理独白
- 禁止对话无意义的寒暄
- 禁止纯描写无动作
- 禁止违反已设定的人物性格

📝 **输出**：直接输出小说正文，800-1500字
"""
        elif task_type == "章节内容":
            chapter_index = task.metadata.get("chapter_index", "未知")
            # 计算每章目标字数
            word_count = goal.get("word_count", 50000)
            chapter_count = goal.get("chapter_count", 10)
            words_per_chapter = word_count // chapter_count
            # 设置合理的范围
            min_words = max(2000, int(words_per_chapter * 0.8))
            max_words = int(words_per_chapter * 1.2)
            
            # 🔥 获取前面章节内容，构建连贯性上下文
            chapter_continuity = ""
            if isinstance(chapter_index, int) and chapter_index > 1:
                previous_chapters = await self._get_previous_chapters(chapter_index, context, max_chapters=2)
                outline_content = predecessor_contents.get("大纲", "")
                chapter_continuity = self._build_chapter_continuity_context(
                    chapter_index, previous_chapters, outline_content
                )
            
            task_section = f"""
{chapter_continuity}

## 当前任务：第{chapter_index}章 - 章节内容 ✍️

你是一位顶级畅销小说家，正在创作第{chapter_index}章的**完整正文**。

> "写作的秘诀是把每一个句子都写得让读者想读下一句。" — 约翰·格里森

---

### ⚠️ 连贯性要求（最重要！）

{"**这是第一章**，是读者接触故事的第一印象。需要：吸引人的开场、引入主角、建立世界观基调、制造悬念钩子。" if chapter_index == 1 else f'''**必须从第{chapter_index-1}章结尾处衔接！**

本章开头必须：
1. 自然承接上一章的结尾场景/情绪/悬念
2. 人物状态与上一章结尾保持一致
3. 时间线和空间位置要连贯
4. 如果有时间跳跃，必须用过渡语句交代

❌ **绝对禁止**：本章开头像另一个独立的故事，与前面毫无关联'''}

---

### 📌 写作要求

| 项目 | 要求 |
|-----|------|
| 目标字数 | **{min_words}-{max_words}** 字 |
| 叙事视角 | [根据风格元素设定] |
| 语言风格 | [根据风格元素设定] |

---

### 🏆 顶级作家的写作法则

**法则一：展示，不要告诉（Show, Don't Tell）**
- ❌ "他很生气"
- ✅ "他的手指收紧，指节发白，咬着牙一字一顿地说……"

**法则二：对话要推动剧情**
- 每句对话都要有目的：揭示信息/制造冲突/展现性格
- 避免无意义的寒暄和废话

**法则三：场景转换要流畅**
- 场景之间需要过渡，不能生硬跳切
- 可以用时间跳跃、空间移动、或情绪转换

**法则四：五感细节要丰富**
- 不只是"看到"，还有听到、闻到、触到、尝到
- 细节要服务于氛围和情绪

**法则五：保持故事线索连贯**
- 每一章都是整体故事的一部分，不是独立短篇
- 前面埋的伏笔要有回应或继续铺垫
- 人物弧线要有连续性发展

---

### 📋 写作指南

**基于章节大纲，创作完整的章节正文**

**内容要求**：
1. {"从引人入胜的场景开始" if chapter_index == 1 else "从上一章结尾自然衔接开始"}
2. 按场景顺序自然展开
3. 场景之间有流畅过渡
4. 人物性格保持一致
5. 世界观设定保持一致
6. 节奏有张有弛
7. **与前面章节保持情节连贯**

**格式要求**：
- 直接输出小说正文
- 以章节标题开头（如："第{chapter_index}章 [标题]"）
- 不要输出"场景1"、"场景2"之类的标记
- 段落分明，对话独立成行

**质量标准**：
- {"开头100字要抓住读者，建立第一印象" if chapter_index == 1 else "开头要自然衔接上一章"}
- 对话要自然有节奏
- 描写要有画面感
- 结尾要有钩子，让读者想读下一章

---

### ❌ 禁止事项

- 禁止大段心理独白（要化为行动和对话）
- 禁止信息堆砌式描写
- 禁止对话冗长无重点
- 禁止场景转换生硬
- 禁止输出写作说明或注释
- **禁止与前面章节脱节，像独立短篇**

📝 **输出**：完整的章节正文，{min_words}-{max_words}字
"""
        elif task_type == "章节润色":
            chapter_index = task.metadata.get("chapter_index", "未知")
            
            # 🔥 获取前面章节内容，确保润色时保持连贯性
            chapter_continuity = ""
            if isinstance(chapter_index, int) and chapter_index > 1:
                previous_chapters = await self._get_previous_chapters(chapter_index, context, max_chapters=2)
                outline_content = predecessor_contents.get("大纲", "")
                chapter_continuity = self._build_chapter_continuity_context(
                    chapter_index, previous_chapters, outline_content
                )
            
            task_section = f"""
{chapter_continuity}

## 当前任务：第{chapter_index}章 - 章节润色 ✨

你是一位顶级文学编辑，正在为第{chapter_index}章进行**精细润色**。

> "好的写作是改出来的。第一稿是把沙子倒出来，修改是从沙子里淘金。" — 欧内斯特·海明威

---

### 📌 润色目标

把一份"好"的稿子变成"优秀"的稿子。

---

### 🏆 顶级编辑的润色法则

**法则一：删掉所有不必要的词**
- 每个形容词、每个副词都要质问：真的需要吗？
- "非常美丽的花" → "绚烂的花"

**法则二：加强动词的力度**
- 弱动词换强动词："他走过去" → "他冲过去/踱过去/溜过去"
- 动词承载情绪

**法则三：对话要能"听出"性格**
- 不同人物说话方式应该不同
- 读对话时能分辨是谁在说

**法则四：节奏感要体现在句子长度**
- 紧张时用短句
- 抒情时可以用长句
- 避免句式单调

---

### 📋 润色方向

**1. 文字层面**
- [ ] 删除冗余词汇
- [ ] 替换弱动词为强动词
- [ ] 优化形容词使用
- [ ] 调整句子节奏

**2. 描写层面**
- [ ] 补充必要的感官细节
- [ ] 强化有画面感的描写
- [ ] 删除无意义的环境描写

**3. 对话层面**
- [ ] 让对话更符合人物性格
- [ ] 删除无意义的对话
- [ ] 对话标签多样化（不只是"说"）

**4. 结构层面**
- [ ] 检查场景过渡是否流畅
- [ ] 检查节奏起伏是否合适
- [ ] 检查开头是否抓人
- [ ] 检查结尾是否有钩子

**5. 一致性检查**
- [ ] 人物性格是否一致
- [ ] 设定是否一致
- [ ] 与前后章节是否衔接

---

### ❌ 禁止事项

- 禁止改变情节走向
- 禁止改变人物关系
- 禁止添加新的剧情元素
- 禁止输出修改说明（只输出润色后的正文）

---

### 📝 输出要求

直接输出**润色后的完整章节内容**
- 不要输出对比说明
- 不要标注修改位置
- 不要写"修改前/修改后"
- 只输出最终版本
"""
        elif task_type == "一致性检查":
            task_section = f"""
## 当前任务：{task_type} 🔍

🚨🚨🚨 **极其重要的警告** 🚨🚨🚨

你是一位**质量检查员**，正在做**检查报告**，而不是写小说！！！

❌ **绝对禁止**：输出任何小说内容、故事情节、人物对话
✅ **你的任务**：只输出问题清单和评估报告

如果你输出了小说内容，说明你完全理解错了任务！这是**检查任务**，不是**创作任务**！

---

> "读者会原谅作者的写作瑕疵，但不会原谅逻辑漏洞。" — 布兰登·桑德森

---

### 📌 检查维度

**1. 人物一致性**
| 检查项 | 要点 |
|-------|------|
| 性格一致 | 人物行为是否前后矛盾 |
| 外貌一致 | 外貌描写有无冲突 |
| 背景一致 | 人物背景有无自相矛盾 |
| 关系一致 | 人物关系有无错乱 |

**2. 世界观一致性**
| 检查项 | 要点 |
|-------|------|
| 规则一致 | 设定的规则是否被违反 |
| 时间线 | 时间顺序有无矛盾 |
| 空间 | 地理/距离有无冲突 |
| 科技/魔法 | 能力体系是否自洽 |

**3. 情节一致性**
| 检查项 | 要点 |
|-------|------|
| 伏笔回收 | 埋下的伏笔是否揭示 |
| 因果关系 | 事件之间因果是否成立 |
| 情节漏洞 | 有无逻辑问题 |

---

### 📋 输出格式

**问题清单**（按严重程度排序）：

| 严重度 | 位置 | 问题描述 | 修改建议 |
|-------|-----|---------|---------|
| 🔴严重 | 第X章 | | |
| 🟡中等 | 第X章 | | |
| 🟢轻微 | 第X章 | | |

**总体评估**：
- 一致性评分：X/10
- 主要问题：
- 整体评价：

🚨🚨🚨 **再次强调** 🚨🚨🚨
- 这是**检查报告**任务
- 只输出上面格式的**问题清单**和**总体评估**
- **绝对不要**输出任何小说内容、故事情节、人物描写
- 如果检查发现没有问题，就写"未发现明显问题"
"""
        elif task_type == "评估":
            task_section = f"""
## 当前任务：{task_type} 📊

你是一位资深的文学评论家和编辑，正在对创作内容进行**专业评估**。

> "好的编辑不只是挑毛病，而是帮助作品成为它本该成为的样子。" — 罗伯特·戈特利布

---

### 📌 评估维度

| 维度 | 评分 | 说明 |
|-----|-----|------|
| **故事性** | X/10 | 情节是否吸引人？有无让人想继续读的欲望？ |
| **人物** | X/10 | 人物是否立体？有无让人记住的角色？ |
| **文学性** | X/10 | 文字是否有美感？语言是否得当？ |
| **可读性** | X/10 | 是否通俗易懂？节奏是否合适？ |
| **完整性** | X/10 | 结构是否完整？有无遗漏？ |
| **创意性** | X/10 | 有无新意？是否有独特之处？ |

---

### 📋 请输出以下内容

**一、各维度详细评分**

| 维度 | 评分 | 优点 | 不足 |
|-----|-----|-----|-----|
| 故事性 | /10 | | |
| 人物 | /10 | | |
| 文学性 | /10 | | |
| 可读性 | /10 | | |
| 完整性 | /10 | | |
| 创意性 | /10 | | |

**二、亮点总结**（3-5条）
- 

**三、待改进**（3-5条）
- 

**四、修改建议**（按优先级）
1. 🔴 必须改：
2. 🟡 建议改：
3. 🟢 可以改：

**五、总体评价**
- 综合评分：X/10
- 一句话评价：

⚠️ 这是评估报告，请客观专业。不要输出小说内容。
"""
        elif task_type == "修订":
            task_section = f"""
## 当前任务：{task_type} ✏️

你是创作这部小说的顶级畅销小说家，现在需要根据反馈**修订内容**。

> "写作是改出来的。第一稿是把沙子倒出来，修改是从沙子里淘金。" — 海明威

---

### 📌 修订原则

**优先级**：
1. 🔴 **先修逻辑**：情节漏洞、设定矛盾
2. 🟡 **再改结构**：节奏问题、结构松散
3. 🟢 **最后润色**：文字质量、细节描写

**守则**：
- 保持原有风格和基调
- 不过度改写，保留原作特点
- 确保与整体设定一致
- 改善但不改变故事核心

---

### ❌ 禁止事项

- 禁止改变已确定的情节走向
- 禁止改变人物基本性格
- 禁止添加未经规划的新元素
- 禁止输出修订说明（只输出最终内容）

---

### 📝 输出要求

直接输出**修订后的完整内容**
- 不要输出"修改前/修改后"
- 不要标注修改位置
- 不要写修改说明
- 只输出最终版本
"""
        else:
            # Default for other tasks
            task_section = f"\n## 当前任务\n{task.description}\n\n"
            task_section += f"任务类型: {task.task_type.value}\n"

            if task.metadata.get("chapter_index"):
                task_section += f"章节: 第{task.metadata['chapter_index']}章\n"
            if task.metadata.get("scene_index"):
                task_section += f"场景: {task.metadata['scene_index']}\n"

        sections.append(task_section)
        
        # 🎯 添加高分示例参考（如果有的话）
        best_example = self._get_best_example_for_task(task_type, genre)
        if best_example:
            sections.append(best_example)
            logger.info(f"📌 为任务 {task_type} 添加了高分示例参考")

        # Output format instruction based on task type
        if task_type in planning_tasks:
            sections.append("""
## 输出要求
- 使用结构化的格式输出（标题+内容）
- 语言简洁明了，每项1-3句话
- 这是规划文档，不是小说正文
- 不要写成学术论文，用通俗的语言
""")
        elif task_type in element_tasks:
            sections.append("""
## 输出要求
- 结构清晰，便于后续参考
- 描述要有文学性，但也要实用
- 这是创作素材，不是小说正文
- 适度使用描述性语言，让素材生动
""")
        elif task_type == "大纲":
            sections.append("""
## 输出要求
- 完整输出故事大纲
- 章节规划要覆盖所有章节
- 用叙事性的语言，让大纲本身也有可读性
- 不要输出标题或额外说明，直接输出大纲内容
""")
        else:
            # Content generation tasks
            sections.append("""
## 输出要求
请直接输出小说内容，使用文学化的语言：
- 必须是故事性的、叙事性的内容
- 使用生动、形象的文学语言
- 内容应该适合普通读者阅读
- 不需要额外的说明、标题或标注

📖 科幻小说要点：
- 科学概念要通过故事情节呈现，不是写技术文档
- 复杂设定用对话、场景、隐喻等方式自然融入
- 技术细节服务于氛围和情节，不是详尽罗列
- 参考刘慈欣的手法：用通俗的方式讲复杂的科学

你在写给科幻爱好者看的小说，不是写给研究者看的论文！
""")

        prompt = "".join(sections)
        
        # 🧬 检查是否有进化后的更优提示词片段
        if self.enable_self_evolution:
            evolved_prompt = self.prompt_evolver.get_best_prompt(task_type)
            if evolved_prompt:
                # 将进化后的优化建议添加到提示词末尾
                prompt += f"""

════════════════════════════════════════════════════════════════
🧬 【提示词进化优化 - 基于历史反馈】
════════════════════════════════════════════════════════════════

根据以往的评估反馈，请特别注意以下优化建议：

{evolved_prompt}

════════════════════════════════════════════════════════════════
"""
                logger.info(f"📈 已加载进化提示词: {task_type}")
        
        return prompt

    async def _attempt_rewrite(
        self,
        task: Task,
        content: str,
        evaluation: EvaluationResult,
        context: MemoryContext,
        goal: Dict[str, Any],
        max_retries: int = 999,  # 不限制次数，直到通过为止
        token_stats: Dict[str, int] = None,  # 🔥 用于累计 token 统计
    ) -> tuple:
        """
        Attempt to rewrite content based on evaluation feedback until it passes
        
        Returns:
            tuple: (final_content, token_stats_dict)
            token_stats_dict 包含: total_tokens, prompt_tokens, completion_tokens, cost
        """

        logger.info(f"🔄 开始重写任务 {task.task_id}，直到评估通过为止")

        # 初始化统计
        if token_stats is None:
            token_stats = {"total_tokens": 0, "prompt_tokens": 0, "completion_tokens": 0, "cost": 0.0}

        attempt = 0
        current_content = content
        current_evaluation = evaluation
        
        # 🔥 获取一致性检查结果（如果有的话）
        consistency_result = task.metadata.get("consistency_check_result", None)
        
        while attempt < max_retries:
            attempt += 1
            logger.info(f"🔄 重写尝试 #{attempt} - 任务: {task.task_type.value}")
            
            # 通知前端重试状态
            if self._on_task_start:
                task.metadata["retry_count"] = attempt
                task.metadata["retry_reason"] = f"评估未通过 (得分: {current_evaluation.score:.2f})"
                await self._safe_callback(self._on_task_start, task)

            # Build improved prompt with feedback
            # 🔥 传递一致性检查结果
            feedback_prompt = self._build_rewrite_prompt(
                task=task,
                original_content=current_content,
                evaluation=current_evaluation,
                context=context,
                goal=goal,
                attempt=attempt,
                consistency_result=consistency_result,  # 传递一致性检查结果
            )

            try:
                response = await self.llm_client.generate(
                    prompt=feedback_prompt,
                    task_type=task.task_type.value,
                    temperature=min(0.7 + attempt * 0.05, 1.0),  # 逐渐提高温度增加变化
                    max_tokens=self._get_max_tokens_for_task(task.task_type),
                )
                
                # 🔥 累计重写过程中的 token 消耗
                token_stats["total_tokens"] += response.usage.total_tokens
                token_stats["prompt_tokens"] += response.usage.prompt_tokens
                token_stats["completion_tokens"] += response.usage.completion_tokens
                token_stats["cost"] += self._calculate_cost(
                    response.provider.value, response.model, response.usage
                )

                # Re-evaluate
                new_evaluation = await self.evaluator.evaluate(
                    task_type=task.task_type.value,
                    content=response.content,
                    context=context.to_dict(),
                    goal=goal,
                )

                if new_evaluation.passed:
                    logger.info(f"✅ 重写成功！尝试 #{attempt}，得分: {new_evaluation.score:.2f}")
                    self.stats.retried_tasks += 1
                    task.metadata["final_retry_count"] = attempt
                    return response.content, token_stats

                # Update for next retry
                current_content = response.content
                current_evaluation = new_evaluation
                
                # 🔥 记录失败尝试次数
                task.failed_attempts += 1
                
                logger.warning(
                    f"⚠️ 尝试 #{attempt} 未通过评估，得分: {new_evaluation.score:.2f}，继续重试..."
                )
                
                # 每5次重试暂停一下，避免过快请求
                if attempt % 5 == 0:
                    logger.info(f"⏸️ 已重试 {attempt} 次，暂停2秒后继续...")
                    await asyncio.sleep(2)

            except Exception as e:
                logger.error(f"❌ 重写尝试 #{attempt} 失败: {e}")
                task.failed_attempts += 1
                # 出错后等待一下再重试
                await asyncio.sleep(1)
                continue

        # 理论上不应该到达这里（max_retries=999）
        logger.warning(f"⚠️ 任务 {task.task_id} 达到最大重试次数 {max_retries}")
        task.metadata["final_retry_count"] = attempt
        return current_content, token_stats

    def _build_rewrite_prompt(
        self,
        task: Task,
        original_content: str,
        evaluation: EvaluationResult,
        context: MemoryContext,
        goal: Dict[str, Any],
        attempt: int = 1,
        consistency_result: Dict[str, Any] = None,  # 🔥 新增参数
    ) -> str:
        """Build prompt for content rewriting with retry information and consistency feedback"""
        
        task_type = task.task_type.value
        chapter_index = task.metadata.get("chapter_index", None)
        
        # 根据重试次数调整提示强度
        urgency = ""
        if attempt >= 3:
            urgency = f"""
⚠️ **警告**：这是第 {attempt} 次重写尝试！
请认真阅读评估反馈，针对性地修改问题。不要只是小修小补，要从根本上解决问题。
"""
        if attempt >= 5:
            urgency = f"""
🚨 **紧急**：这是第 {attempt} 次重写尝试！
之前的修改显然没有解决核心问题。请：
1. 仔细阅读每一条反馈
2. 思考为什么之前的修改没有效果
3. 尝试完全不同的写作方式
"""

        # 🔥 构建一致性问题部分（如果有一致性检查失败）
        consistency_section = ""
        if consistency_result and not consistency_result.get("passed", True):
            issues = consistency_result.get("issues", [])
            suggestions = consistency_result.get("suggestions", [])
            continuity_issues = consistency_result.get("continuity_issues", [])
            score = consistency_result.get("score", 0)
            
            consistency_section = f"""
## 🚨 一致性检查失败（必须修复！）

一致性评分：{score:.2f}/1.00

"""
            if issues:
                consistency_section += f"""### ❌ 发现的一致性问题
{chr(10).join(f'- {issue}' for issue in issues)}

"""
            
            if continuity_issues:
                consistency_section += f"""### ❌ 章节连贯性问题（非常重要！）
{chr(10).join(f'- {issue}' for issue in continuity_issues)}

**重要**：这些连贯性问题说明当前章节像独立短篇，与前面章节脱节！
必须确保：
1. 开头自然衔接上一章结尾
2. 人物状态延续（位置、情绪、正在做的事）
3. 时间线连贯
4. 情节有承接关系

"""
            
            if suggestions:
                consistency_section += f"""### 💡 修改建议
{chr(10).join(f'- {s}' for s in suggestions)}

"""

        prompt = f"""## 重写任务（第 {attempt} 次尝试）

任务类型: {task_type}
{f"章节: 第{chapter_index}章" if chapter_index else ""}
描述: {task.description}
{urgency}

{consistency_section}

## 原始内容
```
{original_content[:3000]}
```

## 评估反馈
总体评分: {evaluation.score:.2f}/1.00
状态: {'未通过' if not evaluation.passed else '通过'}

### 问题原因（必须解决）:
{chr(10).join(f'❌ {r}' for r in evaluation.reasons[:5])}

改进建议:
{chr(10).join(f'- {s}' for s in evaluation.suggestions[:5])}

## 重写要求
请根据评估反馈改进内容，**必须解决所有一致性和连贯性问题**。

{"特别注意：确保本章开头与前一章结尾自然衔接，不要像另一个独立故事！" if chapter_index and chapter_index > 1 else ""}

## 输出要求
请直接输出改进后的内容，不需要解释或说明。
"""

        return prompt

    def _calculate_cost(self, provider: str, model: str, usage) -> float:
        """
        计算 API 调用的费用（美元）
        
        基于不同提供商和模型的定价计算。
        
        Args:
            provider: LLM 提供商（deepseek, aliyun, ark 等）
            model: 模型名称
            usage: token 使用统计对象
            
        Returns:
            费用（美元）
        """
        # 定价表（每百万 token 的价格，美元）
        # 注意：这些价格可能会变化，需要定期更新
        pricing = {
            # DeepSeek 定价（很便宜）
            "deepseek": {
                "deepseek-chat": {"input": 0.14, "output": 0.28},
                "deepseek-reasoner": {"input": 0.55, "output": 2.19},
                "default": {"input": 0.14, "output": 0.28},
            },
            # 阿里云通义千问定价（人民币转美元，汇率约 7.2）
            "aliyun": {
                "qwen-long": {"input": 0.07, "output": 0.28},  # 0.5/3.5M tokens CNY
                "qwen-max": {"input": 2.78, "output": 8.33},  # 20/60 CNY per M
                "qwen-plus": {"input": 0.56, "output": 1.39},  # 4/10 CNY per M
                "qwen-turbo": {"input": 0.14, "output": 0.28},
                "default": {"input": 0.07, "output": 0.28},
            },
            # 火山引擎 Ark (豆包) 定价
            "ark": {
                "doubao-pro": {"input": 0.11, "output": 0.28},  # 0.8/2 CNY per M
                "doubao-lite": {"input": 0.04, "output": 0.14},
                "default": {"input": 0.11, "output": 0.28},
            },
            # 默认定价（保守估计）
            "default": {"input": 0.50, "output": 1.00},
        }
        
        # 获取提供商定价
        provider_pricing = pricing.get(provider, pricing["default"])
        
        # 获取模型定价
        if isinstance(provider_pricing, dict) and "input" in provider_pricing:
            model_pricing = provider_pricing
        else:
            # 尝试匹配模型名称
            model_pricing = None
            for key in provider_pricing:
                if key != "default" and key in model.lower():
                    model_pricing = provider_pricing[key]
                    break
            if not model_pricing:
                model_pricing = provider_pricing.get("default", pricing["default"])
        
        # 计算费用
        input_cost = (usage.prompt_tokens / 1_000_000) * model_pricing["input"]
        output_cost = (usage.completion_tokens / 1_000_000) * model_pricing["output"]
        
        return input_cost + output_cost

    def _get_temperature_for_task(self, task_type: NovelTaskType) -> float:
        """Get appropriate temperature for a task type"""
        # Creative tasks need higher temperature
        high_temp_tasks = {
            NovelTaskType.CHAPTER_CONTENT,
            NovelTaskType.SCENE_GENERATION,
            NovelTaskType.REVISION,
        }

        # Structured tasks need lower temperature
        low_temp_tasks = {
            NovelTaskType.OUTLINE,
            NovelTaskType.CHARACTER_DESIGN,
            NovelTaskType.WORLDVIEW_RULES,
            NovelTaskType.CONSISTENCY_CHECK,
        }

        if task_type in high_temp_tasks:
            return 0.8
        elif task_type in low_temp_tasks:
            return 0.5
        else:
            return 0.7

    def _get_max_tokens_for_task(self, task_type: NovelTaskType) -> int:
        """Get appropriate max tokens for a task type"""
        # 章节内容需要最多 tokens
        if task_type == NovelTaskType.CHAPTER_CONTENT:
            return 16000  # 约 12000 字中文
        
        # 大纲和场景生成需要较多 tokens
        elif task_type in {NovelTaskType.OUTLINE, NovelTaskType.SCENE_GENERATION, NovelTaskType.CHAPTER_OUTLINE}:
            return 8000  # 约 6000 字中文
        
        # 规划类任务需要足够空间
        elif task_type in {NovelTaskType.CHARACTER_DESIGN, NovelTaskType.WORLDVIEW_RULES, 
                           NovelTaskType.EVENTS, NovelTaskType.SCENES_ITEMS_CONFLICTS, NovelTaskType.FORESHADOW_LIST}:
            return 8000  # 约 6000 字中文
        
        # 其他任务
        else:
            return 4000  # 约 3000 字中文
    
    async def _check_and_save_high_score_example(
        self, 
        task_type: str, 
        genre: str, 
        content: str, 
        score: float,
        evaluation: Any
    ) -> bool:
        """
        🎯 检查内容是否为高分，如果是则保存为示例供后续任务参考
        
        Args:
            task_type: 任务类型
            genre: 小说类型（仙侠、科幻、言情等）
            content: 生成的内容
            score: 评分（0-1）
            evaluation: 评估结果对象
            
        Returns:
            bool: 是否保存为高分示例
        """
        score_100 = int(score * 100)
        
        # 只有超过阈值的内容才考虑保存
        if score_100 < self.high_score_threshold:
            return False
        
        # 初始化存储结构
        if task_type not in self.best_examples:
            self.best_examples[task_type] = {}
        
        # 检查该类型+题材是否已有更高分的示例
        current_best = self.best_examples[task_type].get(genre)
        
        if current_best is None or score_100 > current_best.get("score", 0):
            # 截取内容摘要（不超过2000字）
            content_summary = content[:2000] + "..." if len(content) > 2000 else content
            
            # 提取评估中的优点（如果有的话）
            strengths = []
            if hasattr(evaluation, 'dimension_scores') and evaluation.dimension_scores:
                for dim, data in evaluation.dimension_scores.items():
                    if isinstance(data, dict) and data.get('score', 0) >= 80:
                        strengths.append(f"{dim}: {data.get('reason', '表现优秀')}")
            
            # 保存为最佳示例
            self.best_examples[task_type][genre] = {
                "score": score_100,
                "content": content_summary,
                "strengths": strengths,
                "saved_at": datetime.utcnow().isoformat(),
            }
            
            logger.info(f"🏆 记录高分示例: {task_type}/{genre} 得分 {score_100}/100")
            return True
        
        return False
    
    def _get_best_example_for_task(self, task_type: str, genre: str) -> Optional[str]:
        """
        🎯 获取该任务类型和题材的最佳示例（用于提示词参考）
        
        Returns:
            Optional[str]: 格式化的示例文本，如果没有则返回 None
        """
        if task_type not in self.best_examples:
            return None
        
        # 优先获取同题材的示例
        example = self.best_examples[task_type].get(genre)
        
        # 如果没有同题材的，尝试获取通用的
        if not example and genre != "通用":
            example = self.best_examples[task_type].get("通用")
        
        if not example:
            return None
        
        strengths_text = ""
        if example.get("strengths"):
            strengths_text = "\n**优点**:\n" + "\n".join(f"- {s}" for s in example["strengths"])
        
        return f"""
---
📌 **高分参考示例**（评分: {example['score']}/100）
{strengths_text}

**内容摘要**:
{example['content']}
---
"""

    def _get_memory_type_for_task(self, task_type: NovelTaskType) -> MemoryType:
        """Map task type to memory type for storage
        
        所有核心任务都需要被正确分类存储到向量数据库，
        方便后续章节创作时能够检索到相关内容。
        """
        mapping = {
            # 核心创意阶段 - 使用 GENERAL（最重要，会被频繁检索）
            NovelTaskType.CREATIVE_BRAINSTORM: MemoryType.GENERAL,
            NovelTaskType.STORY_CORE: MemoryType.GENERAL,
            
            # 元素创建阶段
            NovelTaskType.CHARACTER_DESIGN: MemoryType.CHARACTER,
            NovelTaskType.WORLDVIEW_RULES: MemoryType.WORLDVIEW,
            
            # 风格定位阶段
            NovelTaskType.THEME_CONFIRMATION: MemoryType.GENERAL,
            NovelTaskType.STYLE_ELEMENTS: MemoryType.GENERAL,
            NovelTaskType.MARKET_POSITIONING: MemoryType.GENERAL,
            
            # 情节阶段
            NovelTaskType.EVENTS: MemoryType.PLOT,
            NovelTaskType.SCENES_ITEMS_CONFLICTS: MemoryType.SCENE,
            NovelTaskType.FORESHADOW_LIST: MemoryType.FORESHADOW,
            
            # 大纲阶段
            NovelTaskType.OUTLINE: MemoryType.OUTLINE,
            NovelTaskType.CONSISTENCY_CHECK: MemoryType.GENERAL,
            
            # 章节阶段
            NovelTaskType.CHAPTER_OUTLINE: MemoryType.CHAPTER,
            NovelTaskType.SCENE_GENERATION: MemoryType.SCENE,
            NovelTaskType.CHAPTER_CONTENT: MemoryType.CHAPTER,
            NovelTaskType.CHAPTER_POLISH: MemoryType.CHAPTER,
        }

        return mapping.get(task_type, MemoryType.GENERAL)

    def _collect_outputs(self) -> Dict[str, str]:
        """Collect all task outputs"""
        outputs = {}

        # Get completed tasks from planner
        for task in self.planner.get_tasks_by_status("completed"):
            if task.result:
                key = f"{task.task_type.value}"
                if task.metadata.get("chapter_index"):
                    key += f"_ch{task.metadata['chapter_index']}"
                outputs[key] = task.result

        return outputs

    async def _safe_callback(self, callback: Callable, *args) -> None:
        """Safely execute a callback"""
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(*args)
            else:
                callback(*args)
        except Exception as e:
            logger.error(f"Callback error: {e}")

    # Control methods

    def pause(self) -> None:
        """Pause execution"""
        self.is_paused = True
        self.status = ExecutionStatus.PAUSED
        logger.info(f"Paused execution for session {self.session_id}")

    def resume(self) -> None:
        """Resume execution"""
        self.is_paused = False
        self.status = ExecutionStatus.RUNNING
        logger.info(f"Resumed execution for session {self.session_id}")

    def stop(self) -> None:
        """Stop execution"""
        self.is_running = False
        self.status = ExecutionStatus.STOPPED
        logger.info(f"Stopped execution for session {self.session_id}")

    def approve_task(self, action: str = 'approve', feedback: Optional[str] = None, selected_idea: Optional[int] = None) -> None:
        """
        Approve or reject the current task result
        
        Args:
            action: 'approve', 'reject', or 'regenerate'
            feedback: Optional feedback for regeneration
            selected_idea: For brainstorm tasks, the number of the selected idea (1-4)
        """
        if not self.is_waiting_approval:
            logger.warning("No task is waiting for approval")
            return
        
        self.approval_result = {
            'action': action,
            'feedback': feedback,
            'selected_idea': selected_idea
        }
        self._approval_event.set()
        logger.info(f"Task approval: {action}" + (f", selected idea: {selected_idea}" if selected_idea else ""))

    def get_status(self) -> ExecutionStatus:
        """Get current execution status"""
        return self.status

    def get_progress(self) -> Dict[str, Any]:
        """Get current progress"""
        return self.planner.get_progress()

    def get_stats(self) -> Dict[str, Any]:
        """Get execution statistics"""
        return self.stats.to_dict()
    
    @staticmethod
    def get_genre_specific_guide(genre: str) -> str:
        """
        🎯 获取针对特定小说类型的创作指南
        
        不同类型的小说有不同的创作要点和禁忌，
        这个方法返回类型特定的提示词，帮助AI写出符合类型特点的内容。
        
        Args:
            genre: 小说类型
            
        Returns:
            str: 类型特定的创作指南
        """
        genre_guides = {
            "科幻": """
🔬 **科幻小说创作要点**

**类型特色**：
- 以科学或技术设定为核心驱动故事
- 探讨科技对人类/社会的影响
- 创造令人惊叹的未来/平行世界

**必须做到**：
- 科学设定要自洽（不需要完全准确，但要能自圆其说）
- 用故事讲科学，而非科普式解释
- 技术细节融入情节，不要单独讲解
- 人物情感和科技设定同样重要

**经典参考**：《三体》《流浪地球》《银河帝国》《沙丘》

**常见问题**：
- ❌ 大段技术原理解释
- ❌ 过于追求"硬核"而牺牲可读性
- ❌ 人物只是展示科技的工具
- ✅ 用角色的眼睛展示世界
""",
            "仙侠": """
⚔️ **仙侠小说创作要点**

**类型特色**：
- 修仙求道的主线
- 江湖恩怨、门派争斗
- 天道规则、境界突破

**必须做到**：
- 修炼体系设定清晰（炼气→筑基→金丹...）
- 突出快意恩仇的江湖气
- 人物要有"道心"和追求
- 打斗描写要有画面感

**经典参考**：《凡人修仙传》《遮天》《仙逆》《诛仙》

**常见问题**：
- ❌ 境界划分混乱
- ❌ 主角金手指过于离谱
- ❌ 配角智商下线
- ✅ 注重修炼过程的合理性
""",
            "玄幻": """
✨ **玄幻小说创作要点**

**类型特色**：
- 自由度高，设定可以天马行空
- 强调"爽感"和主角成长
- 异世界冒险、升级打怪

**必须做到**：
- 力量体系设定明确
- 主角的"金手指"要有代价或限制
- 升级节奏要有松有紧
- 要有让读者期待的长期目标

**经典参考**：《斗破苍穹》《斗罗大陆》《完美世界》《武动乾坤》

**常见问题**：
- ❌ 主角无脑碾压没有挑战
- ❌ 配角全是衬托主角的工具人
- ❌ 升级太快缺乏积累感
- ✅ 每个强敌都让读者印象深刻
""",
            "言情": """
💕 **言情小说创作要点**

**类型特色**：
- 以感情线为核心
- 男女主的情感发展是主线
- 强调情感的细腻表达

**必须做到**：
- 男女主人设要立体、有魅力
- 感情发展要有层次，不能太突兀
- 注重细节描写和氛围营造
- 误会/阻碍要合理，不能太刻意

**经典参考**：《何以笙箫默》《微微一笑很倾城》《你好，旧时光》

**常见问题**：
- ❌ 为虐而虐，误会太牵强
- ❌ 男/女主人设崩塌
- ❌ 配角刻意制造矛盾
- ✅ 甜与虐的节奏要平衡
""",
            "悬疑": """
🔍 **悬疑小说创作要点**

**类型特色**：
- 以解谜、查案为核心
- 设置悬念吸引读者
- 层层剥茧、逻辑推理

**必须做到**：
- 线索要公平，不能藏着关键信息
- 推理逻辑要严密
- 节奏要紧凑，保持紧张感
- 反转要在情理之中

**经典参考**：《白夜行》《嫌疑人X的献身》《福尔摩斯》《坏小孩》

**常见问题**：
- ❌ 关键线索没给读者就揭晓答案
- ❌ 推理过程有明显漏洞
- ❌ 为反转而反转，不合逻辑
- ✅ 让读者可以一起推理
""",
            "都市": """
🏙️ **都市小说创作要点**

**类型特色**：
- 现代都市为背景
- 贴近现实生活
- 职场、商战、人际关系

**必须做到**：
- 设定要贴合现实（除非是都市异能类）
- 人物职业、生活要真实可信
- 对话要有现代感
- 情节要接地气

**经典参考**：《遥远的救世主》《余罪》《杜拉拉升职记》

**常见问题**：
- ❌ 主角开局就是顶级大佬
- ❌ 对职业/行业描写不专业
- ❌ 人物言行脱离现实
- ✅ 让读者有代入感
""",
            "武侠": """
🗡️ **武侠小说创作要点**

**类型特色**：
- 江湖侠客、快意恩仇
- 武功招式、武林门派
- 侠之大者，为国为民

**必须做到**：
- 武功招式描写要有画面感
- 江湖规矩、门派设定要合理
- 人物要有侠义精神
- 情节要有武侠的氛围感

**经典参考**：金庸系列、古龙系列、《雪中悍刀行》

**常见问题**：
- ❌ 武功越写越离谱
- ❌ 侠义精神空洞
- ❌ 江湖味不够
- ✅ 注重"侠"的内涵
""",
            "历史": """
📜 **历史小说创作要点**

**类型特色**：
- 以历史事件/人物为背景
- 还原历史氛围
- 可以是架空但要有历史感

**必须做到**：
- 重大历史事件要有据可查
- 人物言行要符合时代
- 器物、服饰、习俗要考究
- 即使架空也要有历史质感

**经典参考**：《明朝那些事儿》《大明王朝1566》《庆余年》

**常见问题**：
- ❌ 明显的历史错误
- ❌ 人物思维太现代
- ❌ 细节穿帮
- ✅ 让读者感受到时代氛围
""",
        }
        
        # 获取类型指南，如果没有特定类型则返回通用指南
        guide = genre_guides.get(genre, f"""
📚 **{genre}小说创作要点**

**通用原则**：
- 遵循{genre}类型的惯例和读者期待
- 人物塑造要立体真实
- 情节发展要有逻辑
- 保持类型的核心吸引力

请发挥你对{genre}类型的理解，创作符合类型特色的内容。
""")
        
        return guide

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.87 at 0x1041130e0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.core.loop_engine'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.39 at 0x10417bb00>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-28.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-28.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.core.evaluator'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Evaluation Engine - Quality assessment for generated content

Implements multi-dimensional quality evaluation with configurable criteria.
Uses LLM-based evaluation for semantic quality assessment.
"""

import json
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from loguru import logger

from creative_autogpt.utils.llm_client import MultiLLMClient, LLMMessage


class EvaluationCriterion(str, Enum):
    """Evaluation criteria for content quality"""

    COHERENCE = "coherence"  # Logical flow and consistency
    CREATIVITY = "creativity"  # Originality and innovation
    QUALITY = "quality"  # Writing quality and prose
    CONSISTENCY = "consistency"  # Consistency with established context
    GOAL_ALIGNMENT = "goal_alignment"  # Alignment with creation goals
    CHARACTER_VOICE = "character_voice"  # Character voice consistency
    PLOT_PROGRESSION = "plot_progression"  # Story development
    DIALOGUE_QUALITY = "dialogue_quality"  # Dialogue naturalness


@dataclass
class DimensionScore:
    """Score for a single evaluation dimension"""

    dimension: str
    score: float  # 0.0 to 1.0
    reason: str = ""
    suggestions: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "dimension": self.dimension,
            "score": self.score,
            "reason": self.reason,
            "suggestions": self.suggestions,
        }


@dataclass
class EvaluationResult:
    """Result of content evaluation"""

    passed: bool
    score: float  # Overall score 0.0 to 1.0
    dimension_scores: Dict[str, DimensionScore] = field(default_factory=dict)
    reasons: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    evaluated_at: datetime = field(default_factory=datetime.utcnow)
    evaluator: str = "default"
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "passed": self.passed,
            "score": self.score,
            "dimension_scores": {
                k: v.to_dict() for k, v in self.dimension_scores.items()
            },
            "reasons": self.reasons,
            "suggestions": self.suggestions,
            "evaluated_at": self.evaluated_at.isoformat(),
            "evaluator": self.evaluator,
            "metadata": self.metadata,
        }


class EvaluationEngine:
    """
    Evaluates generated content quality across multiple dimensions

    Default criteria and weights:
    - Coherence: 20%
    - Creativity: 20%
    - Quality: 20%
    - Consistency: 20%
    - Goal Alignment: 20%

    Can be customized for different content types.
    """

    # Default evaluation criteria with weights
    DEFAULT_CRITERIA: Dict[EvaluationCriterion, float] = {
        EvaluationCriterion.COHERENCE: 0.20,
        EvaluationCriterion.CREATIVITY: 0.20,
        EvaluationCriterion.QUALITY: 0.20,
        EvaluationCriterion.CONSISTENCY: 0.20,
        EvaluationCriterion.GOAL_ALIGNMENT: 0.20,
    }

    # Content-specific criteria overrides
    CONTENT_TYPE_CRITERIA: Dict[str, Dict[EvaluationCriterion, float]] = {
        "章节内容": {
            EvaluationCriterion.COHERENCE: 0.15,
            EvaluationCriterion.CREATIVITY: 0.20,
            EvaluationCriterion.QUALITY: 0.25,
            EvaluationCriterion.CONSISTENCY: 0.20,
            EvaluationCriterion.CHARACTER_VOICE: 0.10,
            EvaluationCriterion.PLOT_PROGRESSION: 0.10,
        },
        "对话检查": {
            EvaluationCriterion.DIALOGUE_QUALITY: 0.40,
            EvaluationCriterion.CHARACTER_VOICE: 0.30,
            EvaluationCriterion.CONSISTENCY: 0.20,
            EvaluationCriterion.QUALITY: 0.10,
        },
        "大纲": {
            EvaluationCriterion.COHERENCE: 0.25,
            EvaluationCriterion.CREATIVITY: 0.25,
            EvaluationCriterion.GOAL_ALIGNMENT: 0.25,
            EvaluationCriterion.PLOT_PROGRESSION: 0.25,
        },
    }

    def __init__(
        self,
        llm_client: Optional[MultiLLMClient] = None,
        passing_threshold: float = 0.7,
        criteria: Optional[Dict[EvaluationCriterion, float]] = None,
    ):
        """
        Initialize evaluation engine

        Args:
            llm_client: LLM client for AI-based evaluation
            passing_threshold: Minimum score to pass (0.0 to 1.0)
            criteria: Custom criteria weights
        """
        self.llm_client = llm_client
        self.passing_threshold = passing_threshold
        self.criteria = criteria or self.DEFAULT_CRITERIA.copy()

        logger.info(
            f"EvaluationEngine initialized (threshold={passing_threshold}, "
            f"criteria={len(self.criteria)})"
        )

    async def evaluate(
        self,
        task_type: str,
        content: str,
        criteria: Optional[Dict[EvaluationCriterion, float]] = None,
        context: Optional[Dict[str, Any]] = None,
        goal: Optional[Dict[str, Any]] = None,
    ) -> EvaluationResult:
        """
        Evaluate content quality

        Args:
            task_type: Type of content being evaluated
            content: The content to evaluate
            criteria: Custom criteria for this evaluation
            context: Additional context for evaluation
            goal: Original creation goals

        Returns:
            EvaluationResult with scores and feedback
        """
        logger.debug(f"Evaluating content for task type: {task_type}")

        # Determine criteria to use
        eval_criteria = criteria or self._get_criteria_for_task_type(task_type)

        if self.llm_client:
            # Use LLM-based evaluation
            result = await self._llm_evaluate(
                task_type=task_type,
                content=content,
                criteria=eval_criteria,
                context=context,
                goal=goal,
            )
        else:
            # Use rule-based evaluation (fallback)
            result = await self._rule_based_evaluate(
                task_type=task_type,
                content=content,
                criteria=eval_criteria,
                context=context,
            )

        logger.info(
            f"Evaluation complete: score={result.score:.3f}, passed={result.passed}"
        )

        return result

    def _get_criteria_for_task_type(
        self,
        task_type: str,
    ) -> Dict[EvaluationCriterion, float]:
        """Get evaluation criteria for a specific task type"""
        return self.CONTENT_TYPE_CRITERIA.get(
            task_type,
            self.DEFAULT_CRITERIA,
        )

    async def _llm_evaluate(
        self,
        task_type: str,
        content: str,
        criteria: Dict[EvaluationCriterion, float],
        context: Optional[Dict[str, Any]] = None,
        goal: Optional[Dict[str, Any]] = None,
    ) -> EvaluationResult:
        """
        Perform LLM-based evaluation

        Uses DeepSeek for logical evaluation (cost-effective)
        """
        # Build evaluation prompt
        prompt = self._build_evaluation_prompt(
            task_type=task_type,
            content=content,
            criteria=criteria,
            context=context,
            goal=goal,
        )

        try:
            # Use DeepSeek for evaluation (logic/reasoning strength)
            response = await self.llm_client.generate(
                prompt=prompt,
                task_type="评估",  # Route to DeepSeek
                temperature=0.3,  # Lower temperature for consistent evaluation
                max_tokens=2000,
            )

            # Parse evaluation result
            return self._parse_evaluation_response(
                response.content,
                criteria,
                task_type,
            )

        except Exception as e:
            logger.error(f"LLM evaluation failed: {e}, falling back to rule-based")
            return await self._rule_based_evaluate(
                task_type=task_type,
                content=content,
                criteria=criteria,
                context=context,
            )

    def _build_evaluation_prompt(
        self,
        task_type: str,
        content: str,
        criteria: Dict[EvaluationCriterion, float],
        context: Optional[Dict[str, Any]] = None,
        goal: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Build prompt for LLM evaluation"""

        criteria_desc = "\n".join(
            f"- {c.value}: {w * 100:.0f}%权重"
            for c, w in criteria.items()
        )

        context_section = ""
        if context:
            context_section = f"\n\n上下文信息:\n{json.dumps(context, ensure_ascii=False, indent=2)}"

        goal_section = ""
        if goal:
            goal_section = f"\n\n创作目标:\n{json.dumps(goal, ensure_ascii=False, indent=2)}"

        prompt = f"""你是一位专业的小说内容评估专家。你正在评估一部**小说**的{task_type}内容质量。

⚠️ 重要提醒：
- 这是小说创作，不是学术论文或科学研究报告
- 内容应该是故事性的、文学性的、面向大众读者的
- 必须使用小说的叙事语言，而不是学术论文语言

📖 科幻小说特殊规则（参考《三体》《流浪地球》标准）：
- ✅ 允许：适度的科学概念、技术设定、未来科技描述
- ✅ 允许：必要的科学术语，但必须通过故事情节自然呈现
- ✅ 允许：用通俗易懂的方式解释科学原理（像刘慈欣的写法）
- ❌ 禁止：堆砌复杂公式、学术论文式的理论推导
- ❌ 禁止：纯技术文档式的描述、缺乏故事性
- ❌ 禁止：面向专业研究者的学术写作风格

核心标准：科学设定服务于故事，而不是展示学术研究。

## 评估标准
{criteria_desc}

## 待评估内容
```
{content[:5000]}  # Limit content length
```
{context_section}
{goal_section}

## 评估要求
请对每个评估维度进行打分（0-100分）并给出理由和改进建议。

特别注意：如果内容包含以下特征，必须大幅降低评分（< 30分）：
- 论文格式（摘要、引言、方法论、参考文献等学术结构）
- 纯粹的公式推导，没有故事情节包裹
- 大量堆砌专业术语，不解释或硬性灌输
- 学术报告的语气和结构
- 完全缺乏故事性、对话、场景描写
- 不是面向普通读者，而是面向专业研究者

请以JSON格式返回评估结果:
```json
{{
  "dimension_scores": {{
    "coherence": {{"score": 85, "reason": "...", "suggestions": ["..."]}},
    "creativity": {{"score": 75, "reason": "...", "suggestions": ["..."]}},
    ...
  }},
  "overall_reasons": ["...", "..."],
  "suggestions": ["...", "..."]
}}
```

请确保:
1. 每个维度的分数在0-100之间
2. 理由具体明确
3. 建议具有可操作性
"""

        return prompt

    def _parse_evaluation_response(
        self,
        response: str,
        criteria: Dict[EvaluationCriterion, float],
        task_type: str,
    ) -> EvaluationResult:
        """Parse LLM evaluation response"""

        try:
            # Extract JSON from response
            json_start = response.find("{")
            json_end = response.rfind("}") + 1

            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                data = json.loads(json_str)
            else:
                raise ValueError("No JSON found in response")

            # Build dimension scores
            dimension_scores = {}
            total_score = 0.0
            total_weight = 0.0

            for criterion, weight in criteria.items():
                criterion_key = criterion.value
                if criterion_key in data.get("dimension_scores", {}):
                    score_data = data["dimension_scores"][criterion_key]
                    score = score_data.get("score", 70) / 100.0  # Convert to 0-1

                    dimension_scores[criterion_key] = DimensionScore(
                        dimension=criterion_key,
                        score=score,
                        reason=score_data.get("reason", ""),
                        suggestions=score_data.get("suggestions", []),
                    )

                    total_score += score * weight
                    total_weight += weight
                else:
                    # Use default score if missing
                    dimension_scores[criterion_key] = DimensionScore(
                        dimension=criterion_key,
                        score=0.7,
                        reason="未评估",
                        suggestions=[],
                    )
                    total_score += 0.7 * weight
                    total_weight += weight

            # Calculate overall score
            overall_score = total_score / total_weight if total_weight > 0 else 0.7

            # Collect reasons and suggestions
            all_reasons = data.get("overall_reasons", [])
            all_suggestions = data.get("suggestions", [])

            for dim_score in dimension_scores.values():
                if dim_score.reason:
                    all_reasons.append(f"{dim_score.dimension}: {dim_score.reason}")
                all_suggestions.extend(dim_score.suggestions)

            return EvaluationResult(
                passed=overall_score >= self.passing_threshold,
                score=overall_score,
                dimension_scores=dimension_scores,
                reasons=all_reasons,
                suggestions=all_suggestions,
                evaluator="llm_deepseek",
                metadata={"task_type": task_type},
            )

        except Exception as e:
            logger.error(f"Failed to parse evaluation response: {e}")
            # Return a default result
            return EvaluationResult(
                passed=True,  # Pass on error to avoid blocking
                score=0.7,
                dimension_scores={
                    c.value: DimensionScore(
                        dimension=c.value,
                        score=0.7,
                        reason="评估解析失败，使用默认分数",
                        suggestions=[],
                    )
                    for c in criteria.keys()
                },
                reasons=["评估解析失败"],
                suggestions=["请重试评估"],
                evaluator="llm_deepseek_fallback",
            )

    async def _rule_based_evaluate(
        self,
        task_type: str,
        content: str,
        criteria: Dict[EvaluationCriterion, float],
        context: Optional[Dict[str, Any]] = None,
    ) -> EvaluationResult:
        """
        Perform rule-based evaluation (fallback)

        Uses simple heuristics to assess content quality
        """
        dimension_scores = {}
        total_score = 0.0
        total_weight = 0.0

        content_length = len(content)
        word_count = len(content.split())

        # Coherence: Check for reasonable length and structure
        coherence_score = min(1.0, min(content_length / 500, 1.0))
        if content_length < 100:
            coherence_score = 0.5
        dimension_scores[EvaluationCriterion.COHERENCE.value] = DimensionScore(
            dimension=EvaluationCriterion.COHERENCE.value,
            score=coherence_score,
            reason=f"内容长度: {content_length}字符",
            suggestions=["内容过短，建议扩展" if content_length < 200 else "长度适中"],
        )
        total_score += coherence_score * criteria.get(EvaluationCriterion.COHERENCE, 0.2)
        total_weight += criteria.get(EvaluationCriterion.COHERENCE, 0.2)

        # Creativity: Check for variety in vocabulary
        unique_words = len(set(content.split()))
        vocabulary_diversity = unique_words / max(word_count, 1)
        creativity_score = min(1.0, vocabulary_diversity * 1.5)
        dimension_scores[EvaluationCriterion.CREATIVITY.value] = DimensionScore(
            dimension=EvaluationCriterion.CREATIVITY.value,
            score=creativity_score,
            reason=f"词汇多样性: {vocabulary_diversity:.2f}",
            suggestions=["增加词汇丰富度" if vocabulary_diversity < 0.5 else "词汇丰富度良好"],
        )
        total_score += creativity_score * criteria.get(EvaluationCriterion.CREATIVITY, 0.2)
        total_weight += criteria.get(EvaluationCriterion.CREATIVITY, 0.2)

        # Quality: Check for basic grammar indicators
        quality_score = 0.8  # Default good score
        issues = []
        if content.count("。") < content_length / 200:
            issues.append("句子结尾标点可能不足")
            quality_score -= 0.1
        if content.count("\n") < content_length / 1000:
            issues.append("段落划分可能不足")
            quality_score -= 0.1
        dimension_scores[EvaluationCriterion.QUALITY.value] = DimensionScore(
            dimension=EvaluationCriterion.QUALITY.value,
            score=max(0.5, quality_score),
            reason="基础格式检查",
            suggestions=issues if issues else ["格式良好"],
        )
        total_score += quality_score * criteria.get(EvaluationCriterion.QUALITY, 0.2)
        total_weight += criteria.get(EvaluationCriterion.QUALITY, 0.2)

        # Consistency and goal alignment: Default scores
        for criterion in [EvaluationCriterion.CONSISTENCY, EvaluationCriterion.GOAL_ALIGNMENT]:
            if criterion in criteria:
                default_score = 0.7
                dimension_scores[criterion.value] = DimensionScore(
                    dimension=criterion.value,
                    score=default_score,
                    reason="基于规则的默认评估",
                    suggestions=["建议使用LLM进行更准确的评估"],
                )
                total_score += default_score * criteria[criterion]
                total_weight += criteria[criterion]

        # Calculate overall score
        overall_score = total_score / total_weight if total_weight > 0 else 0.7

        all_reasons = [f"{d.dimension}: {d.reason}" for d in dimension_scores.values()]
        all_suggestions = []
        for d in dimension_scores.values():
            all_suggestions.extend(d.suggestions)

        return EvaluationResult(
            passed=overall_score >= self.passing_threshold,
            score=overall_score,
            dimension_scores=dimension_scores,
            reasons=all_reasons,
            suggestions=all_suggestions,
            evaluator="rule_based",
            metadata={"task_type": task_type},
        )

    def set_passing_threshold(self, threshold: float) -> None:
        """Update the passing threshold"""
        self.passing_threshold = max(0.0, min(1.0, threshold))
        logger.info(f"Updated passing threshold to {self.passing_threshold}")

    def set_criteria(
        self,
        criteria: Dict[EvaluationCriterion, float],
    ) -> None:
        """Update evaluation criteria"""
        # Validate weights sum to approximately 1.0
        total_weight = sum(criteria.values())
        if abs(total_weight - 1.0) > 0.1:
            logger.warning(
                f"Criteria weights sum to {total_weight}, "
                f"expected ~1.0. Normalizing..."
            )
            # Normalize
            self.criteria = {
                k: v / total_weight for k, v in criteria.items()
            }
        else:
            self.criteria = criteria.copy()

        logger.info(f"Updated evaluation criteria: {list(self.criteria.keys())}")

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.39 at 0x10417bb00>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.core.evaluator'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.31 at 0x1047febd0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-28.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-28.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.plugins.event'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Event Plugin - Manages plot events, causality, and conflicts

This plugin handles:
- Plot event tracking and organization
- Event causality and dependencies
- Conflict design and resolution
- Story pacing through events
"""

import json
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class EventPlugin(NovelElementPlugin):
    """
    Plugin for managing plot events and story structure

    Tracks events, their relationships, conflicts, and story progression.
    """

    name = "event"
    version = "1.0.0"
    description = "Manages plot events, causality, and conflicts"
    author = "Creative AutoGPT"

    # Event state storage
    _events: List[Dict[str, Any]] = []
    _conflicts: List[Dict[str, Any]] = []
    _event_graph: Dict[str, List[str]] = {}  # event_id -> dependent event_ids

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._events = []
        self._conflicts = []
        self._event_graph = {}

    async def on_init(self, context: WritingContext) -> None:
        """Initialize event plugin with session context"""
        logger.info(f"EventPlugin initialized for session {context.session_id}")
        if "events" in context.metadata:
            self._events = context.metadata.get("events", [])
        if "conflicts" in context.metadata:
            self._conflicts = context.metadata.get("conflicts", [])

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for event data"""
        return {
            "type": "object",
            "title": "Event Schema",
            "description": "Schema for plot events",
            "properties": {
                "event_id": {
                    "type": "string",
                    "description": "Unique event identifier"
                },
                "name": {
                    "type": "string",
                    "description": "Event name/title"
                },
                "type": {
                    "type": "string",
                    "enum": ["setup", "inciting_incident", "rising_action", "climax", "falling_action", "resolution"],
                    "description": "Story structure type"
                },
                "plot_line": {
                    "type": "string",
                    "enum": ["main", "subplot_1", "subplot_2", "subplot_3"],
                    "description": "Which plot line this belongs to"
                },
                "chapter": {
                    "type": "integer",
                    "description": "Chapter where event occurs"
                },
                "description": {
                    "type": "string",
                    "description": "Event description"
                },
                "trigger": {
                    "type": "string",
                    "description": "What triggers this event"
                },
                "outcome": {
                    "type": "string",
                    "description": "Result of this event"
                },
                "characters_involved": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Character IDs involved"
                },
                "locations": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Location IDs where event occurs"
                },
                "foreshadowing": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Foreshadowing element IDs"
                },
                "conflicts": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Conflict IDs involved"
                },
                "emotional_tone": {
                    "type": "string",
                    "description": "Emotional tone of the event"
                },
                "depends_on": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Event IDs that must happen before this"
                }
            },
            "required": ["event_id", "name", "type", "plot_line"]
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for event-related tasks"""
        return {
            "event_design": """## 任务: 设计情节事件链

### 故事大纲
{outline}

### 事件设计要求

请为小说设计完整的情节事件链:

**主线事件 (10-20个):**
按时间顺序列出主线事件，每个事件包含:
1. **事件名称**: 简洁的事件标题
2. **事件类型**: 开端/激励事件/上升动作/高潮/下降动作/结局
3. **章节位置**: 大约在第几章发生
4. **触发条件**: 什么导致这个事件发生
5. **主要内容**: 事件的具体描述 (100-200字)
6. **结果影响**: 这个事件导致的后果
7. **涉及角色**: 出场的主要角色
8. **涉及场景**: 发生的地点
9. **关联伏笔**: 相关的伏笔元素
10. **情感基调**: 事件的整体情感色彩
11. **冲突内容**: 包含的冲突

**支线事件 (3-5条支线):**
每条支线包含:
- 支线主题
- 起承转合事件
- 与主线的交汇点
- 支线结局

**冲突设计:**
1. **主要冲突**:
   - 冲突类型: (人物对抗/社会对抗/自然对抗/自我对抗/命运对抗)
   - 冲突双方
   - 冲突核心
   - 冲突发展路径
   - 冲突解决方式

2. **次要冲突**: 2-3个次要冲突

3. **冲突升级机制**:
   - 冲突如何逐步升级
   - 转折点设置

请以 JSON 格式输出事件设计。
""",

            "conflict_design": """## 任务: 设计故事冲突

### 事件链
{events}

### 冲突设计要求

请设计故事的核心冲突体系:

**1. 核心冲突 (主线冲突):**
- **冲突类型**: 人物/社会/自然/自我/命运
- **冲突双方**: 明确的对抗双方
- **冲突根源**: 为什么产生冲突
- **冲突表现**: 冲突的具体表现形式
- **冲突升级**: 冲突如何随时间升级
- **高潮时刻**: 冲突的最高点
- **解决方式**: 最终如何解决
- **象征意义**: 冲突的深层含义

**2. 次要冲突 (2-4个):**
每个包含:
- 与主线冲突的关系
- 独立的发展路径
- 对主线的推动作用

**3. 内部冲突:**
- 主角内心的矛盾和挣扎
- 成长面临的内在障碍
- 自我超越的契机

**4. 冲突节奏:**
- 冲突的引入时机
- 冲突的缓解和爆发
- 多冲突的交织

请以 JSON 格式输出。
""",

            "event_pacing": """## 任务: 分析事件节奏

### 事件列表
{events}

### 节奏分析要求

请分析事件链的节奏安排:

1. **节奏变化**:
   - 快节奏段落: 高强度、多事件
   - 慢节奏段落: 心理、铺垫
   - 节奏转换点

2. **张力曲线**:
   - 张力上升阶段
   - 张力释放时刻
   - 张力低谷

3. **情感波动**:
   - 情感高潮
   - 情感低谷
   - 情感转换

4. **改进建议**:
   - 节奏问题
   - 调整建议

请输出结构化的节奏分析报告。
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for event-related operations"""
        return [
            {
                "task_id": "events_design",
                "task_type": "事件",
                "description": "Design plot event chain with causality",
                "depends_on": ["大纲", "人物设计"],
                "metadata": {
                    "plugin": "event",
                    "operation": "design"
                }
            },
            {
                "task_id": "conflict_design",
                "task_type": "冲突设计",
                "description": "Design story conflicts and resolution paths",
                "depends_on": ["事件"],
                "metadata": {
                    "plugin": "event",
                    "operation": "conflicts"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate event data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Event data must be a dictionary"]
            )

        # Check required fields
        required_fields = ["event_id", "name", "type", "plot_line"]
        for field in required_fields:
            if field not in data:
                errors.append(f"Missing required field: {field}")

        # Validate event type
        valid_types = ["setup", "inciting_incident", "rising_action", "climax", "falling_action", "resolution"]
        if "type" in data and data["type"] not in valid_types:
            errors.append(f"Invalid event type: {data['type']}")

        # Check for causality
        if "depends_on" in data and data["depends_on"]:
            for dep_id in data["depends_on"]:
                if not any(e.get("event_id") == dep_id for e in self._events):
                    warnings.append(f"Dependency {dep_id} not found in existing events")

        # Check for emotional content
        if "emotional_tone" not in data:
            suggestions.append("Add emotional tone for better scene writing")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Extract and store event data from task results"""
        task_type = task.get("task_type", "")

        if task_type == "事件":
            await self._extract_events(result, context)
        elif task_type == "冲突设计":
            await self._extract_conflicts(result, context)

        return result

    async def _extract_events(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract event data from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                if isinstance(data, dict) and "events" in data:
                    self._events = data["events"]
                    # Build event dependency graph
                    self._build_event_graph()

                logger.info(f"Extracted {len(self._events)} events")

        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse event data as JSON: {e}")
        except Exception as e:
            logger.error(f"Error extracting events: {e}")

    async def _extract_conflicts(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract conflict data from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                if isinstance(data, dict) and "conflicts" in data:
                    self._conflicts = data["conflicts"]

                logger.info(f"Extracted {len(self._conflicts)} conflicts")

        except Exception as e:
            logger.error(f"Error extracting conflicts: {e}")

    def _build_event_graph(self) -> None:
        """Build event dependency graph"""
        self._event_graph = {}
        for event in self._events:
            event_id = event.get("event_id")
            if event_id:
                self._event_graph[event_id] = event.get("depends_on", [])

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with event information"""
        task_type = task.get("task_type", "")

        # Add event summary for chapter generation
        if "章节" in task_type:
            chapter_index = task.get("metadata", {}).get("chapter_index")
            if chapter_index is not None:
                chapter_events = self._get_events_for_chapter(chapter_index)
                if chapter_events:
                    context["chapter_events"] = chapter_events

        # Add conflicts for relevant tasks
        if self._conflicts and "章节" in task_type:
            context["conflicts"] = self._conflicts

        return context

    def _get_events_for_chapter(self, chapter_index: int) -> List[Dict[str, Any]]:
        """Get events that occur in a specific chapter"""
        return [
            event for event in self._events
            if event.get("chapter") == chapter_index
        ]

    def get_events(self) -> List[Dict[str, Any]]:
        """Get all events"""
        return self._events.copy()

    def get_event(self, event_id: str) -> Optional[Dict[str, Any]]:
        """Get a specific event by ID"""
        for event in self._events:
            if event.get("event_id") == event_id:
                return event
        return None

    def get_conflicts(self) -> List[Dict[str, Any]]:
        """Get all conflicts"""
        return self._conflicts.copy()

    def get_event_chain(self, plot_line: str = "main") -> List[Dict[str, Any]]:
        """Get events for a specific plot line in order"""
        return [
            event for event in self._events
            if event.get("plot_line") == plot_line
        ]

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize event plugin and persist data"""
        logger.info("EventPlugin finalized")
        context.metadata["events"] = self._events
        context.metadata["conflicts"] = self._conflicts
        context.metadata["event_graph"] = self._event_graph

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.31 at 0x1047febd0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.plugins.event'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 166, in _post_build
    self.add_from_names_to_locals(from_node)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 223, in add_from_names_to_locals
    imported = node.do_import_module()
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 341, in infer_import_from
    stmts = module.getattr(name, ignore_locals=module is self.root())
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 412, in getattr
    result = [self.import_module(name, relative_only=True)]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 304, in infer_import
    yield self.do_import_module(self.real_name(name))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-28.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-28.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.utils.config'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""Configuration management for Creative AutoGPT"""

from typing import Optional, List
from pathlib import Path
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """Application settings loaded from environment variables"""

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore",
    )

    # Application
    app_env: str = "development"
    app_debug: bool = True
    app_host: str = "0.0.0.0"
    app_port: int = 8000
    secret_key: str = "change-this-in-production"

    # Database
    database_url: str = "sqlite+aiosqlite:///./data/creative_autogpt.db"

    # Vector Database
    chroma_persist_directory: str = "./data/chroma"
    embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"

    # LLM Configuration
    default_provider: str = "multi"  # multi, aliyun, deepseek, ark
    smart_routing: bool = True
    router_strategy: str = "hybrid"  # hybrid, ai_only, rule_only
    router_cache_ttl: int = 300

    # Default LLM parameters
    default_temperature: float = 0.7
    default_max_tokens: int = 4000
    llm_request_timeout: int = 300  # 5 minutes for long content generation
    max_retries: int = 3

    # Aliyun (Qwen)
    aliyun_api_key: Optional[str] = None
    aliyun_base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1"
    aliyun_model: str = "qwen-long"
    aliyun_enabled: bool = True
    aliyun_embedding_model: str = "text-embedding-v3"
    aliyun_embedding_base_url: str = "https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding-v3"

    # DeepSeek
    deepseek_api_key: Optional[str] = None
    deepseek_base_url: str = "https://api.deepseek.com/v1"
    deepseek_model: str = "deepseek-chat"
    deepseek_enabled: bool = True

    # Ark (Doubao)
    ark_api_key: Optional[str] = None
    ark_base_url: str = "https://ark.cn-beijing.volces.com/api/v3"
    ark_model: str = "ep-20250118094854-wd5pp"
    ark_enabled: bool = True

    # NVIDIA (optional backup)
    nvidia_api_key: Optional[str] = None
    nvidia_base_url: str = "https://integrate.api.nvidia.com/v1/chat/completions"
    nvidia_model: str = "deepseek-ai/DeepSeek-V3"
    nvidia_enabled: bool = False

    # Storage
    storage_type: str = "local"  # local, s3
    local_storage_path: str = "./data/novels"

    # Logging
    log_level: str = "DEBUG"
    log_file: str = "./logs/app.log"
    log_rotation: str = "1 day"
    log_retention: str = "30 days"

    # Performance
    max_concurrent_tasks: int = 5
    worker_pool_size: int = 10

    # CORS
    cors_origins: List[str] = [
        "http://localhost:3000",
        "http://localhost:5173",
        "http://localhost:4173",
    ]

    @property
    def is_development(self) -> bool:
        return self.app_env.lower() in ("development", "dev")

    @property
    def is_production(self) -> bool:
        return self.app_env.lower() in ("production", "prod")

    def get_data_dir(self) -> Path:
        """Get data directory path, creating if needed"""
        data_dir = Path("./data")
        data_dir.mkdir(exist_ok=True)
        return data_dir

    def get_logs_dir(self) -> Path:
        """Get logs directory path, creating if needed"""
        logs_dir = Path("./logs")
        logs_dir.mkdir(exist_ok=True)
        return logs_dir


# Global settings instance
_settings: Optional[Settings] = None


def get_settings() -> Settings:
    """Get global settings instance, creating if needed"""
    global _settings
    if _settings is None:
        _settings = Settings()
    return _settings


def reset_settings() -> None:
    """Reset global settings instance (mainly for testing)"""
    global _settings
    _settings = None

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 166, in _post_build
    self.add_from_names_to_locals(from_node)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 223, in add_from_names_to_locals
    imported = node.do_import_module()
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 341, in infer_import_from
    stmts = module.getattr(name, ignore_locals=module is self.root())
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 412, in getattr
    result = [self.import_module(name, relative_only=True)]
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 304, in infer_import
    yield self.do_import_module(self.real_name(name))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.utils.config'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.57 at 0x104f505c0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-29.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-29.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.utils.llm_client'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Multi-LLM Client with intelligent routing and fallback support

Supports Aliyun (Qwen), DeepSeek, Ark (Doubao), and NVIDIA providers.
Implements task-type-based routing for optimal LLM selection.
"""

import asyncio
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Union, Tuple
import json

import httpx
from loguru import logger
from openai import AsyncOpenAI, APIError, APIConnectionError, RateLimitError

from creative_autogpt.utils.config import get_settings


class LLMProvider(str, Enum):
    """Supported LLM providers"""

    ALIYUN = "aliyun"  # Qwen
    DEEPSEEK = "deepseek"
    ARK = "ark"  # Doubao
    NVIDIA = "nvidia"


@dataclass
class LLMUsage:
    """Token usage information"""

    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0

    def to_dict(self) -> Dict[str, int]:
        return {
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "total_tokens": self.total_tokens,
        }


@dataclass
class LLMResponse:
    """Response from LLM generation"""

    content: str
    model: str
    provider: LLMProvider
    usage: LLMUsage
    raw_response: Optional[Dict[str, Any]] = None
    cached: bool = False
    generation_time: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "content": self.content,
            "model": self.model,
            "provider": self.provider.value,
            "usage": self.usage.to_dict(),
            "cached": self.cached,
            "generation_time": self.generation_time,
        }


@dataclass
class LLMMessage:
    """Chat message"""

    role: str  # system, user, assistant
    content: str

    def to_dict(self) -> Dict[str, str]:
        return {"role": self.role, "content": self.content}


class LLMClientBase(ABC):
    """Base class for LLM clients"""

    def __init__(
        self,
        api_key: str,
        base_url: str,
        model: str,
        timeout: int = 120,
        max_retries: int = 3,
    ):
        self.api_key = api_key
        self.base_url = base_url
        self.model = model
        self.timeout = timeout
        self.max_retries = max_retries

        # Create async OpenAI client (works with OpenAI-compatible APIs)
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url,
            timeout=timeout,
            max_retries=max_retries,
        )

    @property
    @abstractmethod
    def provider(self) -> LLMProvider:
        """Return the provider type"""
        pass

    @abstractmethod
    async def generate(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        **kwargs,
    ) -> LLMResponse:
        """
        Generate text from the LLM

        Args:
            prompt: The prompt to generate from
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
            messages: Optional list of messages for chat completion
            **kwargs: Additional parameters

        Returns:
            LLMResponse with generated content and metadata
        """
        pass

    async def _generate_with_retry(
        self,
        messages: List[Dict[str, str]],
        temperature: float,
        max_tokens: int,
        **kwargs,
    ) -> Tuple[str, LLMUsage, Dict[str, Any]]:
        """Internal method with enhanced retry logic and exponential backoff"""

        last_error = None
        # 增加重试次数到 5 次
        max_retries = max(self.max_retries, 5)
        
        for attempt in range(max_retries):
            try:
                logger.debug(f"LLM request attempt {attempt + 1}/{max_retries} for {self.provider.value}")
                
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    **kwargs,
                )

                content = response.choices[0].message.content or ""

                usage = LLMUsage(
                    prompt_tokens=response.usage.prompt_tokens if response.usage else 0,
                    completion_tokens=response.usage.completion_tokens if response.usage else 0,
                    total_tokens=response.usage.total_tokens if response.usage else 0,
                )

                raw = response.model_dump() if hasattr(response, "model_dump") else {}
                
                logger.debug(f"LLM request successful on attempt {attempt + 1}")
                return content, usage, raw

            except RateLimitError as e:
                last_error = e
                wait_time = min(2 ** attempt * 2, 60)  # 指数退避，最多等60秒
                logger.warning(
                    f"Rate limit hit for {self.provider.value}, "
                    f"waiting {wait_time}s before retry {attempt + 1}/{max_retries}"
                )
                await asyncio.sleep(wait_time)

            except (APIConnectionError, APIError) as e:
                last_error = e
                wait_time = min(2 ** attempt * 2, 30)  # 指数退避
                logger.warning(
                    f"API error for {self.provider.value}: {e}, "
                    f"waiting {wait_time}s before retry {attempt + 1}/{max_retries}"
                )
                if attempt < max_retries - 1:
                    await asyncio.sleep(wait_time)
                    
            except asyncio.TimeoutError as e:
                last_error = e
                wait_time = min(2 ** attempt * 3, 45)  # 超时用更长的退避时间
                logger.warning(
                    f"⏰ Timeout for {self.provider.value}, "
                    f"waiting {wait_time}s before retry {attempt + 1}/{max_retries}"
                )
                if attempt < max_retries - 1:
                    await asyncio.sleep(wait_time)
                    
            except Exception as e:
                # Catch any other errors (including httpx timeout)
                last_error = e
                error_str = str(e).lower()
                if "timeout" in error_str or "timed out" in error_str or "read timed out" in error_str:
                    wait_time = min(2 ** attempt * 3, 45)  # 超时用更长的退避时间
                    logger.warning(
                        f"⏰ Request timeout for {self.provider.value}: {e}, "
                        f"waiting {wait_time}s before retry {attempt + 1}/{max_retries}"
                    )
                    if attempt < max_retries - 1:
                        await asyncio.sleep(wait_time)
                elif "connection" in error_str:
                    wait_time = min(2 ** attempt * 2, 30)
                    logger.warning(
                        f"🔌 Connection error for {self.provider.value}: {e}, "
                        f"waiting {wait_time}s before retry {attempt + 1}/{max_retries}"
                    )
                    if attempt < max_retries - 1:
                        await asyncio.sleep(wait_time)
                else:
                    # Unknown error, re-raise immediately
                    logger.error(f"Unknown error for {self.provider.value}: {e}")
                    raise

        # All retries failed
        logger.error(f"❌ All {max_retries} retries failed for {self.provider.value}: {last_error}")
        raise APIError(
            f"All {max_retries} retries failed for {self.provider.value}: {last_error}"
        )


class AliyunLLMClient(LLMClientBase):
    """Aliyun (Qwen) LLM client - optimized for long context and planning"""

    def __init__(self, api_key: str, base_url: str, model: str = "qwen-long", **kwargs):
        super().__init__(api_key=api_key, base_url=base_url, model=model, **kwargs)

    @property
    def provider(self) -> LLMProvider:
        return LLMProvider.ALIYUN

    async def generate(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        **kwargs,
    ) -> LLMResponse:
        """Generate text using Qwen"""

        start_time = time.time()

        # Build messages
        if messages is None:
            messages = [LLMMessage(role="user", content=prompt)]

        message_dicts = [m.to_dict() for m in messages]

        logger.debug(f"Generating with {self.provider.value}, prompt length: {len(prompt)}")

        content, usage, raw = await self._generate_with_retry(
            messages=message_dicts,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )

        generation_time = time.time() - start_time

        logger.info(
            f"Generated {len(content)} chars with {self.provider.value} "
            f"in {generation_time:.2f}s, tokens: {usage.total_tokens}"
        )

        return LLMResponse(
            content=content,
            model=self.model,
            provider=self.provider,
            usage=usage,
            raw_response=raw,
            generation_time=generation_time,
        )


class DeepSeekLLMClient(LLMClientBase):
    """DeepSeek LLM client - optimized for logic and reasoning"""

    def __init__(self, api_key: str, base_url: str, model: str = "deepseek-chat", **kwargs):
        super().__init__(api_key=api_key, base_url=base_url, model=model, **kwargs)

    @property
    def provider(self) -> LLMProvider:
        return LLMProvider.DEEPSEEK

    async def generate(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        **kwargs,
    ) -> LLMResponse:
        """Generate text using DeepSeek"""

        start_time = time.time()

        # Build messages
        if messages is None:
            messages = [LLMMessage(role="user", content=prompt)]

        message_dicts = [m.to_dict() for m in messages]

        logger.debug(f"Generating with {self.provider.value}, prompt length: {len(prompt)}")

        content, usage, raw = await self._generate_with_retry(
            messages=message_dicts,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )

        generation_time = time.time() - start_time

        logger.info(
            f"Generated {len(content)} chars with {self.provider.value} "
            f"in {generation_time:.2f}s, tokens: {usage.total_tokens}"
        )

        return LLMResponse(
            content=content,
            model=self.model,
            provider=self.provider,
            usage=usage,
            raw_response=raw,
            generation_time=generation_time,
        )


class ArkLLMClient(LLMClientBase):
    """Ark (Doubao) LLM client - optimized for creative writing"""

    def __init__(
        self,
        api_key: str,
        base_url: str,
        model: str = "ep-20250118094854-wd5pp",
        **kwargs,
    ):
        super().__init__(api_key=api_key, base_url=base_url, model=model, **kwargs)

    @property
    def provider(self) -> LLMProvider:
        return LLMProvider.ARK

    async def generate(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        **kwargs,
    ) -> LLMResponse:
        """Generate text using Doubao"""

        start_time = time.time()

        # Build messages
        if messages is None:
            messages = [LLMMessage(role="user", content=prompt)]

        message_dicts = [m.to_dict() for m in messages]

        logger.debug(f"Generating with {self.provider.value}, prompt length: {len(prompt)}")

        content, usage, raw = await self._generate_with_retry(
            messages=message_dicts,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )

        generation_time = time.time() - start_time

        logger.info(
            f"Generated {len(content)} chars with {self.provider.value} "
            f"in {generation_time:.2f}s, tokens: {usage.total_tokens}"
        )

        return LLMResponse(
            content=content,
            model=self.model,
            provider=self.provider,
            usage=usage,
            raw_response=raw,
            generation_time=generation_time,
        )


class NvidiaLLMClient(LLMClientBase):
    """NVIDIA LLM client - backup provider using NVIDIA's API gateway"""

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://integrate.api.nvidia.com/v1/chat/completions",
        model: str = "deepseek-ai/DeepSeek-V3",
        **kwargs,
    ):
        super().__init__(api_key=api_key, base_url=base_url, model=model, **kwargs)

    @property
    def provider(self) -> LLMProvider:
        return LLMProvider.NVIDIA

    async def generate(
        self,
        prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        **kwargs,
    ) -> LLMResponse:
        """Generate text using NVIDIA API"""

        start_time = time.time()

        # Build messages
        if messages is None:
            messages = [LLMMessage(role="user", content=prompt)]

        message_dicts = [m.to_dict() for m in messages]

        logger.debug(f"Generating with {self.provider.value}, prompt length: {len(prompt)}")

        content, usage, raw = await self._generate_with_retry(
            messages=message_dicts,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs,
        )

        generation_time = time.time() - start_time

        logger.info(
            f"Generated {len(content)} chars with {self.provider.value} "
            f"in {generation_time:.2f}s, tokens: {usage.total_tokens}"
        )

        return LLMResponse(
            content=content,
            model=self.model,
            provider=self.provider,
            usage=usage,
            raw_response=raw,
            generation_time=generation_time,
        )


class MultiLLMClient:
    """
    Multi-LLM client with intelligent task-type routing

    Routes different task types to the optimal LLM:
    - Qwen (Aliyun): Planning, outlining, character design, worldview (long context)
    - DeepSeek: Logic, evaluation, consistency checks (strong reasoning)
    - Doubao (Ark): Creative content, dialogue, prose (literary quality)
    """

    # Default task type routing map
    DEFAULT_TASK_TYPE_MAP: Dict[str, LLMProvider] = {
        # Planning tasks → Qwen (long context, global memory)
        "大纲": LLMProvider.ALIYUN,
        "outline": LLMProvider.ALIYUN,
        "风格元素": LLMProvider.ALIYUN,
        "style_elements": LLMProvider.ALIYUN,
        "人物设计": LLMProvider.ALIYUN,
        "character_design": LLMProvider.ALIYUN,
        "主题确认": LLMProvider.ALIYUN,
        "theme_confirmation": LLMProvider.ALIYUN,
        "市场定位": LLMProvider.ALIYUN,
        "market_positioning": LLMProvider.ALIYUN,
        "世界观规则": LLMProvider.ALIYUN,
        "worldview": LLMProvider.ALIYUN,
        "世界观": LLMProvider.ALIYUN,

        # Logic tasks → DeepSeek (strong reasoning, cost-effective)
        "事件": LLMProvider.DEEPSEEK,
        "events": LLMProvider.DEEPSEEK,
        "场景物品冲突": LLMProvider.DEEPSEEK,
        "scenes_items_conflicts": LLMProvider.DEEPSEEK,
        "场景": LLMProvider.DEEPSEEK,
        "评估": LLMProvider.DEEPSEEK,
        "evaluation": LLMProvider.DEEPSEEK,
        "一致性检查": LLMProvider.DEEPSEEK,
        "consistency_check": LLMProvider.DEEPSEEK,
        "时间线检查": LLMProvider.DEEPSEEK,
        "timeline_check": LLMProvider.DEEPSEEK,
        "伏笔列表": LLMProvider.DEEPSEEK,
        "foreshadow_list": LLMProvider.DEEPSEEK,

        # Creative tasks → Doubao (literary quality)
        "章节内容": LLMProvider.ARK,
        "chapter_content": LLMProvider.ARK,
        "章节": LLMProvider.ARK,
        "chapter": LLMProvider.ARK,
        "修订": LLMProvider.ARK,
        "revision": LLMProvider.ARK,
        "润色": LLMProvider.ARK,
        "polish": LLMProvider.ARK,
        "对话检查": LLMProvider.ARK,
        "dialogue_check": LLMProvider.ARK,
    }

    def __init__(
        self,
        providers: Optional[List[LLMClientBase]] = None,
        task_type_map: Optional[Dict[str, LLMProvider]] = None,
        default_provider: LLMProvider = LLMProvider.ARK,
        fallback_order: Optional[List[LLMProvider]] = None,
    ):
        """
        Initialize multi-LLM client

        Args:
            providers: List of LLM clients (if None, will create from settings)
            task_type_map: Custom task type routing map
            default_provider: Default provider if task type not found
            fallback_order: Fallback order for failed requests
        """
        settings = get_settings()

        # Create providers from settings if not provided
        if providers is None:
            providers = self._create_providers_from_settings(settings)

        self.providers: Dict[LLMProvider, LLMClientBase] = {
            p.provider: p for p in providers if p is not None
        }

        # Use default task type map or custom
        self.task_type_map = task_type_map or self.DEFAULT_TASK_TYPE_MAP.copy()

        # Set default provider
        self.default_provider = default_provider

        # Fallback order (try alternatives in this order)
        self.fallback_order = fallback_order or [
            LLMProvider.ALIYUN,
            LLMProvider.DEEPSEEK,
            LLMProvider.ARK,
            LLMProvider.NVIDIA,
        ]

        # Remove providers that aren't available from fallback order
        self.fallback_order = [p for p in self.fallback_order if p in self.providers]

        logger.info(
            f"MultiLLMClient initialized with providers: {list(self.providers.keys())}"
        )

    def _create_providers_from_settings(self, settings) -> List[Optional[LLMClientBase]]:
        """Create LLM providers from application settings"""
        providers = []

        # Aliyun (Qwen)
        if settings.aliyun_enabled and settings.aliyun_api_key:
            providers.append(
                AliyunLLMClient(
                    api_key=settings.aliyun_api_key,
                    base_url=settings.aliyun_base_url,
                    model=settings.aliyun_model,
                    timeout=settings.llm_request_timeout,
                    max_retries=settings.max_retries,
                )
            )
            logger.info("Aliyun (Qwen) provider enabled")
        else:
            providers.append(None)
            logger.warning("Aliyun (Qwen) provider disabled or missing API key")

        # DeepSeek
        if settings.deepseek_enabled and settings.deepseek_api_key:
            providers.append(
                DeepSeekLLMClient(
                    api_key=settings.deepseek_api_key,
                    base_url=settings.deepseek_base_url,
                    model=settings.deepseek_model,
                    timeout=settings.llm_request_timeout,
                    max_retries=settings.max_retries,
                )
            )
            logger.info("DeepSeek provider enabled")
        else:
            providers.append(None)
            logger.warning("DeepSeek provider disabled or missing API key")

        # Ark (Doubao)
        if settings.ark_enabled and settings.ark_api_key:
            providers.append(
                ArkLLMClient(
                    api_key=settings.ark_api_key,
                    base_url=settings.ark_base_url,
                    model=settings.ark_model,
                    timeout=settings.llm_request_timeout,
                    max_retries=settings.max_retries,
                )
            )
            logger.info("Ark (Doubao) provider enabled")
        else:
            providers.append(None)
            logger.warning("Ark (Doubao) provider disabled or missing API key")

        # NVIDIA (optional backup)
        if settings.nvidia_enabled and settings.nvidia_api_key:
            providers.append(
                NvidiaLLMClient(
                    api_key=settings.nvidia_api_key,
                    base_url=settings.nvidia_base_url,
                    model=settings.nvidia_model,
                    timeout=settings.llm_request_timeout,
                    max_retries=settings.max_retries,
                )
            )
            logger.info("NVIDIA provider enabled")
        else:
            providers.append(None)

        return [p for p in providers if p is not None]

    def _select_provider(self, task_type: Optional[str]) -> LLMProvider:
        """
        Select the optimal provider for a given task type

        Args:
            task_type: The type of task

        Returns:
            Selected LLM provider
        """
        if task_type and task_type in self.task_type_map:
            provider = self.task_type_map[task_type]
            if provider in self.providers:
                logger.debug(f"Routed task '{task_type}' to {provider.value}")
                return provider
            else:
                logger.warning(
                    f"Task '{task_type}' mapped to {provider.value}, but provider not available"
                )

        # Use default provider
        logger.debug(f"Using default provider {self.default_provider.value} for task '{task_type}'")
        return self.default_provider

    def _get_fallback_order(self, primary: LLMProvider) -> List[LLMProvider]:
        """Get fallback order excluding the primary provider"""
        return [p for p in self.fallback_order if p != primary and p in self.providers]

    async def generate(
        self,
        prompt: str,
        task_type: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        llm: Optional[str] = None,
        **kwargs,
    ) -> LLMResponse:
        """
        Generate text with intelligent routing and fallback

        Args:
            prompt: The prompt to generate from
            task_type: The type of task (for routing)
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
            messages: Optional list of messages for chat completion
            llm: Override LLM selection (provider name)
            **kwargs: Additional parameters

        Returns:
            LLMResponse with generated content and metadata

        Raises:
            APIError: If all providers fail
        """
        # Select provider
        if llm:
            # Manual override
            try:
                primary_provider = LLMProvider(llm.lower())
            except ValueError:
                logger.warning(f"Invalid provider '{llm}', using default")
                primary_provider = self.default_provider
        else:
            # Use task-based routing
            primary_provider = self._select_provider(task_type)

        # Try primary provider first, then fallbacks
        providers_to_try = [primary_provider] + self._get_fallback_order(primary_provider)

        last_error = None
        for provider in providers_to_try:
            if provider not in self.providers:
                continue

            client = self.providers[provider]
            try:
                logger.info(f"Generating with {provider.value} for task '{task_type}'")
                response = await client.generate(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    messages=messages,
                    **kwargs,
                )
                return response

            except Exception as e:
                last_error = e
                logger.warning(
                    f"Provider {provider.value} failed for task '{task_type}': {e}"
                )
                continue

        # All providers failed
        raise APIError(
            f"All providers failed for task '{task_type}': {last_error}"
        )

    async def generate_stream(
        self,
        prompt: str,
        task_type: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 4000,
        messages: Optional[List[LLMMessage]] = None,
        **kwargs,
    ):
        """
        Generate text with streaming response

        Args:
            prompt: The prompt to generate from
            task_type: The type of task (for routing)
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
            messages: Optional list of messages for chat completion
            **kwargs: Additional parameters

        Yields:
            Chunks of generated text
        """
        # Select provider
        primary_provider = self._select_provider(task_type)
        client = self.providers[primary_provider]

        # Build messages
        if messages is None:
            messages = [LLMMessage(role="user", content=prompt)]

        message_dicts = [m.to_dict() for m in messages]

        logger.info(f"Streaming with {primary_provider.value} for task '{task_type}'")

        try:
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=message_dicts,
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True,
                **kwargs,
            )

            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            logger.error(f"Streaming failed for {primary_provider.value}: {e}")
            raise

    def get_available_providers(self) -> List[str]:
        """Get list of available provider names"""
        return [p.value for p in self.providers.keys()]

    def add_task_type_mapping(self, task_type: str, provider: str) -> None:
        """
        Add or update a task type mapping

        Args:
            task_type: The task type name
            provider: The provider name (aliyun, deepseek, ark, nvidia)
        """
        try:
            provider_enum = LLMProvider(provider.lower())
            self.task_type_map[task_type] = provider_enum
            logger.info(f"Added mapping: {task_type} -> {provider}")
        except ValueError:
            logger.error(f"Invalid provider: {provider}")

    def get_task_type_mapping(self) -> Dict[str, str]:
        """Get all task type mappings as provider names"""
        return {k: v.value for k, v in self.task_type_map.items()}

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.57 at 0x104f505c0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 39, in _transform
    ret = transform_func(node)
          ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 66, in dataclass_transform
    for assign_node in _get_dataclass_attributes(node):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 126, in _get_dataclass_attributes
    if _is_class_var(assign_node.annotation):  # type: ignore[arg-type]
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 546, in _is_class_var
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.utils.llm_client'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1865, in _class_type
    name = _class_type(base, ancestors)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 426, in infer_subscript
    for value in self.value.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 304, in infer_import
    yield self.do_import_module(self.real_name(name))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-29.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-29.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.storage.vector_store'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Vector store for semantic memory and context retrieval

Uses ChromaDB for vector storage and retrieval with configurable embeddings.
Supports Aliyun embeddings as the primary provider.
"""

import os
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import chromadb
from chromadb.config import Settings as ChromaSettings
from chromadb.utils import embedding_functions
from loguru import logger

from creative_autogpt.utils.config import get_settings


class MemoryType(str, Enum):
    """Types of memory entries"""

    CHARACTER = "character"
    PLOT = "plot"
    SETTING = "setting"
    DIALOGUE = "dialogue"
    WORLDVIEW = "worldview"
    FORESHADOW = "foreshadow"
    SCENE = "scene"
    CHAPTER = "chapter"
    OUTLINE = "outline"
    GENERAL = "general"


@dataclass
class VectorMemoryItem:
    """An item stored in vector memory"""

    id: str
    content: str
    memory_type: MemoryType
    metadata: Dict[str, Any] = field(default_factory=dict)
    task_id: Optional[str] = None
    chapter_index: Optional[int] = None
    created_at: datetime = field(default_factory=datetime.utcnow)
    embedding: Optional[List[float]] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "content": self.content,
            "memory_type": self.memory_type.value,
            "metadata": self.metadata,
            "task_id": self.task_id,
            "chapter_index": self.chapter_index,
            "created_at": self.created_at.isoformat(),
        }


@dataclass
class SearchResult:
    """A search result from vector memory"""

    item: VectorMemoryItem
    score: float
    distance: Optional[float] = None


class VectorStore:
    """
    Vector store for semantic memory using ChromaDB

    Provides:
    - Storage of text with vector embeddings
    - Semantic search/retrieval
    - Context-aware memory management
    - Chapter-scoped memory isolation
    """

    def __init__(
        self,
        persist_directory: Optional[str] = None,
        collection_name: str = "creative_autogpt",
        embedding_model: Optional[str] = None,
    ):
        """
        Initialize vector store

        Args:
            persist_directory: Directory to persist ChromaDB data
            collection_name: Name of the ChromaDB collection
            embedding_model: Name/path of embedding model
        """
        settings = get_settings()

        self.persist_directory = persist_directory or settings.chroma_persist_directory
        self.collection_name = collection_name
        self.embedding_model = embedding_model or settings.embedding_model

        # Ensure persist directory exists
        Path(self.persist_directory).mkdir(parents=True, exist_ok=True)

        # Initialize ChromaDB client
        self.client = chromadb.PersistentClient(
            path=self.persist_directory,
            settings=ChromaSettings(
                anonymized_telemetry=False,
                allow_reset=True,
            ),
        )

        # Initialize embedding function
        self.embedding_function = self._create_embedding_function()

        # Get or create collection
        self.collection = self.client.get_or_create_collection(
            name=self.collection_name,
            embedding_function=self.embedding_function,
            metadata={"description": "Creative AutoGPT memory collection"},
        )

        logger.info(
            f"VectorStore initialized with {self.collection.count()} existing items"
        )

    def _create_embedding_function(self):
        """Create embedding function based on configuration"""
        settings = get_settings()

        # Try to use Aliyun embeddings if API key is available
        if settings.aliyun_api_key and settings.aliyun_embedding_base_url:
            try:
                # Create a custom embedding function for Aliyun
                import dashscope

                class AliyunEmbeddingFunction(embedding_functions.EmbeddingFunction):
                    def __init__(self, api_key: str, model: str = "text-embedding-v3"):
                        self.api_key = api_key
                        self.model = model
                        dashscope.api_key = api_key

                    def __call__(self, texts: List[str]) -> List[List[float]]:
                        """Generate embeddings for texts"""
                        import numpy as np

                        embeddings = []
                        for text in texts:
                            try:
                                response = dashscope.TextEmbedding.call(
                                    model=self.model,
                                    input=text,
                                    text_type="document",
                                )
                                if response.status_code == 200:
                                    emb = response.output["embeddings"][0]["embedding"]
                                    embeddings.append(emb)
                                else:
                                    logger.warning(
                                        f"Aliyun embedding failed: {response.message}"
                                    )
                                    # Fallback to zeros
                                    embeddings.append([0.0] * 1024)
                            except Exception as e:
                                logger.error(f"Aliyun embedding error: {e}")
                                embeddings.append([0.0] * 1024)

                        return embeddings

                return AliyunEmbeddingFunction(
                    api_key=settings.aliyun_api_key,
                    model=settings.aliyun_embedding_model,
                )

            except ImportError:
                logger.warning("DashScope not available, falling back to sentence-transformers")
            except Exception as e:
                logger.warning(f"Aliyun embedding setup failed: {e}, falling back")

        # Default to sentence-transformers
        try:
            return embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=self.embedding_model,
                device="cpu",
            )
        except Exception as e:
            logger.error(f"Failed to initialize embedding function: {e}")
            # Fallback to a simple function
            class DummyEmbeddingFunction(embedding_functions.EmbeddingFunction):
                def __call__(self, texts: List[str]) -> List[List[float]]:
                    # Return zero vectors as fallback
                    return [[0.0] * 384 for _ in texts]

            return DummyEmbeddingFunction()

    async def add(
        self,
        content: str,
        memory_type: MemoryType,
        metadata: Optional[Dict[str, Any]] = None,
        task_id: Optional[str] = None,
        chapter_index: Optional[int] = None,
        item_id: Optional[str] = None,
    ) -> str:
        """
        Add an item to vector memory

        Args:
            content: The text content to store
            memory_type: Type of memory
            metadata: Additional metadata
            task_id: Associated task ID
            chapter_index: Associated chapter index
            item_id: Custom ID (auto-generated if None)

        Returns:
            The ID of the added item
        """
        item_id = item_id or str(uuid.uuid4())

        # Prepare metadata
        item_metadata = {
            "memory_type": memory_type.value,
            "created_at": datetime.utcnow().isoformat(),
        }

        if metadata:
            # Filter out None values and complex types (dict, list) as Chroma only accepts str, int, float, bool
            for k, v in metadata.items():
                if v is None:
                    continue
                # Chroma 只支持 str, int, float, bool 类型
                if isinstance(v, (str, int, float, bool)):
                    item_metadata[k] = v
                elif isinstance(v, (dict, list)):
                    # 复杂类型转为 JSON 字符串存储
                    import json
                    try:
                        item_metadata[k] = json.dumps(v, ensure_ascii=False)
                    except:
                        logger.warning(f"Could not serialize metadata key '{k}', skipping")
                else:
                    # 其他类型尝试转为字符串
                    try:
                        item_metadata[k] = str(v)
                    except:
                        logger.warning(f"Could not convert metadata key '{k}' to string, skipping")

        if task_id:
            item_metadata["task_id"] = task_id

        if chapter_index is not None:
            item_metadata["chapter_index"] = chapter_index

        # Add to collection
        try:
            self.collection.add(
                ids=[item_id],
                documents=[content],
                metadatas=[item_metadata],
            )

            logger.debug(
                f"Added item {item_id} to vector store (type: {memory_type.value})"
            )
            return item_id

        except Exception as e:
            logger.error(f"Failed to add item to vector store: {e}")
            raise

    async def add_batch(
        self,
        items: List[Tuple[str, MemoryType, Dict[str, Any]]],
    ) -> List[str]:
        """
        Add multiple items to vector memory

        Args:
            items: List of (content, memory_type, metadata) tuples

        Returns:
            List of item IDs
        """
        ids = []
        documents = []
        metadatas = []

        for content, memory_type, metadata in items:
            item_id = str(uuid.uuid4())
            ids.append(item_id)
            documents.append(content)

            item_metadata = {
                "memory_type": memory_type.value,
                "created_at": datetime.utcnow().isoformat(),
            }
            # Filter out None values as Chroma doesn't accept them
            item_metadata.update({k: v for k, v in metadata.items() if v is not None})
            metadatas.append(item_metadata)

        try:
            self.collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas,
            )

            logger.info(f"Added {len(ids)} items to vector store")
            return ids

        except Exception as e:
            logger.error(f"Failed to add batch to vector store: {e}")
            raise

    async def search(
        self,
        query: str,
        top_k: int = 5,
        memory_type: Optional[MemoryType] = None,
        chapter_index: Optional[int] = None,
        where: Optional[Dict[str, Any]] = None,
        min_score: float = 0.0,
    ) -> List[SearchResult]:
        """
        Search vector memory for similar items

        Args:
            query: Search query text
            top_k: Number of results to return
            memory_type: Filter by memory type
            chapter_index: Filter by chapter index
            where: Additional metadata filters
            min_score: Minimum similarity score (0-1)

        Returns:
            List of search results with scores
        """
        start_time = time.time()

        # Build where clause
        where_clause = {}
        if memory_type:
            where_clause["memory_type"] = memory_type.value
        if chapter_index is not None:
            where_clause["chapter_index"] = chapter_index
        if where:
            where_clause.update(where)

        # Query collection
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k,
                where=where_clause if where_clause else None,
            )

            # Convert to SearchResult objects
            search_results = []
            if results["ids"] and results["ids"][0]:
                for i, item_id in enumerate(results["ids"][0]):
                    # Convert distance to similarity score (ChromaDB uses L2 distance)
                    distance = results["distances"][0][i] if results["distances"] else None
                    score = 1.0 / (1.0 + distance) if distance is not None else 0.0

                    # Filter by minimum score
                    if score < min_score:
                        continue

                    item = VectorMemoryItem(
                        id=item_id,
                        content=results["documents"][0][i],
                        memory_type=MemoryType(
                            results["metadatas"][0][i].get("memory_type", "general")
                        ),
                        metadata=results["metadatas"][0][i],
                        task_id=results["metadatas"][0][i].get("task_id"),
                        chapter_index=results["metadatas"][0][i].get("chapter_index"),
                    )

                    search_results.append(
                        SearchResult(item=item, score=score, distance=distance)
                    )

            elapsed = time.time() - start_time
            logger.debug(
                f"Vector search returned {len(search_results)} results in {elapsed:.3f}s"
            )

            return search_results

        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return []

    async def get_by_id(self, item_id: str) -> Optional[VectorMemoryItem]:
        """
        Get an item by its ID

        Args:
            item_id: The item ID

        Returns:
            The item if found, None otherwise
        """
        try:
            results = self.collection.get(ids=[item_id])

            if results["ids"] and results["ids"][0]:
                return VectorMemoryItem(
                    id=results["ids"][0],
                    content=results["documents"][0],
                    memory_type=MemoryType(
                        results["metadatas"][0].get("memory_type", "general")
                    ),
                    metadata=results["metadatas"][0],
                    task_id=results["metadatas"][0].get("task_id"),
                    chapter_index=results["metadatas"][0].get("chapter_index"),
                )

            return None

        except Exception as e:
            logger.error(f"Failed to get item {item_id}: {e}")
            return None

    async def get_by_task(self, task_id: str) -> List[VectorMemoryItem]:
        """
        Get all items associated with a task

        Args:
            task_id: The task ID

        Returns:
            List of items
        """
        try:
            results = self.collection.get(
                where={"task_id": task_id},
            )

            items = []
            if results["ids"]:
                for i, item_id in enumerate(results["ids"]):
                    items.append(
                        VectorMemoryItem(
                            id=item_id,
                            content=results["documents"][i],
                            memory_type=MemoryType(
                                results["metadatas"][i].get("memory_type", "general")
                            ),
                            metadata=results["metadatas"][i],
                            task_id=results["metadatas"][i].get("task_id"),
                            chapter_index=results["metadatas"][i].get("chapter_index"),
                        )
                    )

            return items

        except Exception as e:
            logger.error(f"Failed to get items for task {task_id}: {e}")
            return []

    async def update(
        self,
        item_id: str,
        content: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        Update an existing item

        Args:
            item_id: The item ID
            content: New content (if updating)
            metadata: New metadata (will be merged with existing)

        Returns:
            True if successful, False otherwise
        """
        try:
            update_data = {"ids": [item_id]}

            if content:
                update_data["documents"] = [content]

            if metadata:
                # Get existing metadata first
                existing = self.collection.get(ids=[item_id])
                if existing["metadatas"]:
                    merged_metadata = existing["metadatas"][0].copy()
                    merged_metadata.update(metadata)
                    update_data["metadatas"] = [merged_metadata]
                else:
                    update_data["metadatas"] = [metadata]

            self.collection.update(**update_data)

            logger.debug(f"Updated item {item_id} in vector store")
            return True

        except Exception as e:
            logger.error(f"Failed to update item {item_id}: {e}")
            return False

    async def delete(self, item_id: str) -> bool:
        """
        Delete an item from vector memory

        Args:
            item_id: The item ID

        Returns:
            True if successful, False otherwise
        """
        try:
            self.collection.delete(ids=[item_id])
            logger.debug(f"Deleted item {item_id} from vector store")
            return True

        except Exception as e:
            logger.error(f"Failed to delete item {item_id}: {e}")
            return False

    async def delete_by_task(self, task_id: str) -> int:
        """
        Delete all items associated with a task

        Args:
            task_id: The task ID

        Returns:
            Number of items deleted
        """
        try:
            # Get items first to count them
            items = await self.get_by_task(task_id)
            item_ids = [item.id for item in items]

            if item_ids:
                self.collection.delete(ids=item_ids)
                logger.info(f"Deleted {len(item_ids)} items for task {task_id}")

            return len(item_ids)

        except Exception as e:
            logger.error(f"Failed to delete items for task {task_id}: {e}")
            return 0

    async def get_recent(
        self,
        limit: int = 10,
        memory_type: Optional[MemoryType] = None,
    ) -> List[VectorMemoryItem]:
        """
        Get recent items from memory

        Args:
            limit: Maximum number of items to return
            memory_type: Filter by memory type

        Returns:
            List of recent items
        """
        try:
            where_clause = {"memory_type": memory_type.value} if memory_type else None

            results = self.collection.get(
                where=where_clause,
                limit=limit,
            )

            items = []
            if results["ids"]:
                for i, item_id in enumerate(results["ids"]):
                    items.append(
                        VectorMemoryItem(
                            id=item_id,
                            content=results["documents"][i],
                            memory_type=MemoryType(
                                results["metadatas"][i].get("memory_type", "general")
                            ),
                            metadata=results["metadatas"][i],
                            task_id=results["metadatas"][i].get("task_id"),
                            chapter_index=results["metadatas"][i].get("chapter_index"),
                        )
                    )

            # Sort by created_at descending
            items.sort(key=lambda x: x.created_at, reverse=True)

            return items[:limit]

        except Exception as e:
            logger.error(f"Failed to get recent items: {e}")
            return []

    def count(self) -> int:
        """Get total number of items in the store"""
        return self.collection.count()

    async def clear(self) -> bool:
        """
        Clear all items from the store

        Returns:
            True if successful
        """
        try:
            self.client.delete_collection(name=self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                embedding_function=self.embedding_function,
            )
            logger.info(f"Cleared vector store '{self.collection_name}'")
            return True

        except Exception as e:
            logger.error(f"Failed to clear vector store: {e}")
            return False

    async def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the vector store

        Returns:
            Dictionary with stats
        """
        try:
            # Count by memory type
            all_items = self.collection.get()
            type_counts = {}

            if all_items["metadatas"]:
                for metadata in all_items["metadatas"]:
                    memory_type = metadata.get("memory_type", "general")
                    type_counts[memory_type] = type_counts.get(memory_type, 0) + 1

            return {
                "total_items": self.count(),
                "type_counts": type_counts,
                "collection_name": self.collection_name,
                "persist_directory": self.persist_directory,
            }

        except Exception as e:
            logger.error(f"Failed to get stats: {e}")
            return {
                "total_items": 0,
                "type_counts": {},
                "error": str(e),
            }

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1865, in _class_type
    name = _class_type(base, ancestors)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 426, in infer_subscript
    for value in self.value.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 304, in infer_import
    yield self.do_import_module(self.real_name(name))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.storage.vector_store'
```
.
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 270, in infer_call
    for callee in self.func.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 430, in infer_subscript
    for index in self.slice.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 270, in infer_call
    for callee in self.func.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-29.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-29.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ``Building error when trying to create ast representation of module 'creative_autogpt.storage.session'`` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Session Storage - Manages writing session persistence

Handles session state, task results, and checkpoint management.
"""

import json
import uuid
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional

import aiosqlite
from loguru import logger
from sqlalchemy import Column, String, Integer, Float, Text, DateTime, Boolean, JSON, select, delete
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.orm import declarative_base

from creative_autogpt.utils.config import get_settings


Base_Model = declarative_base()


class SessionStatus(str, Enum):
    """Status of a writing session"""

    CREATED = "created"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class SessionModel(Base_Model):
    """SQLAlchemy model for sessions"""

    __tablename__ = "sessions"

    id = Column(String, primary_key=True)
    title = Column(String, nullable=False)
    mode = Column(String, nullable=False, default="novel")
    status = Column(String, nullable=False, default=SessionStatus.CREATED.value)
    goal = Column(JSON, nullable=True)
    config = Column(JSON, nullable=True)
    created_at = Column(DateTime, nullable=False, default=datetime.utcnow)
    updated_at = Column(DateTime, nullable=False, default=datetime.utcnow, onupdate=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)
    total_tasks = Column(Integer, default=0)
    completed_tasks = Column(Integer, default=0)
    failed_tasks = Column(Integer, default=0)
    llm_calls = Column(Integer, default=0)
    tokens_used = Column(Integer, default=0)


class TaskResultModel(Base_Model):
    """SQLAlchemy model for task results"""

    __tablename__ = "task_results"

    id = Column(String, primary_key=True)
    session_id = Column(String, nullable=False, index=True)
    task_id = Column(String, nullable=False, index=True)
    task_type = Column(String, nullable=False)
    status = Column(String, nullable=False)
    result = Column(Text, nullable=True)
    error = Column(Text, nullable=True)
    task_metadata = Column(JSON, nullable=True)
    evaluation = Column(JSON, nullable=True)
    created_at = Column(DateTime, nullable=False, default=datetime.utcnow)
    chapter_index = Column(Integer, nullable=True)


class SessionStorage:
    """
    Storage for writing sessions

    Manages:
    - Session creation and retrieval
    - Session state updates
    - Task result storage
    - Checkpoint management
    """

    def __init__(self, db_url: Optional[str] = None):
        """
        Initialize session storage

        Args:
            db_url: Database URL (uses settings if None)
        """
        settings = get_settings()
        self.db_url = db_url or settings.database_url

        # Create async engine
        self.engine = create_async_engine(
            self.db_url,
            echo=settings.is_development,
        )

        # Create session factory
        self.session_factory = async_sessionmaker(
            self.engine,
            class_=AsyncSession,
            expire_on_commit=False,
        )

        logger.info(f"SessionStorage initialized with DB: {self.db_url}")

    async def initialize(self) -> None:
        """Initialize database tables"""
        async with self.engine.begin() as conn:
            await conn.run_sync(Base_Model.metadata.create_all)

        logger.info("Database tables initialized")

    async def create_session(
        self,
        title: str,
        mode: str = "novel",
        goal: Optional[Dict[str, Any]] = None,
        config: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Create a new writing session

        Args:
            title: Session title
            mode: Writing mode
            goal: Creation goal
            config: Session configuration

        Returns:
            Session ID
        """
        session_id = str(uuid.uuid4())

        async with self.session_factory() as session:
            db_session = SessionModel(
                id=session_id,
                title=title,
                mode=mode,
                status=SessionStatus.CREATED.value,
                goal=goal or {},
                config=config or {},
            )

            session.add(db_session)
            await session.commit()

        logger.info(f"Created session {session_id}: {title}")
        return session_id

    async def get_session(self, session_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a session by ID

        Args:
            session_id: The session ID

        Returns:
            Session data or None
        """
        async with self.session_factory() as session:
            result = await session.get(SessionModel, session_id)

            if result:
                return {
                    "id": result.id,
                    "title": result.title,
                    "mode": result.mode,
                    "status": result.status,
                    "goal": result.goal,
                    "config": result.config,
                    "created_at": result.created_at.isoformat(),
                    "updated_at": result.updated_at.isoformat(),
                    "completed_at": result.completed_at.isoformat() if result.completed_at else None,
                    "total_tasks": result.total_tasks,
                    "completed_tasks": result.completed_tasks,
                    "failed_tasks": result.failed_tasks,
                    "llm_calls": result.llm_calls,
                    "tokens_used": result.tokens_used,
                }

        return None

    async def list_sessions(
        self,
        status: Optional[str] = None,
        limit: int = 50,
        offset: int = 0,
    ) -> List[Dict[str, Any]]:
        """
        List sessions

        Args:
            status: Filter by status
            limit: Maximum number to return
            offset: Offset for pagination

        Returns:
            List of sessions
        """
        async with self.session_factory() as session:
            stmt = select(SessionModel)

            if status:
                stmt = stmt.where(SessionModel.status == status)

            stmt = stmt.order_by(SessionModel.created_at.desc())
            stmt = stmt.limit(limit).offset(offset)

            result = await session.execute(stmt)
            sessions = result.scalars().all()

            return [
                {
                    "id": s.id,
                    "title": s.title,
                    "mode": s.mode,
                    "status": s.status,
                    "goal": s.goal or {},
                    "config": s.config or {},
                    "created_at": s.created_at.isoformat(),
                    "updated_at": s.updated_at.isoformat(),
                    "completed_at": s.completed_at.isoformat() if s.completed_at else None,
                    "total_tasks": s.total_tasks,
                    "completed_tasks": s.completed_tasks,
                    "failed_tasks": s.failed_tasks,
                    "llm_calls": s.llm_calls or 0,
                    "tokens_used": s.tokens_used or 0,
                }
                for s in sessions
            ]

    async def update_session_status(
        self,
        session_id: str,
        status: SessionStatus,
    ) -> bool:
        """
        Update session status

        Args:
            session_id: The session ID
            status: New status

        Returns:
            True if successful
        """
        async with self.session_factory() as session:
            result = await session.get(SessionModel, session_id)

            if result:
                result.status = status.value

                if status == SessionStatus.COMPLETED:
                    result.completed_at = datetime.utcnow()

                await session.commit()
                return True

        return False

    async def update_session_progress(
        self,
        session_id: str,
        total_tasks: Optional[int] = None,
        completed_tasks: Optional[int] = None,
        failed_tasks: Optional[int] = None,
        llm_calls: Optional[int] = None,
        tokens_used: Optional[int] = None,
    ) -> bool:
        """
        Update session progress statistics

        Args:
            session_id: The session ID
            total_tasks: Total task count
            completed_tasks: Completed task count
            failed_tasks: Failed task count
            llm_calls: LLM call count
            tokens_used: Token usage

        Returns:
            True if successful
        """
        async with self.session_factory() as session:
            result = await session.get(SessionModel, session_id)

            if result:
                if total_tasks is not None:
                    result.total_tasks = total_tasks
                if completed_tasks is not None:
                    result.completed_tasks = completed_tasks
                if failed_tasks is not None:
                    result.failed_tasks = failed_tasks
                if llm_calls is not None:
                    result.llm_calls = llm_calls
                if tokens_used is not None:
                    result.tokens_used = tokens_used

                await session.commit()
                return True

        return False

    async def save_task_result(
        self,
        session_id: str,
        task_id: str,
        task_type: str,
        status: str,
        result: Optional[str] = None,
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
        evaluation: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        Save a task result

        Args:
            session_id: The session ID
            task_id: The task ID
            task_type: Type of task
            status: Task status
            result: Task result content
            error: Error message if failed
            metadata: Task metadata
            evaluation: Evaluation result

        Returns:
            True if successful
        """
        async with self.session_factory() as session:
            # Check if result already exists
            stmt = select(TaskResultModel).filter(
                TaskResultModel.session_id == session_id,
                TaskResultModel.task_id == task_id,
            )
            existing = await session.execute(stmt)
            existing_result = existing.scalar_one_or_none()

            chapter_index = metadata.get("chapter_index") if metadata else None

            if existing_result:
                # Update existing
                existing_result.status = status
                existing_result.result = result
                existing_result.error = error
                existing_result.task_metadata = metadata
                existing_result.evaluation = evaluation
            else:
                # Create new
                task_result = TaskResultModel(
                    id=str(uuid.uuid4()),
                    session_id=session_id,
                    task_id=task_id,
                    task_type=task_type,
                    status=status,
                    result=result,
                    error=error,
                    task_metadata=metadata,
                    evaluation=evaluation,
                    chapter_index=chapter_index,
                )
                session.add(task_result)

            await session.commit()
            return True

    async def get_task_results(
        self,
        session_id: str,
        task_type: Optional[str] = None,
        chapter_index: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """
        Get task results for a session

        Args:
            session_id: The session ID
            task_type: Filter by task type
            chapter_index: Filter by chapter index

        Returns:
            List of task results
        """
        async with self.session_factory() as session:
            stmt = select(TaskResultModel).filter(
                TaskResultModel.session_id == session_id
            )

            if task_type:
                stmt = stmt.filter(TaskResultModel.task_type == task_type)

            if chapter_index is not None:
                stmt = stmt.filter(TaskResultModel.chapter_index == chapter_index)

            stmt = stmt.order_by(TaskResultModel.created_at)

            result = await session.execute(stmt)
            tasks = result.scalars().all()

            task_list = []
            for t in tasks:
                # Base task data
                task_data = {
                    "id": t.id,
                    "task_id": t.task_id,
                    "task_type": t.task_type,
                    "status": t.status,
                    "result": t.result,
                    "error": t.error,
                    "evaluation": t.evaluation,
                    "created_at": t.created_at.isoformat(),
                    "chapter_index": t.chapter_index,
                }
                
                # Merge metadata fields into task data for frontend compatibility
                if t.task_metadata:
                    metadata = t.task_metadata
                    task_data.update({
                        "description": metadata.get("description"),
                        "started_at": metadata.get("started_at"),
                        "completed_at": metadata.get("completed_at"),
                        "execution_time_seconds": metadata.get("execution_time_seconds"),
                        "total_tokens": metadata.get("total_tokens"),
                        "prompt_tokens": metadata.get("prompt_tokens"),
                        "completion_tokens": metadata.get("completion_tokens"),
                        "cost_usd": metadata.get("cost_usd"),
                        "failed_attempts": metadata.get("failed_attempts"),
                        "retry_count": metadata.get("retry_count"),
                        "llm_provider": metadata.get("llm_provider"),
                        "llm_model": metadata.get("llm_model"),
                        "metadata": metadata,  # Keep full metadata for reference
                    })
                
                task_list.append(task_data)
            
            return task_list

    async def delete_session(self, session_id: str) -> bool:
        """
        Delete a session and all its data

        Args:
            session_id: The session ID

        Returns:
            True if successful
        """
        async with self.session_factory() as session:
            # Delete task results
            stmt = delete(TaskResultModel).where(
                TaskResultModel.session_id == session_id
            )
            await session.execute(stmt)

            # Delete session
            result = await session.get(SessionModel, session_id)
            if result:
                await session.delete(result)

            await session.commit()
            return True

        return False

    async def create_checkpoint(
        self,
        session_id: str,
        name: str,
    ) -> str:
        """
        Create a checkpoint for a session

        Args:
            session_id: The session ID
            name: Checkpoint name

        Returns:
            Checkpoint ID
        """
        checkpoint_id = f"{session_id}_{name}_{int(datetime.utcnow().timestamp())}"

        # For now, checkpoints are implicit - we can restore to any point
        # by loading session state and task results

        logger.info(f"Created checkpoint {checkpoint_id} for session {session_id}")
        return checkpoint_id

    async def close(self) -> None:
        """Close database connection"""
        await self.engine.dispose()
        logger.info("SessionStorage closed")

```

pylint crashed with a ``AstroidBuildingError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1026, in get_ast
    return MANAGER.ast_from_file(filepath, modname, source=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_namedtuple_enum.py", line 613, in _is_enum_subclass
    for klass in cls.mro()
                 ^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3043, in mro
    return self._compute_mro(context=context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 3012, in _compute_mro
    inferred_bases = list(self._inferred_bases(context=context))
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in _inferred_bases
    baseobj = next(
              ^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 2995, in <genexpr>
    baseobj = next(
                  ^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 270, in infer_call
    for callee in self.func.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 169, in _post_build
    self.delayed_assattr(delayed)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 240, in delayed_assattr
    for inferred in node.expr.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 1152, in infer_assign
    stmts = list(self.assigned_stmts(context=context))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/protocols.py", line 406, in _arguments_infer_argname
    is_metaclass = isinstance(cls, nodes.ClassDef) and cls.type == "metaclass"
                                                       ^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1851, in _class_type
    if _is_metaclass(klass):
       ^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 1820, in _is_metaclass
    for baseobj in base.infer():
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 430, in infer_subscript
    for index in self.slice.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 270, in infer_call
    for callee in self.func.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 718, in _get_asts
    ast_per_fileitem[fileitem] = self.get_ast(
                                 ^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1048, in get_ast
    raise astroid.AstroidBuildingError(
astroid.exceptions.AstroidBuildingError: Building error when trying to create ast representation of module 'creative_autogpt.storage.session'
```
.
Exception on node <Subscript l.30 at 0x10416bec0> in file '/Users/fanhailiang/Desktop/ai/division_autoGpt/src/creative_autogpt/core/engine_registry.py'
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 304, in infer_import
    yield self.do_import_module(self.real_name(name))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 166, in _post_build
    self.add_from_names_to_locals(from_node)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 223, in add_from_names_to_locals
    imported = node.do_import_module()
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 56, in is_decorated_with_dataclass
    return any(
           ^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 57, in <genexpr>
    _looks_like_dataclass_decorator(decorator_attribute, decorator_names)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 445, in _looks_like_dataclass_decorator
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Engine Registry - Manages running LoopEngine instances

This module provides a central registry for managing active LoopEngine instances,
enabling pause/resume/stop functionality across API requests.
"""

import asyncio
from typing import Dict, Optional, Set
from datetime import datetime

from loguru import logger

from creative_autogpt.core.loop_engine import LoopEngine, ExecutionStatus


class EngineRegistry:
    """
    Global registry for managing running LoopEngine instances

    Enables:
    - Tracking active engines by session_id
    - Pausing, resuming, and stopping engines
    - Querying engine status
    - Cleanup of completed engines
    """

    _instance: Optional["EngineRegistry"] = None
    _engines: Dict[str, LoopEngine] = {}
    _cleanup_task: Optional[asyncio.Task] = None
    _lock = asyncio.Lock()

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self._engines = {}
        self._cleanup_task = None
        self._initialized = True
        logger.info("EngineRegistry initialized")

    async def register(
        self,
        session_id: str,
        engine: LoopEngine,
    ) -> None:
        """
        Register a LoopEngine instance

        Args:
            session_id: Session identifier
            engine: LoopEngine instance
        """
        async with self._lock:
            self._engines[session_id] = engine
            logger.info(f"Registered engine for session {session_id}")

            # Start cleanup task if not running
            if self._cleanup_task is None or self._cleanup_task.done():
                self._cleanup_task = asyncio.create_task(self._cleanup_loop())

    async def unregister(self, session_id: str) -> None:
        """
        Unregister a LoopEngine instance

        Args:
            session_id: Session identifier
        """
        async with self._lock:
            if session_id in self._engines:
                del self._engines[session_id]
                logger.info(f"Unregistered engine for session {session_id}")

    def get(self, session_id: str) -> Optional[LoopEngine]:
        """
        Get a registered engine by session_id

        Args:
            session_id: Session identifier

        Returns:
            LoopEngine instance or None
        """
        return self._engines.get(session_id)

    async def pause(self, session_id: str) -> bool:
        """
        Pause a running engine

        Args:
            session_id: Session identifier

        Returns:
            True if successfully paused
        """
        engine = self.get(session_id)
        if engine is None:
            logger.warning(f"No engine found for session {session_id}")
            return False

        if engine.get_status() not in (ExecutionStatus.RUNNING, ExecutionStatus.PLANNING):
            logger.warning(
                f"Cannot pause session {session_id} with status {engine.get_status()}"
            )
            return False

        engine.pause()
        logger.info(f"Paused engine for session {session_id}")
        return True

    async def resume(self, session_id: str) -> bool:
        """
        Resume a paused engine

        Args:
            session_id: Session identifier

        Returns:
            True if successfully resumed
        """
        engine = self.get(session_id)
        if engine is None:
            logger.warning(f"No engine found for session {session_id}")
            return False

        if engine.get_status() != ExecutionStatus.PAUSED:
            logger.warning(
                f"Cannot resume session {session_id} with status {engine.get_status()}"
            )
            return False

        engine.resume()
        logger.info(f"Resumed engine for session {session_id}")
        return True

    async def stop(self, session_id: str) -> bool:
        """
        Stop a running engine

        Args:
            session_id: Session identifier

        Returns:
            True if successfully stopped
        """
        engine = self.get(session_id)
        if engine is None:
            logger.warning(f"No engine found for session {session_id}")
            return False

        if engine.get_status() in (
            ExecutionStatus.COMPLETED,
            ExecutionStatus.FAILED,
            ExecutionStatus.STOPPED,
        ):
            logger.warning(
                f"Cannot stop session {session_id} with status {engine.get_status()}"
            )
            return False

        engine.stop()
        logger.info(f"Stopped engine for session {session_id}")
        return True

    def get_status(self, session_id: str) -> Optional[ExecutionStatus]:
        """
        Get the status of an engine

        Args:
            session_id: Session identifier

        Returns:
            ExecutionStatus or None if not found
        """
        engine = self.get(session_id)
        if engine:
            return engine.get_status()
        return None

    def get_progress(self, session_id: str) -> Optional[Dict]:
        """
        Get the progress of an engine

        Args:
            session_id: Session identifier

        Returns:
            Progress dict or None if not found
        """
        engine = self.get(session_id)
        if engine:
            return engine.get_progress()
        return None

    def get_stats(self, session_id: str) -> Optional[Dict]:
        """
        Get the statistics of an engine

        Args:
            session_id: Session identifier

        Returns:
            Stats dict or None if not found
        """
        engine = self.get(session_id)
        if engine:
            return engine.get_stats()
        return None

    def list_sessions(self) -> Set[str]:
        """
        List all registered session IDs

        Returns:
            Set of session IDs
        """
        return set(self._engines.keys())

    async def _cleanup_loop(self) -> None:
        """Background task to clean up completed engines"""
        while True:
            try:
                await asyncio.sleep(60)  # Check every minute

                async with self._lock:
                    to_remove = []
                    for session_id, engine in self._engines.items():
                        status = engine.get_status()
                        # Clean up engines that are completed/failed/stopped
                        # and have been finished for more than 5 minutes
                        if status in (
                            ExecutionStatus.COMPLETED,
                            ExecutionStatus.FAILED,
                            ExecutionStatus.STOPPED,
                        ):
                            # Check if engine has been in this state for a while
                            # In production, track completion time
                            to_remove.append(session_id)

                    for session_id in to_remove:
                        await self.unregister(session_id)
                        logger.debug(f"Cleaned up engine for session {session_id}")

            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error in cleanup loop: {e}")

    async def shutdown(self) -> None:
        """
        Shutdown the registry and clean up all engines

        Stops all running engines and cancels the cleanup task.
        """
        logger.info("Shutting down EngineRegistry")

        # Stop all running engines
        for session_id, engine in list(self._engines.items()):
            if engine.get_status() in (ExecutionStatus.RUNNING, ExecutionStatus.PAUSED):
                logger.info(f"Stopping engine for session {session_id}")
                engine.stop()

        # Cancel cleanup task
        if self._cleanup_task and not self._cleanup_task.done():
            self._cleanup_task.cancel()
            try:
                await self._cleanup_task
            except asyncio.CancelledError:
                pass

        # Clear registry
        async with self._lock:
            self._engines.clear()

        logger.info("EngineRegistry shutdown complete")


# Global singleton instance
registry = EngineRegistry()


async def get_registry() -> EngineRegistry:
    """
    Get the global EngineRegistry instance

    Returns:
        The singleton EngineRegistry instance
    """
    return registry

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 358, in infer_attribute
    for owner in self.expr.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 304, in infer_import
    yield self.do_import_module(self.real_name(name))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 166, in _post_build
    self.add_from_names_to_locals(from_node)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 223, in add_from_names_to_locals
    imported = node.do_import_module()
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 145, in file_build
    return self._post_build(module, builder, encoding)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 173, in _post_build
    module = self._manager.visit_transforms(module)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 95, in visit_transforms
    return self._transform.visit(node)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 89, in visit
    return self._visit(module)
           ^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 54, in _visit
    visited = self._visit_generic(value)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 61, in _visit_generic
    return [self._visit_generic(child) for child in node]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 67, in _visit_generic
    return self._visit(node)
           ^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 57, in _visit
    return self._transform(node)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/transforms.py", line 38, in _transform
    if predicate is None or predicate(node):
                            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 56, in is_decorated_with_dataclass
    return any(
           ^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 57, in <genexpr>
    _looks_like_dataclass_decorator(decorator_attribute, decorator_names)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_dataclasses.py", line 445, in _looks_like_dataclass_decorator
    inferred = next(node.infer())
               ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Novel Mode - Writing mode for novels and long-form fiction

Implements the standard novel creation pipeline with:
- Style definition
- Theme confirmation
- Outline generation
- Character design
- World-building
- Chapter generation
- Quality evaluation
"""

from typing import Any, Dict, List, Optional

from loguru import logger

from creative_autogpt.modes.base import Mode, WritingMode, register_mode
from creative_autogpt.core.task_planner import TaskDefinition, NovelTaskType
from creative_autogpt.core.vector_memory import MemoryContext


@register_mode
class NovelMode(Mode):
    """
    Writing mode for novels

    Supports:
    - Various genres (xuanhuan, wuxia, urban, scifi, etc.)
    - Long-form structure (up to millions of characters)
    - Complex character relationships
    - Multi-arc storylines
    """

    mode_type = WritingMode.NOVEL
    name = "Novel Mode"
    description = "Writing mode for novels and long-form fiction"

    # Genre-specific configurations
    GENRE_CONFIGS = {
        "玄幻": {
            "style": "宏大世界观，修炼升级体系",
            "themes": ["成长", "复仇", "守护", "探索"],
            "elements": ["灵力", "功法", "法宝", "宗门", "秘境"],
        },
        "武侠": {
            "style": "江湖恩怨，侠义精神",
            "themes": ["义气", "情仇", "门派", "传承"],
            "elements": ["武功", "内力", "兵器", "秘籍", "门派"],
        },
        "都市": {
            "style": "现代都市背景，贴近现实",
            "themes": ["奋斗", "情感", "商战", "悬疑"],
            "elements": ["职场", "家庭", "友情", "爱情"],
        },
        "科幻": {
            "style": "未来科技，宇宙探索",
            "themes": ["科技", "人性", "文明", "探索"],
            "elements": ["AI", "太空", "基因", "能源"],
        },
        "悬疑": {
            "style": "层层悬念，逻辑推理",
            "themes": ["解谜", "真相", "人性", "犯罪"],
            "elements": ["线索", "推理", "反转", "伏笔"],
        },
    }

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.genre = config.get("genre", "玄幻") if config else "玄幻"
        self.genre_config = self.GENRE_CONFIGS.get(self.genre, {})

    async def build_prompt(
        self,
        task_type: str,
        context: MemoryContext,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Build prompt for a novel task type"""
        metadata = metadata or {}

        # Get task-specific prompt
        if task_type == NovelTaskType.STYLE_ELEMENTS.value:
            return self._build_style_prompt(metadata)

        elif task_type == NovelTaskType.THEME_CONFIRMATION.value:
            return self._build_theme_prompt(context, metadata)

        elif task_type == NovelTaskType.MARKET_POSITIONING.value:
            return self._build_market_prompt(context, metadata)

        elif task_type == NovelTaskType.OUTLINE.value:
            return self._build_outline_prompt(context, metadata)

        elif task_type == NovelTaskType.CHARACTER_DESIGN.value:
            return self._build_character_prompt(context, metadata)

        elif task_type == NovelTaskType.WORLDVIEW_RULES.value:
            return self._build_worldview_prompt(context, metadata)

        elif task_type == NovelTaskType.EVENTS.value:
            return self._build_events_prompt(context, metadata)

        elif task_type == NovelTaskType.SCENES_ITEMS_CONFLICTS.value:
            return self._build_scenes_prompt(context, metadata)

        elif task_type == NovelTaskType.FORESHADOW_LIST.value:
            return self._build_foreshadow_prompt(context, metadata)

        elif task_type == NovelTaskType.CONSISTENCY_CHECK.value:
            return self._build_consistency_prompt(context, metadata)

        elif task_type == NovelTaskType.CHAPTER_OUTLINE.value:
            return self._build_chapter_outline_prompt(context, metadata)

        elif task_type == NovelTaskType.SCENE_GENERATION.value:
            return self._build_scene_generation_prompt(context, metadata)

        elif task_type == NovelTaskType.CHAPTER_CONTENT.value:
            return self._build_chapter_content_prompt(context, metadata)

        elif task_type == NovelTaskType.CHAPTER_POLISH.value:
            return self._build_chapter_polish_prompt(context, metadata)

        elif task_type == NovelTaskType.EVALUATION.value:
            return self._build_evaluation_prompt(context, metadata)

        elif task_type == NovelTaskType.REVISION.value:
            return self._build_revision_prompt(context, metadata)

        else:
            return self._build_generic_prompt(task_type, context, metadata)

    def _build_style_prompt(self, metadata: Dict[str, Any]) -> str:
        """Build prompt for style elements definition"""
        genre = metadata.get("goal_style") or metadata.get("genre", self.genre)
        genre_config = self.GENRE_CONFIGS.get(genre, {})

        prompt = f"""## 任务: 定义小说风格元素

请为一部{genre}小说定义详细的风格元素。

### 类型特征
"""

        if genre_config.get("style"):
            prompt += f"风格特点: {genre_config['style']}\n"

        if genre_config.get("themes"):
            prompt += f"常见主题: {', '.join(genre_config['themes'])}\n"

        if genre_config.get("elements"):
            prompt += f"核心元素: {', '.join(genre_config['elements'])}\n"

        prompt += """
### 输出要求

请以JSON格式输出风格元素配置:

```json
{
  "narrative_style": "叙述风格描述",
  "language_style": "语言风格描述",
  "pacing": "节奏控制",
  "tone": "基调氛围",
  "key_elements": ["元素1", "元素2", ...],
  "avoid_elements": ["避免的元素1", "避免的元素2", ...],
  "target_audience": "目标读者",
  "similar_works": ["类似作品1", "类似作品2", ...]
}
```

请直接输出JSON，不需要其他内容。
"""
        return prompt

    def _build_theme_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for theme confirmation"""
        goal_theme = metadata.get("goal_theme", "成长与冒险")

        prompt = f"""## 任务: 确认小说主题

### 目标主题
{goal_theme}

### 已确认的风格
"""

        # Add recent style information if available
        for result in context.recent_results:
            if result["task_type"] == "风格元素":
                prompt += f"\n{result['content'][:500]}...\n"
                break

        prompt += f"""

### 输出要求

请确认并细化小说的核心主题，包括:

1. **核心主题**: 一句话概括小说的核心思想
2. **主题层次**: 主要主题、次要主题
3. **价值取向**: 小说的价值观导向
4. **情感基调": 主要的情感色彩
5. **现实意义**: 小说的现实寓意

请以清晰的结构输出主题确认结果。
"""
        return prompt

    def _build_market_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for market positioning"""
        prompt = """## 任务: 市场定位分析

### 已确认信息
"""

        # Add theme information
        for result in context.recent_results:
            if result["task_type"] == "主题确认":
                prompt += f"\n主题:\n{result['content'][:500]}...\n"
                break

        prompt += """

### 输出要求

请分析小说的市场定位:

1. **目标读者**: 年龄、性别、阅读偏好
2. **平台定位**: 适合的平台（起点、晋江、番茄等）
3. **同类竞品**: 3-5部同类作品分析
4. **差异化**: 本作品的独特卖点
5. **更新策略**: 建议的更新节奏和字数
6. **变现潜力**: 付费、IP改编等潜力分析

请以结构化格式输出分析结果。
"""
        return prompt

    def _build_outline_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for story outline generation"""
        goal_length = metadata.get("goal_length", "100万字")

        prompt = f"""## 任务: 创建小说大纲

### 目标规模
{goal_length}

### 前置信息
"""

        # Add relevant context
        for result in context.recent_results[:3]:
            prompt += f"\n#### {result['task_type']}\n{result['content'][:300]}...\n"

        prompt += """

### 输出要求

请创建完整的故事大纲，包括:

1. **故事简介**: 200-300字简介
2. **主线剧情**: 开端、发展、高潮、结局
3. **分卷规划**: 建议的分卷（每卷20-50万字）
4. **核心冲突**: 主要矛盾和冲突点
5. **关键转折**: 故事的关键转折点
6. **结局方向**: 预期的结局走向

请以清晰的层级结构输出大纲。
"""
        return prompt

    def _build_character_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for character design"""
        prompt = """## 任务: 设计人物角色

### 故事大纲
"""

        # Add outline information
        for result in context.recent_results:
            if result["task_type"] == "大纲":
                prompt += f"\n{result['content'][:800]}...\n"
                break

        prompt += """

### 输出要求

请设计主要人物角色，包括:

**主角:**
- 姓名、年龄、外貌
- 性格特点
- 背景设定
- 核心动机
- 能力/特长
- 性格缺陷
- 成长弧线

**重要配角:**
- 3-5个重要配角
- 每个角色的角色定位
- 与主角的关系

**人物关系图:**
- 主要人物之间的关系网络

请以结构化格式输出人物设计。
"""
        return prompt

    def _build_worldview_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for worldview building"""
        genre = metadata.get("genre", self.genre)

        prompt = f"""## 任务: 构建世界观设定

### 类型
{genre}

### 故事大纲
"""

        # Add outline information
        for result in context.recent_results:
            if result["task_type"] == "大纲":
                prompt += f"\n{result['content'][:800]}...\n"
                break

        prompt += """

### 输出要求

请构建完整的世界观设定:

**基础设定:**
- 世界类型（现实/架空/未来等）
- 时代背景
- 地理环境

**力量体系:** (如适用)
- 能量类型
- 等级划分
- 修炼/成长方式
- 限制和代价

**社会结构:**
- 政治体系
- 经济体系
- 文化特色
- 势力划分

**特殊设定:**
- 独特的规则或现象
- 重要地点
- 关键物品

请以结构化格式输出世界观设定。
"""
        return prompt

    def _build_events_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for event design"""
        prompt = """## 任务: 设计情节事件

### 故事大纲
"""

        # Add outline information
        for result in context.recent_results:
            if result["task_type"] == "大纲":
                prompt += f"\n{result['content'][:800]}...\n"
                break

        prompt += """

### 输出要求

请设计主要情节事件链:

**主线事件:**
- 按时间顺序列出10-20个关键事件
- 每个事件包括: 触发条件、主要内容、结果影响、伏笔关联

**支线事件:**
- 3-5条支线
- 每条支线的起承转合

**冲突设计:**
- 主要冲突点
- 冲突升级路径
- 冲突解决方式

请以清晰的时间线格式输出事件设计。
"""
        return prompt

    def _build_scenes_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for scene and item design"""
        prompt = """## 任务: 设计场景、物品和冲突

### 相关信息
"""

        # Add relevant context
        for result in context.recent_results[:3]:
            prompt += f"\n#### {result['task_type']}\n{result['content'][:400]}...\n"

        prompt += """

### 输出要求

**重要场景:**
- 5-10个关键场景
- 每个场景的环境描述
- 氛围营造要点
- 与剧情的关联

**重要物品:**
- 5-10个关键物品
- 每个物品的描述
- 功能和象征意义
- 获取/使用方式

**冲突场景:**
- 主要对峙场景
- 冲突的表现形式
- 场景的转折点

请以结构化格式输出设计结果。
"""
        return prompt

    def _build_foreshadow_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for foreshadow planning"""
        prompt = """## 任务: 规划伏笔元素

### 故事大纲和事件
"""

        # Add relevant context
        for result in context.recent_results:
            if result["task_type"] in ["大纲", "事件"]:
                prompt += f"\n#### {result['task_type']}\n{result['content'][:400]}...\n"

        prompt += """

### 输出要求

请规划故事的伏笔系统:

**主线伏笔:**
- 5-10个主线伏笔
- 每个伏笔的: 埋设位置、暗示内容、回收时机、影响范围

**支线伏笔:**
- 3-5个支线伏笔
- 埋设和回收计划

**细节伏笔:**
- 可以埋藏伏笔的细节类型
- 隐藏技巧

请以表格形式列出伏笔规划，包含章节位置信息。
"""
        return prompt

    def _build_consistency_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for consistency check"""
        prompt = """## 任务: 一致性检查

### 所有设定
"""

        # Add all relevant context
        for result in context.recent_results:
            prompt += f"\n#### {result['task_type']}\n{result['content'][:300]}...\n"

        prompt += """

### 输出要求

请检查所有设定的一致性:

**检查项:**
1. 人物设定是否自洽
2. 世界观规则是否统一
3. 事件逻辑是否合理
4. 时间线是否连贯
5. 力量体系是否平衡
6. 伏笔是否可落实

**输出格式:**
- 发现的问题列表
- 问题的严重程度
- 修改建议
- 需要调整的设定

请以清晰的结构输出检查结果。
"""
        return prompt

    def _build_chapter_outline_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for chapter outline"""
        chapter_index = metadata.get("chapter_index", 1)

        prompt = f"""## 任务: 第{chapter_index}章大纲

### 全局设定
"""

        # Add global context
        for result in context.recent_results[:3]:
            prompt += f"{result['task_type']}: {result['content'][:200]}...\n"

        prompt += f"""

### 输出要求

请为第{chapter_index}章创建详细大纲:

1. **章节标题**: 吸引人的标题
2. **主要内容**: 本章要讲述的内容
3. **场景划分**: 3-5个场景
4. **出场人物**: 本章出场的人物
5. **情节推进**: 推进的主线/支线
6. **冲突发展**: 本章的冲突
7. **伏笔埋设/回收**: 本章涉及的伏笔
8. **结尾悬念**: 章末的悬念点

请以结构化格式输出章节大纲。
"""
        return prompt

    def _build_scene_generation_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for scene generation"""
        chapter_index = metadata.get("chapter_index", 1)
        scene_index = metadata.get("scene_index", 1)

        prompt = f"""## 任务: 第{chapter_index}章场景{scene_index}生成

### 章节大纲
"""

        # Add chapter outline
        for result in context.recent_results:
            if result.get("chapter_index") == chapter_index:
                prompt += f"\n{result['content'][:500]}...\n"
                break

        prompt += """

### 输出要求

请生成详细的场景内容:

1. **场景描述**: 环境、氛围
2. **人物动作**: 人物的行为和互动
3. **对话**: 人物对话
4. **心理描写**: 人物内心活动
5. **感官细节**: 视觉、听觉等细节
6. **节奏控制**: 快慢节奏的把握

请直接输出场景内容，1500-2500字。
"""
        return prompt

    def _build_chapter_content_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for chapter content generation"""
        chapter_index = metadata.get("chapter_index", 1)

        prompt = f"""## 任务: 第{chapter_index}章内容生成

### 相关信息
"""

        # Add relevant context
        chapter_scenes = []
        for result in context.recent_results:
            if result.get("chapter_index") == chapter_index:
                chapter_scenes.append(result)

        for scene in chapter_scenes:
            prompt += f"\n{scene.get('task_type', '场景')}\n{scene['content'][:400]}...\n"

        prompt += f"""

### 输出要求

请将各场景整合成完整的章节内容:

1. **结构完整**: 开头、发展、结尾
2. **过渡自然**: 场景之间的过渡
3. **节奏协调**: 快慢节奏把握
4. **字数控制**: 3000-5000字
5. **悬念设置**: 章末留悬念

请直接输出章节内容，不需要章节标题。
"""
        return prompt

    def _build_chapter_polish_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for chapter polish"""
        chapter_index = metadata.get("chapter_index", 1)

        prompt = f"""## 任务: 第{chapter_index}章润色

### 原始内容
"""

        # Add chapter content
        for result in context.recent_results:
            if result.get("task_type") == "章节内容" and result.get("chapter_index") == chapter_index:
                prompt += f"\n{result['content'][:2000]}...\n"
                break

        prompt += """

### 输出要求

请对章节内容进行润色:

1. **语言优化**: 更优美的表达
2. **节奏调整**: 改善节奏感
3. **细节增强**: 增加生动细节
4. **情感渲染**: 增强情感表达
5. **保持原意**: 不改变原有情节

请直接输出润色后的内容。
"""
        return prompt

    def _build_evaluation_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for content evaluation"""
        chapter_index = metadata.get("chapter_index", 1)

        prompt = f"""## 任务: 第{chapter_index}章质量评估

### 章节内容
"""

        # Add chapter content
        for result in context.recent_results:
            if result.get("task_type") == "章节润色" and result.get("chapter_index") == chapter_index:
                prompt += f"\n{result['content'][:3000]}\n"
                break

        prompt += """

### 评估维度

请从以下维度评估（0-100分）:

1. **连贯性**: 逻辑是否连贯
2. **创意性**: 内容是否有新意
3. **文笔质量**: 文字是否优美
4. **一致性**: 是否与前面设定一致
5. **吸引力**: 是否吸引读者继续阅读

请输出JSON格式的评估结果。
"""
        return prompt

    def _build_revision_prompt(self, context: MemoryContext, metadata: Dict[str, Any]) -> str:
        """Build prompt for content revision"""
        chapter_index = metadata.get("chapter_index", 1)

        prompt = f"""## 任务: 第{chapter_index}章修订

### 当前内容
"""

        # Add chapter content
        for result in context.recent_results:
            if result.get("chapter_index") == chapter_index and result.get("task_type") in ["章节润色", "评估"]:
                prompt += f"\n{result['content'][:2000]}\n"
                break

        prompt += """

### 评估反馈
"""

        # Add evaluation feedback
        for result in context.recent_results:
            if result.get("evaluation"):
                prompt += f"\n{result['evaluation'][:500]}\n"
                break

        prompt += """

### 输出要求

请根据评估反馈修订内容，解决发现的问题。
保持原有结构和情节，仅改进需要修正的部分。

请直接输出修订后的内容。
"""
        return prompt

    def _build_generic_prompt(
        self,
        task_type: str,
        context: MemoryContext,
        metadata: Dict[str, Any],
    ) -> str:
        """Build generic prompt for unknown task types"""
        prompt = f"""## 任务: {task_type}

### 相关上下文
"""

        # Add context
        for result in context.recent_results[:3]:
            prompt += f"\n{result['task_type']}: {result['content'][:200]}...\n"

        prompt += f"""

### 元数据
{metadata}

### 输出要求
请完成任务，直接输出结果。
"""
        return prompt

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.68 at 0x1044d4a40>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  [Previous line repeated 1 more time]
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Base Mode class and mode registry

Provides the foundation for different writing modes (novel, script, etc.)
"""

import uuid
from abc import ABC, abstractmethod
from enum import Enum
from typing import Any, Dict, List, Optional

from loguru import logger

from creative_autogpt.core.task_planner import TaskDefinition, NovelTaskType
from creative_autogpt.core.vector_memory import MemoryContext


class WritingMode(str, Enum):
    """Supported writing modes"""

    NOVEL = "novel"
    SCRIPT = "script"
    LARP = "larp"  # 剧本杀


class Mode:
    """
    Base class for writing modes

    Each mode defines:
    - Task types and their execution order
    - Prompt templates for each task type
    - Evaluation criteria
    - Output format requirements
    """

    mode_type: WritingMode = WritingMode.NOVEL
    name: str = "Base Mode"
    description: str = ""

    # Task definitions for this mode
    task_definitions: List[TaskDefinition] = []

    # Prompt templates (task_type -> template)
    prompt_templates: Dict[str, str] = {}

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize mode

        Args:
            config: Optional mode configuration
        """
        self.config = config or {}
        logger.debug(f"Initialized mode: {self.name}")

    @abstractmethod
    async def build_prompt(
        self,
        task_type: str,
        context: MemoryContext,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Build prompt for a task type

        Args:
            task_type: The type of task
            context: Memory context
            metadata: Additional metadata

        Returns:
            The constructed prompt
        """
        pass

    async def build_improved_prompt(
        self,
        task_type: str,
        previous_result: str,
        feedback: str,
        context: MemoryContext,
    ) -> str:
        """
        Build an improved prompt for rewriting

        Args:
            task_type: The type of task
            previous_result: Previous generation result
            feedback: Feedback/evaluation to address
            context: Memory context

        Returns:
            The improved prompt
        """
        prompt = f"""## 改进任务

任务类型: {task_type}

## 原始结果
```
{previous_result[:3000]}
```

## 反馈意见
{feedback}

## 要求
请根据反馈意见改进内容，保持原有的核心结构和主题，仅改进需要修正的部分。

## 输出
请直接输出改进后的内容，不需要解释或说明。
"""
        return prompt

    def get_task_definitions(self) -> List[TaskDefinition]:
        """Get task definitions for this mode"""
        return self.task_definitions

    def get_prompt_template(self, task_type: str) -> Optional[str]:
        """Get prompt template for a task type"""
        return self.prompt_templates.get(task_type)

    def get_evaluation_criteria(self, task_type: str) -> Dict[str, float]:
        """Get evaluation criteria for a task type"""
        # Default criteria
        return {
            "coherence": 0.2,
            "creativity": 0.2,
            "quality": 0.2,
            "consistency": 0.2,
            "goal_alignment": 0.2,
        }


class ModeRegistry:
    """Registry for writing modes"""

    _modes: Dict[WritingMode, type] = {}

    @classmethod
    def register(cls, mode_class: type) -> None:
        """Register a mode class"""
        if hasattr(mode_class, "mode_type"):
            cls._modes[mode_class.mode_type] = mode_class
            logger.info(f"Registered mode: {mode_class.mode_type.value}")

    @classmethod
    def get(cls, mode_type: WritingMode) -> Optional[type]:
        """Get a mode class by type"""
        return cls._modes.get(mode_type)

    @classmethod
    def create(cls, mode_type: WritingMode, config: Optional[Dict[str, Any]] = None) -> Optional[Mode]:
        """Create a mode instance"""
        mode_class = cls.get(mode_type)
        if mode_class:
            return mode_class(config=config)
        return None

    @classmethod
    def list_modes(cls) -> List[str]:
        """List all registered mode types"""
        return [m.value for m in cls._modes.keys()]

    @classmethod
    def is_registered(cls, mode_type: WritingMode) -> bool:
        """Check if a mode is registered"""
        return mode_type in cls._modes


def register_mode(mode_class: type) -> None:
    """Decorator to register a mode class"""
    ModeRegistry.register(mode_class)
    return mode_class

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.47 at 0x1047a56d0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  [Previous line repeated 1 more time]
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Timeline Plugin - Manages story timeline and chronology

This plugin handles:
- Story timeline tracking
- Event chronology validation
- Time-based consistency checking
- Flashback and flashforward tracking
"""

import json
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class TimelinePlugin(NovelElementPlugin):
    """
    Plugin for managing story timeline

    Tracks chronology and validates time-based consistency.
    """

    name = "timeline"
    version = "1.0.0"
    description = "Manages story timeline and chronology"
    author = "Creative AutoGPT"

    # Timeline state storage
    _timeline: List[Dict[str, Any]] = []
    _current_chapter_time: Optional[str] = None
    _flashbacks: List[Dict[str, Any]] = []
    _flashforwards: List[Dict[str, Any]] = []

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._timeline = []
        self._current_chapter_time = None
        self._flashbacks = []
        self._flashforwards = []

    async def on_init(self, context: WritingContext) -> None:
        """Initialize timeline plugin with session context"""
        logger.info(f"TimelinePlugin initialized for session {context.session_id}")
        if "timeline" in context.metadata:
            self._timeline = context.metadata.get("timeline", [])

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for timeline data"""
        return {
            "type": "object",
            "title": "Timeline Schema",
            "description": "Schema for timeline events",
            "properties": {
                "event_id": {
                    "type": "string",
                    "description": "Unique event identifier"
                },
                "story_time": {
                    "type": "string",
                    "description": "Time in story world (e.g., 'Day 1', 'Year 3045')"
                },
                "chapter": {
                    "type": "integer",
                    "description": "Chapter where this occurs"
                },
                "duration": {
                    "type": "string",
                    "description": "How long the event lasts"
                },
                "description": {
                    "type": "string",
                    "description": "Event description"
                },
                "location": {
                    "type": "string",
                    "description": "Where this occurs"
                },
                "characters_present": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Characters present"
                },
                "time_jump": {
                    "type": "boolean",
                    "description": "Whether there's a time jump after this"
                },
                "jump_duration": {
                    "type": "string",
                    "description": "Duration of time jump if applicable"
                }
            },
            "required": ["event_id", "story_time", "chapter"]
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for timeline-related tasks"""
        return {
            "timeline_check": """## 任务: 检查时间线一致性

### 当前时间线
{current_timeline}

### 检查内容
{content_to_check}

### 检查维度

1. **时间连贯性**: 时间顺序是否合理
2. **持续时间**: 事件持续时间是否合理
3. **时间跳跃**: 时间跳跃是否明确标注
4. **同时事件**: 同时发生的事件是否合理
5. **回忆/预知**: 闪回和闪前是否清晰标注

### 输出要求

请输出 JSON 格式的检查结果:
```json
{{
  "is_consistent": true/false,
  "timeline_events": ["识别到的时间事件"],
  "issues": ["时间问题"],
  "suggestions": ["修改建议"],
  "current_time_established": "当前确立的时间"
}}
```
""",

            "timeline_creation": """## 任务: 创建故事时间线

### 故事大纲
{outline}

### 事件列表
{events}

### 时间线创建要求

请为小说创建详细的时间线:

**时间系统:**
- 时间计量单位: (天/月/年/纪元/其他)
- 历法系统: 如适用
- 时间参照点

**主线时间线:**
按顺序列出每个章节的时间点:
1. 章节编号
2. 故事时间
3. 持续时间
4. 时间跳跃 (如有)
5. 关键事件

**特殊时间处理:**
- 闪回时刻: 时间点、持续内容
- 闪前时刻: 时间点、展示内容
- 平行时间线: 如适用

**时间一致性检查:**
确保角色位置合理、事件顺序逻辑

请以 JSON 格式输出时间线。
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for timeline-related operations"""
        return [
            {
                "task_id": "timeline_check",
                "task_type": "时间线检查",
                "description": "Check timeline consistency in the story",
                "depends_on": ["章节内容"],
                "metadata": {
                    "plugin": "timeline",
                    "operation": "check"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate timeline data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Timeline data must be a dictionary"]
            )

        # Check required fields
        if "event_id" not in data:
            errors.append("Missing event_id")
        if "story_time" not in data:
            errors.append("Missing story_time")
        if "chapter" not in data:
            errors.append("Missing chapter")

        # Check chapter ordering
        if "chapter" in data and self._timeline:
            last_chapter = max(t.get("chapter", 0) for t in self._timeline)
            if data["chapter"] < last_chapter:
                warnings.append(f"Chapter {data['chapter']} is before last chapter {last_chapter}")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Process timeline-related task results"""
        task_type = task.get("task_type", "")

        if task_type == "时间线检查":
            await self._process_timeline_check(result, context)

        return result

    async def _process_timeline_check(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Process timeline check results"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                # Extract timeline events
                if "timeline_events" in data:
                    for event in data["timeline_events"]:
                        if isinstance(event, dict):
                            self._timeline.append(event)

                # Update current time
                if "current_time_established" in data:
                    self._current_chapter_time = data["current_time_established"]

        except Exception as e:
            logger.error(f"Error processing timeline check: {e}")

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with timeline information"""
        task_type = task.get("task_type", "")
        chapter_index = task.get("metadata", {}).get("chapter_index")

        # Add current timeline position for chapter generation
        if chapter_index is not None and "章节" in task_type:
            if self._current_chapter_time:
                context["current_time"] = self._current_chapter_time

            # Add recent timeline events
            recent_events = [
                t for t in self._timeline
                if t.get("chapter", 0) < chapter_index
            ]
            if recent_events:
                context["recent_timeline"] = recent_events[-5:]  # Last 5 events

        return context

    def add_timeline_event(self, event: Dict[str, Any]) -> None:
        """Add a timeline event"""
        self._timeline.append(event)
        # Sort by chapter
        self._timeline.sort(key=lambda x: x.get("chapter", 0))

    def get_timeline(self) -> List[Dict[str, Any]]:
        """Get the full timeline"""
        return self._timeline.copy()

    def get_current_time(self) -> Optional[str]:
        """Get the current established story time"""
        return self._current_chapter_time

    def set_current_time(self, time: str) -> None:
        """Set the current story time"""
        self._current_chapter_time = time

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize timeline plugin and persist data"""
        logger.info("TimelinePlugin finalized")
        context.metadata["timeline"] = self._timeline
        context.metadata["flashbacks"] = self._flashbacks
        context.metadata["flashforwards"] = self._flashforwards

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.38 at 0x10488c4d0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
WorldView Plugin - Manages world-building settings, rules, and lore

This plugin handles:
- World setting definitions (geography, history, society)
- Power/magic systems with consistent rules
- Faction and organization definitions
- Location and place descriptions
- World lore and background information
"""

import json
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class WorldViewPlugin(NovelElementPlugin):
    """
    Plugin for managing novel worldview and settings

    Tracks world-building elements including magic systems, geography,
    social structures, factions, and lore.
    """

    name = "worldview"
    version = "1.0.0"
    description = "Manages world-building settings and lore"
    author = "Creative AutoGPT"

    # World state storage
    _world_settings: Dict[str, Any] = {}
    _power_systems: Dict[str, Dict[str, Any]] = {}
    _factions: Dict[str, Dict[str, Any]] = {}
    _locations: Dict[str, Dict[str, Any]] = {}
    _lore: List[Dict[str, Any]] = []

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._world_settings = {}
        self._power_systems = {}
        self._factions = {}
        self._locations = {}
        self._lore = []

    async def on_init(self, context: WritingContext) -> None:
        """Initialize worldview plugin with session context"""
        logger.info(f"WorldViewPlugin initialized for session {context.session_id}")
        # Load any existing worldview data from context
        if "world_settings" in context.metadata:
            self._world_settings = context.metadata.get("world_settings", {})
        if "power_systems" in context.metadata:
            self._power_systems = context.metadata.get("power_systems", {})
        if "factions" in context.metadata:
            self._factions = context.metadata.get("factions", {})
        if "locations" in context.metadata:
            self._locations = context.metadata.get("locations", {})

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for worldview data"""
        return {
            "type": "object",
            "title": "WorldView Schema",
            "description": "Schema for novel world-building settings",
            "properties": {
                "world_type": {
                    "type": "string",
                    "enum": ["realistic", "fantasy", "scifi", "urban_fantasy", "historical", "post_apocalyptic"],
                    "description": "Type of world setting"
                },
                "time_period": {
                    "type": "string",
                    "description": "Time period of the story"
                },
                "geography": {
                    "type": "object",
                    "properties": {
                        "continents": {"type": "array", "items": {"type": "string"}},
                        "climate": {"type": "string"},
                        "major_features": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Mountains, rivers, forests, etc."
                        }
                    }
                },
                "cosmology": {
                    "type": "object",
                    "properties": {
                        "universe_structure": {"type": "string"},
                        "planes": {"type": "array", "items": {"type": "string"}},
                        "celestial_bodies": {"type": "array", "items": {"type": "string"}}
                    }
                },
                "history": {
                    "type": "object",
                    "properties": {
                        "ancient_events": {"type": "array", "items": {"type": "string"}},
                        "recent_history": {"type": "string"},
                        "calendar_system": {"type": "string"}
                    }
                },
                "society": {
                    "type": "object",
                    "properties": {
                        "political_system": {"type": "string"},
                        "economic_system": {"type": "string"},
                        "social_hierarchy": {"type": "array", "items": {"type": "string"}},
                        "laws": {"type": "array", "items": {"type": "string"}},
                        "customs": {"type": "array", "items": {"type": "string"}}
                    }
                },
                "technology_level": {
                    "type": "string",
                    "enum": ["primitive", "pre_industrial", "industrial", "modern", "advanced", "futuristic"]
                },
                "power_system": {
                    "type": "object",
                    "properties": {
                        "name": {"type": "string"},
                        "source": {"type": "string"},
                        "ranks": {
                            "type": "array",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "level": {"type": "string"},
                                    "description": {"type": "string"},
                                    "capabilities": {"type": "array", "items": {"type": "string"}}
                                }
                            }
                        },
                        "limitations": {"type": "array", "items": {"type": "string"}},
                        "costs": {"type": "array", "items": {"type": "string"}}
                    }
                }
            }
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for worldview-related tasks"""
        return {
            "worldview_creation": """## 任务: 构建世界观设定

### 小说类型
{genre}

### 故事大纲
{outline}

### 世界观构建要求

请为小说创建完整的世界观设定:

**1. 基础设定:**
- 世界类型: (现实/架空/奇幻/科幻/都市奇幻/历史/后末日)
- 时代背景: (具体的历史时期或虚构时代)
- 地理环境:
  - 大陆/国家分布
  - 气候特征
  - 重要地理特征 (山脉、河流、森林、海洋等)
  - 特殊地貌 (如适用)

**2. 宇宙观/位面设定** (如适用):
- 世界结构
- 位面/界域划分
- 天体系统
- 特殊空间 (异空间、秘境等)

**3. 历史背景:**
- 远古重大事件
- 近代历史脉络
- 重要历史转折点
- 纪元/历法系统
- 传说与神话

**4. 社会结构:**
- 政治体系: (君主制/民主制/贵族制/联邦制/无政府等)
- 经济体系: (封建/资本主义/计划经济/物物交换等)
- 社会阶层: 阶级划分和晋升机制
- 法律制度: 主要法律和禁忌
- 文化习俗: 风俗、礼仪、节日等
- 宗教信仰: 主要宗教或信仰体系

**5. 科技水平:**
- 科技等级: (原始/前工业/工业/现代/先进/未来)
- 重要技术/发明
- 科技的社会影响

**6. 力量体系** (如适用):
- 能量来源
- 等级划分:
  - 每个等级的名称
  - 每个等级的能力描述
  - 突破条件
- 修炼/成长方法
- 力量限制和代价
- 特殊能力分类
- 宝物/法器设定

**7. 特殊设定:**
- 独特的世界规则
- 异种/种族设定 (如适用)
- 势力分布
- 重要地点详情

请以结构化的 JSON 格式输出，确保世界观设定逻辑自洽、细节丰富。
""",

            "faction_design": """## 任务: 设计势力组织

### 世界观背景
{worldview}

### 势力设计要求

请为小说设计主要势力/组织:

**每个势力包含:**
1. **基本信息:**
   - 势力名称
   - 势力类型 (门派/家族/国家/组织/公司/其他)
   - 势力规模

2. **核心理念:**
   - 宗旨/目标
   - 价值观
   - 信条

3. **组织架构:**
   - 领导层
   - 分支结构
   - 人员构成

4. **实力设定:**
   - 核心能力
   - 独特资源
   - 领地范围
   - 经济基础

5. **对外关系:**
   - 盟友势力
   - 敌对势力
   - 中立势力

6. **特色元素:**
   - 独特功法/技术
   - 标志性物品
   - 特殊传统

请设计 3-5 个主要势力，确保势力间有合理的制衡关系。

以 JSON 格式输出。
""",

            "location_detail": """## 任务: 设计详细地点

### 世界观背景
{worldview}

### 地点设计要求

请为故事中的重要地点创建详细设定:

**地点分类:**
1. **城市/聚落:**
   - 地理位置
   - 规模和人口
   - 建筑风格
   - 功能分区
   - 经济特色
   - 文化氛围

2. **自然景观:**
   - 地理特征
   - 气候条件
   - 生态特色
   - 特殊现象

3. **特殊地点:**
   - 秘境/禁地
   - 遗迹/废墟
   - 神圣之地
   - 危险区域

**每个地点包含:**
- 地点名称
- 地理位置
- 环境描述 (200-300字)
- 特色/秘密
- 相关势力
- 剧情作用

请设计 5-10 个重要地点。

以 JSON 格式输出。
""",

            "worldview_consistency_check": """## 任务: 检查世界观一致性

### 世界观设定
{worldview_rules}

### 检查内容
{content_to_check}

### 检查维度

1. **规则一致性**: 是否遵守设定的世界规则
2. **地理一致性**: 地点和距离是否合理
3. **科技/力量一致性**: 能力水平是否符合设定
4. **社会一致性**: 社会结构和行为是否符合设定
5. **时间一致性**: 时间线是否连贯

### 输出要求

请输出 JSON 格式的检查结果:
```json
{{
  "is_consistent": true/false,
  "issues": ["具体的不一致问题"],
  "suggestions": ["修改建议"],
  "world_elements_used": ["使用到的世界观元素"]
}}
```
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for worldview-related operations"""
        return [
            {
                "task_id": "worldview_rules",
                "task_type": "世界观规则",
                "description": "Create complete worldview settings and rules",
                "depends_on": ["大纲"],
                "metadata": {
                    "plugin": "worldview",
                    "operation": "create"
                }
            },
            {
                "task_id": "faction_design",
                "task_type": "势力设计",
                "description": "Design major factions and organizations",
                "depends_on": ["世界观规则"],
                "metadata": {
                    "plugin": "worldview",
                    "operation": "factions"
                }
            },
            {
                "task_id": "location_design",
                "task_type": "场景设计",
                "description": "Design detailed locations and places",
                "depends_on": ["世界观规则"],
                "metadata": {
                    "plugin": "worldview",
                    "operation": "locations"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate worldview data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Worldview data must be a dictionary"]
            )

        # Check for world type
        if "world_type" not in data:
            warnings.append("World type not specified")
            suggestions.append("Define the type of world setting")

        # Check for internal consistency
        if data.get("world_type") == "fantasy":
            if "power_system" not in data:
                warnings.append("Fantasy world missing power/magic system")
                suggestions.append("Define magic/power system for fantasy setting")

        if data.get("world_type") == "scifi":
            if "technology_level" not in data:
                warnings.append("Sci-fi world missing technology level specification")

        # Check geography if locations exist
        if "locations" in data and "geography" not in data:
            suggestions.append("Add geography details for location context")

        # Check social structure consistency
        if "society" in data:
            society = data["society"]
            if "political_system" not in society:
                suggestions.append("Define political system for clearer social structure")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Extract and store worldview data from task results"""
        task_type = task.get("task_type", "")

        if task_type == "世界观规则":
            await self._extract_worldview(result, context)
        elif task_type == "势力设计":
            await self._extract_factions(result, context)
        elif task_type == "场景设计":
            await self._extract_locations(result, context)

        return result

    async def _extract_worldview(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract worldview settings from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                self._world_settings = data

                # Extract power system if present
                if "power_system" in data:
                    self._power_systems["main"] = data["power_system"]

                logger.info("Extracted worldview settings")

        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse worldview data as JSON: {e}")
        except Exception as e:
            logger.error(f"Error extracting worldview: {e}")

    async def _extract_factions(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract faction data from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                if isinstance(data, dict) and "factions" in data:
                    for faction_id, faction_data in data["factions"].items():
                        if isinstance(faction_data, dict):
                            self._factions[faction_id] = faction_data

                logger.info(f"Extracted {len(self._factions)} faction definitions")

        except Exception as e:
            logger.error(f"Error extracting factions: {e}")

    async def _extract_locations(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract location data from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                if isinstance(data, dict) and "locations" in data:
                    for loc_id, loc_data in data["locations"].items():
                        if isinstance(loc_data, dict):
                            self._locations[loc_id] = loc_data

                logger.info(f"Extracted {len(self._locations)} location definitions")

        except Exception as e:
            logger.error(f"Error extracting locations: {e}")

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with worldview information"""
        task_type = task.get("task_type", "")

        # Add world settings summary
        if self._world_settings:
            context["worldview"] = {
                "type": self._world_settings.get("world_type"),
                "time_period": self._world_settings.get("time_period"),
                "technology_level": self._world_settings.get("technology_level"),
            }

            # Add power system info if available
            if "power_system" in self._world_settings:
                context["power_system"] = self._world_settings["power_system"]

        # Add factions for relevant tasks
        if "章节" in task_type or "情节" in task_type:
            if self._factions:
                context["factions"] = list(self._factions.keys())

        # Add locations for scene generation
        if "场景" in task_type or "章节" in task_type:
            if self._locations:
                context["available_locations"] = [
                    {"id": k, "name": v.get("name", k)}
                    for k, v in self._locations.items()
                ]

        return context

    def get_world_settings(self) -> Dict[str, Any]:
        """Get all world settings"""
        return self._world_settings.copy()

    def get_power_systems(self) -> Dict[str, Dict[str, Any]]:
        """Get all power systems"""
        return self._power_systems.copy()

    def get_factions(self) -> Dict[str, Dict[str, Any]]:
        """Get all factions"""
        return self._factions.copy()

    def get_locations(self) -> Dict[str, Dict[str, Any]]:
        """Get all locations"""
        return self._locations.copy()

    def get_location(self, location_id: str) -> Optional[Dict[str, Any]]:
        """Get a specific location by ID"""
        return self._locations.get(location_id)

    def add_lore(self, lore_entry: Dict[str, Any]) -> None:
        """Add a lore entry"""
        lore_entry["added_at"] = datetime.utcnow().isoformat()
        self._lore.append(lore_entry)

    def get_lore(self, category: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get lore entries, optionally filtered by category"""
        if category:
            return [entry for entry in self._lore if entry.get("category") == category]
        return self._lore.copy()

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize worldview plugin and persist data"""
        logger.info("WorldViewPlugin finalized")
        context.metadata["world_settings"] = self._world_settings
        context.metadata["power_systems"] = self._power_systems
        context.metadata["factions"] = self._factions
        context.metadata["locations"] = self._locations
        context.metadata["world_lore"] = self._lore

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.44 at 0x1048c8650>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Scene Plugin - Manages scene descriptions and atmosphere

This plugin handles:
- Scene environment descriptions
- Atmosphere and mood tracking
- Sensory details management
- Scene-to-scene transitions
"""

import json
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class ScenePlugin(NovelElementPlugin):
    """
    Plugin for managing scene descriptions

    Tracks locations, atmospheres, and sensory details.
    """

    name = "scene"
    version = "1.0.0"
    description = "Manages scene descriptions and atmosphere"
    author = "Creative AutoGPT"

    # Scene state storage
    _scenes: Dict[str, Dict[str, Any]] = {}
    _atmospheres: Dict[str, List[str]] = {}
    _sensory_templates: Dict[str, Dict[str, List[str]]] = {}

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._scenes = {}
        self._atmospheres = {}
        self._sensory_templates = {}

    async def on_init(self, context: WritingContext) -> None:
        """Initialize scene plugin with session context"""
        logger.info(f"ScenePlugin initialized for session {context.session_id}")
        if "scenes" in context.metadata:
            self._scenes = context.metadata.get("scenes", {})
        if "atmospheres" in context.metadata:
            self._atmospheres = context.metadata.get("atmospheres", {})

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for scene data"""
        return {
            "type": "object",
            "title": "Scene Schema",
            "description": "Schema for scene descriptions",
            "properties": {
                "scene_id": {
                    "type": "string",
                    "description": "Unique scene identifier"
                },
                "name": {
                    "type": "string",
                    "description": "Scene name"
                },
                "location_id": {
                    "type": "string",
                    "description": "Reference to location ID"
                },
                "time_of_day": {
                    "type": "string",
                    "enum": ["dawn", "morning", "noon", "afternoon", "evening", "dusk", "night", "midnight"],
                    "description": "Time of day"
                },
                "weather": {
                    "type": "string",
                    "description": "Weather conditions"
                },
                "atmosphere": {
                    "type": "object",
                    "properties": {
                        "mood": {"type": "string"},
                        "tension": {"type": "integer", "minimum": 0, "maximum": 10},
                        "emotional_tone": {"type": "string"}
                    }
                },
                "visuals": {
                    "type": "object",
                    "properties": {
                        "lighting": {"type": "string"},
                        "colors": {"type": "array", "items": {"type": "string"}},
                        "key_objects": {"type": "array", "items": {"type": "string"}}
                    }
                },
                "sounds": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Auditory details"
                },
                "smells": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Olfactory details"
                },
                "textures": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Tactile details"
                },
                "transitions": {
                    "type": "object",
                    "properties": {
                        "from": {"type": "string"},
                        "to": {"type": "string"},
                        "type": {"type": "string", "enum": ["cut", "fade", "dissolve", "match_cut"]}
                    }
                }
            },
            "required": ["scene_id", "name"]
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for scene-related tasks"""
        return {
            "scene_generation": """## 任务: 生成场景内容

### 场景设定
- 时间: {time_of_day}
- 天气: {weather}
- 地点: {location}
- 氛围: {atmosphere}

### 上下文
{context}

### 场景生成要求

请生成详细的场景内容，包含:

1. **环境描述** (100-150字):
   - 空间布局
   - 视觉元素
   - 光线与色彩

2. **感官细节**:
   - 声音: 3-5种声音
   - 气味: 2-3种气味
   - 触觉: 如适用
   - 温度感

3. **氛围营造**:
   - 情绪基调
   - 张力水平
   - 预示感

4. **人物活动**:
   - 人物位置
   - 动作描述
   - 互动细节

5. **节奏把控**:
   - 快/慢节奏选择
   - 细节与动作的平衡

请直接输出场景内容，1500-2500字。
""",

            "atmosphere_check": """## 任务: 检查场景氛围

### 场景内容
{scene_content}

### 期望氛围
{expected_atmosphere}

### 检查维度

1. **氛围一致性**: 是否符合期望氛围
2. **感官丰富度**: 五感描写是否充分
3. **细节质量**: 细节是否生动具体
4. **沉浸感**: 是否能让读者身临其境

### 输出要求

请输出 JSON 格式的检查结果。
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for scene-related operations"""
        return [
            {
                "task_id": "scene_generation",
                "task_type": "场景生成",
                "description": "Generate detailed scene content",
                "depends_on": ["章节大纲"],
                "metadata": {
                    "plugin": "scene",
                    "operation": "generate"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate scene data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Scene data must be a dictionary"]
            )

        if "scene_id" not in data:
            errors.append("Missing scene_id")
        if "name" not in data:
            errors.append("Missing scene name")

        # Check for sensory details
        atmosphere = data.get("atmosphere", {})
        if not atmosphere.get("mood"):
            suggestions.append("Add mood description for better atmosphere")

        # Check sensory elements
        has_visuals = bool(data.get("visuals"))
        has_sounds = bool(data.get("sounds"))
        has_smells = bool(data.get("smells"))

        if not (has_visuals or has_sounds or has_smells):
            suggestions.append("Add sensory details for immersive scenes")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Process scene-related task results"""
        task_type = task.get("task_type", "")

        if task_type == "场景生成":
            chapter_index = task.get("metadata", {}).get("chapter_index")
            scene_index = task.get("metadata", {}).get("scene_index")

            if chapter_index is not None and scene_index is not None:
                scene_id = f"ch{chapter_index}_scene{scene_index}"
                self._scenes[scene_id] = {
                    "scene_id": scene_id,
                    "content": result,
                    "chapter": chapter_index,
                    "scene_index": scene_index,
                    "created_at": datetime.utcnow().isoformat()
                }

        return result

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with scene information"""
        task_type = task.get("task_type", "")

        if "场景" in task_type or "章节" in task_type:
            # Add atmosphere templates
            if self._atmospheres:
                context["atmosphere_templates"] = self._atmospheres

            # Add sensory templates
            if self._sensory_templates:
                context["sensory_templates"] = self._sensory_templates

        return context

    def add_scene(self, scene_id: str, scene_data: Dict[str, Any]) -> None:
        """Add a scene"""
        self._scenes[scene_id] = scene_data

    def get_scene(self, scene_id: str) -> Optional[Dict[str, Any]]:
        """Get a scene by ID"""
        return self._scenes.get(scene_id)

    def get_scenes_for_chapter(self, chapter_index: int) -> List[Dict[str, Any]]:
        """Get all scenes for a chapter"""
        return [
            scene for scene in self._scenes.values()
            if scene.get("chapter") == chapter_index
        ]

    def set_atmosphere(self, atmosphere_type: str, elements: List[str]) -> None:
        """Set atmosphere elements for a type"""
        self._atmospheres[atmosphere_type] = elements

    def set_sensory_template(self, sense: str, templates: Dict[str, List[str]]) -> None:
        """Set sensory templates"""
        self._sensory_templates[sense] = templates

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize scene plugin and persist data"""
        logger.info("ScenePlugin finalized")
        context.metadata["scenes"] = self._scenes
        context.metadata["atmospheres"] = self._atmospheres
        context.metadata["sensory_templates"] = self._sensory_templates

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.194 at 0x104bd5850>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-30.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Foreshadow Plugin - Manages foreshadowing plant and payoff tracking

This plugin handles:
- Foreshadowing element planning
- Plant tracking (when and where foreshadowing is placed)
- Payoff tracking (when foreshadowing is resolved)
- Foreshadowing consistency validation
"""

import json
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class ForeshadowPlugin(NovelElementPlugin):
    """
    Plugin for managing foreshadowing elements

    Tracks planted foreshadowing and ensures proper payoff.
    """

    name = "foreshadow"
    version = "1.0.0"
    description = "Manages foreshadowing plant and payoff tracking"
    author = "Creative AutoGPT"

    # Foreshadowing state storage
    _elements: List[Dict[str, Any]] = []
    _plants: Dict[str, List[Dict[str, Any]]] = {}  # element_id -> plant locations
    _payoffs: Dict[str, List[Dict[str, Any]]] = {}  # element_id -> payoff locations

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._elements = []
        self._plants = {}
        self._payoffs = {}

    async def on_init(self, context: WritingContext) -> None:
        """Initialize foreshadow plugin with session context"""
        logger.info(f"ForeshadowPlugin initialized for session {context.session_id}")
        if "foreshadow_elements" in context.metadata:
            self._elements = context.metadata.get("foreshadow_elements", [])
        if "foreshadow_plants" in context.metadata:
            self._plants = context.metadata.get("foreshadow_plants", {})

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for foreshadow data"""
        return {
            "type": "object",
            "title": "Foreshadow Schema",
            "description": "Schema for foreshadowing elements",
            "properties": {
                "element_id": {
                    "type": "string",
                    "description": "Unique foreshadow element identifier"
                },
                "name": {
                    "type": "string",
                    "description": "Foreshadow element name"
                },
                "type": {
                    "type": "string",
                    "enum": ["plot", "character", "object", "dialogue", "symbolic", "atmospheric"],
                    "description": "Type of foreshadowing"
                },
                "description": {
                    "type": "string",
                    "description": "What is being foreshadowed"
                },
                "importance": {
                    "type": "string",
                    "enum": ["critical", "major", "minor"],
                    "description": "Importance level"
                },
                "plant_chapter": {
                    "type": "integer",
                    "description": "Chapter where foreshadow is planted"
                },
                "payoff_chapter": {
                    "type": "integer",
                    "description": "Chapter where foreshadow is resolved"
                },
                "subtlety": {
                    "type": "string",
                    "enum": ["obvious", "moderate", "subtle", "very_subtle"],
                    "description": "How obvious the foreshadow should be"
                },
                "related_events": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Related event IDs"
                }
            },
            "required": ["element_id", "name", "type", "description"]
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for foreshadow-related tasks"""
        return {
            "foreshadow_planning": """## 任务: 规划伏笔系统

### 故事大纲
{outline}

### 事件链
{events}

### 伏笔规划要求

请为小说规划完整的伏笔系统:

**主线伏笔 (5-10个):**
每个伏笔包含:
1. **伏笔编号**: 唯一标识
2. **伏笔名称**: 简洁的名称
3. **伏笔类型**: 情节/角色/物品/对话/象征/氛围
4. **伏笔描述**: 要暗示什么内容 (50-100字)
5. **重要性等级**: 关键/重要/次要
6. **埋设位置**: 第几章埋设
7. **埋设方式**:
   - 对话暗示
   - 物品描写
   - 场景细节
   - 行为异常
   - 其他方式
8. **回收位置**: 第几章回收
9. **回收方式**: 如何揭示/解决
10. **影响范围**: 对故事的影响程度
11. **隐蔽程度**: 明显/适度/微妙/极微妙

**支线伏笔 (3-5个):**
同样的结构，但针对支线情节

**细节伏笔:**
- 可以埋藏伏笔的细节类型列表
- 隐藏技巧建议

**伏笔分布表:**
请制作表格显示:
- 章节
- 埋设的伏笔
- 回收的伏笔
- 确保分布均匀

请以 JSON 格式输出伏笔规划。
""",

            "foreshadow_validation": """## 任务: 检查伏笔一致性

### 伏笔规划
{foreshadow_plan}

### 检查内容
{content_to_check}

### 检查维度

1. **埋设检查**: 伏笔是否正确埋设
2. **回收检查**: 伏笔是否得到回收
3. **时机检查**: 埋设和回收的时机是否合理
4. **一致性检查**: 回收是否与埋设一致
5. **遗漏检查**: 是否有未回收的伏笔

### 输出要求

请输出 JSON 格式的检查结果:
```json
{{
  "is_consistent": true/false,
  "planted": ["已埋设的伏笔"],
  "resolved": ["已回收的伏笔"],
  "unresolved": ["未回收的伏笔"],
  "issues": ["具体问题"],
  "suggestions": ["修改建议"]
}}
```
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for foreshadow-related operations"""
        return [
            {
                "task_id": "foreshadow_list",
                "task_type": "伏笔列表",
                "description": "Plan foreshadowing elements for the story",
                "depends_on": ["事件"],
                "metadata": {
                    "plugin": "foreshadow",
                    "operation": "plan"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate foreshadow data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Foreshadow data must be a dictionary"]
            )

        # Check required fields
        required_fields = ["element_id", "name", "type", "description"]
        for field in required_fields:
            if field not in data:
                errors.append(f"Missing required field: {field}")

        # Validate foreshadow type
        valid_types = ["plot", "character", "object", "dialogue", "symbolic", "atmospheric"]
        if "type" in data and data["type"] not in valid_types:
            errors.append(f"Invalid foreshadow type: {data['type']}")

        # Check payoff chapter is after plant chapter
        plant_chapter = data.get("plant_chapter")
        payoff_chapter = data.get("payoff_chapter")
        if plant_chapter and payoff_chapter and payoff_chapter <= plant_chapter:
            errors.append(f"Payoff chapter ({payoff_chapter}) must be after plant chapter ({plant_chapter})")

        # Check for proper spacing
        if plant_chapter and payoff_chapter:
            spacing = payoff_chapter - plant_chapter
            if spacing < 3:
                warnings.append(f"Foreshadow spacing is short ({spacing} chapters), consider extending for better effect")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Extract and store foreshadow data from task results"""
        task_type = task.get("task_type", "")

        if task_type == "伏笔列表":
            await self._extract_foreshadows(result, context)

        return result

    async def _extract_foreshadows(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract foreshadow data from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                if isinstance(data, dict) and "foreshadows" in data:
                    self._elements = data["foreshadows"]
                    # Initialize plant and payoff tracking
                    for element in self._elements:
                        element_id = element.get("element_id")
                        if element_id:
                            self._plants[element_id] = []
                            self._payoffs[element_id] = []

                logger.info(f"Extracted {len(self._elements)} foreshadow elements")

        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse foreshadow data as JSON: {e}")
        except Exception as e:
            logger.error(f"Error extracting foreshadows: {e}")

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with foreshadow information"""
        task_type = task.get("task_type", "")
        chapter_index = task.get("metadata", {}).get("chapter_index")

        # Add foreshadow info for chapter generation
        if chapter_index is not None and ("章节" in task_type or "场景" in task_type):
            # Get foreshadows to plant in this chapter
            to_plant = self._get_foreshadows_to_plant(chapter_index)
            if to_plant:
                context["foreshadows_to_plant"] = to_plant

            # Get foreshadows to payoff in this chapter
            to_payoff = self._get_foreshadows_to_payoff(chapter_index)
            if to_payoff:
                context["foreshadows_to_payoff"] = to_payoff

        return context

    def _get_foreshadows_to_plant(self, chapter_index: int) -> List[Dict[str, Any]]:
        """Get foreshadows that should be planted in this chapter"""
        return [
            element for element in self._elements
            if element.get("plant_chapter") == chapter_index
        ]

    def _get_foreshadows_to_payoff(self, chapter_index: int) -> List[Dict[str, Any]]:
        """Get foreshadows that should be paid off in this chapter"""
        return [
            element for element in self._elements
            if element.get("payoff_chapter") == chapter_index
        ]

    def record_plant(self, element_id: str, chapter_index: int, details: Dict[str, Any]) -> None:
        """Record that a foreshadow was planted"""
        if element_id not in self._plants:
            self._plants[element_id] = []
        self._plants[element_id].append({
            "chapter": chapter_index,
            "timestamp": datetime.utcnow().isoformat(),
            **details
        })

    def record_payoff(self, element_id: str, chapter_index: int, details: Dict[str, Any]) -> None:
        """Record that a foreshadow was paid off"""
        if element_id not in self._payoffs:
            self._payoffs[element_id] = []
        self._payoffs[element_id].append({
            "chapter": chapter_index,
            "timestamp": datetime.utcnow().isoformat(),
            **details
        })

    def get_unresolved_foreshadows(self) -> List[Dict[str, Any]]:
        """Get foreshadows that haven't been paid off yet"""
        unresolved = []
        for element in self._elements:
            element_id = element.get("element_id")
            if element_id and not self._payoffs.get(element_id):
                unresolved.append(element)
        return unresolved

    def get_elements(self) -> List[Dict[str, Any]]:
        """Get all foreshadow elements"""
        return self._elements.copy()

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize foreshadow plugin and persist data"""
        logger.info("ForeshadowPlugin finalized")
        context.metadata["foreshadow_elements"] = self._elements
        context.metadata["foreshadow_plants"] = self._plants
        context.metadata["foreshadow_payoffs"] = self._payoffs

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.38 at 0x104bdb380>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Character Plugin - Manages character profiles, relationships, and development arcs

This plugin handles:
- Character profile creation and validation
- Relationship mapping between characters
- Character arc tracking throughout the story
- Voice consistency checking
"""

import json
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class CharacterPlugin(NovelElementPlugin):
    """
    Plugin for managing novel characters

    Tracks character profiles, relationships, and development arcs.
    Validates character consistency and provides character context.
    """

    name = "character"
    version = "1.0.0"
    description = "Manages character profiles, relationships, and development"
    author = "Creative AutoGPT"

    # Character state storage
    _characters: Dict[str, Dict[str, Any]] = {}
    _relationships: Dict[str, List[Dict[str, Any]]] = {}
    _arcs: Dict[str, List[Dict[str, Any]]] = {}

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._characters = {}
        self._relationships = {}
        self._arcs = {}

    async def on_init(self, context: WritingContext) -> None:
        """Initialize character plugin with session context"""
        logger.info(f"CharacterPlugin initialized for session {context.session_id}")
        # Load any existing character data from context
        if "characters" in context.metadata:
            self._characters = context.metadata.get("characters", {})
        if "relationships" in context.metadata:
            self._relationships = context.metadata.get("relationships", {})

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for character data"""
        return {
            "type": "object",
            "title": "Character Schema",
            "description": "Schema for novel character profiles",
            "properties": {
                "character_id": {
                    "type": "string",
                    "description": "Unique character identifier"
                },
                "name": {
                    "type": "string",
                    "description": "Character name"
                },
                "age": {
                    "type": "integer",
                    "description": "Character age"
                },
                "gender": {
                    "type": "string",
                    "enum": ["male", "female", "other", "unspecified"],
                    "description": "Character gender"
                },
                "appearance": {
                    "type": "string",
                    "description": "Physical appearance description"
                },
                "personality": {
                    "type": "object",
                    "properties": {
                        "traits": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Personality traits"
                        },
                        "strengths": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Character strengths"
                        },
                        "weaknesses": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "Character weaknesses"
                        }
                    }
                },
                "background": {
                    "type": "object",
                    "properties": {
                        "origin": {"type": "string"},
                        "family": {"type": "string"},
                        "education": {"type": "string"},
                        "occupation": {"type": "string"},
                        "history": {"type": "string"}
                    }
                },
                "motivation": {
                    "type": "object",
                    "properties": {
                        "primary_goal": {"type": "string"},
                        "secondary_goals": {
                            "type": "array",
                            "items": {"type": "string"}
                        },
                        "fears": {"type": "array", "items": {"type": "string"}},
                        "desires": {"type": "array", "items": {"type": "string"}}
                    }
                },
                "abilities": {
                    "type": "object",
                    "properties": {
                        "skills": {"type": "array", "items": {"type": "string"}},
                        "powers": {"type": "array", "items": {"type": "string"}},
                        "limitations": {"type": "array", "items": {"type": "string"}}
                    }
                },
                "role": {
                    "type": "string",
                    "enum": ["protagonist", "antagonist", "supporting", "minor"],
                    "description": "Character's role in the story"
                },
                "voice_profile": {
                    "type": "object",
                    "properties": {
                        "speech_patterns": {"type": "array", "items": {"type": "string"}},
                        "vocabulary_level": {"type": "string"},
                        "catchphrases": {"type": "array", "items": {"type": "string"}},
                        "tone": {"type": "string"}
                    }
                }
            },
            "required": ["character_id", "name", "role"]
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for character-related tasks"""
        return {
            "character_design": """## 任务: 设计人物角色

请为小说设计详细的人物角色档案。

### 设计要求

**主角档案:**
- 姓名: 具有角色特色的姓名
- 年龄: 符合角色定位
- 性别:
- 外貌: 详细的体貌特征描述 (100-200字)
- 性格特点:
  - 核心性格特质 (3-5个)
  - 优点 (2-3个)
  - 缺点 (2-3个，角色成长的突破口)
- 背景设定:
  - 出身/来历
  - 家庭状况
  - 成长经历
  - 职业/身份
- 核心动机:
  - 主要目标: 主角最想达成的目标
  - 次要目标: 支撑性目标
  - 恐惧: 主角最害怕的事物
  - 渴望: 主角内心深处的渴望
- 能力设定:
  - 技能: 擅长的技能
  - 特殊能力: 如适用
  - 限制: 能力的局限性
- 成长弧线:
  - 初始状态: 故事开始时的状态
  - 成长节点: 关键的成长转折点
  - 最终状态: 预期的成长结果
- 声音特征:
  - 说话习惯: 特殊的说话方式
  - 用词特点: 词汇风格
  - 口头禅: 标志性的话语
  - 语气基调: 整体语气

**配角设计:**
请设计 3-5 个重要配角，每个包含:
- 姓名和定位
- 与主角的关系
- 在故事中的作用
- 核心特征

**人物关系图:**
- 主要人物之间的关系网络
- 关系的动态变化

请以结构化的 JSON 格式输出。
""",

            "relationship_mapping": """## 任务: 构建人物关系图谱

### 已有角色
{characters}

### 关系映射要求

请分析并定义角色之间的关系:

1. **关系类型**: 家人/恋人/朋友/师徒/仇敌/竞争/其他
2. **关系强度**: 密切/一般/疏远
3. **关系性质**: 正面/负面/复杂
4. **关系动态**: 关系在故事中的变化方向
5. **关键场景**: 展现关系的重要场景

请以 JSON 格式输出关系图谱。
""",

            "character_consistency_check": """## 任务: 检查角色一致性

### 角色档案
{character_profiles}

### 检查内容
{content_to_check}

### 检查维度

1. **性格一致性**: 角色行为是否符合已设定性格
2. **声音一致性**: 对话是否符合角色说话风格
3. **能力一致性**: 角色表现的能力是否与设定匹配
4. **动机一致性**: 角色行为是否与其动机一致
5. **关系一致性**: 角色互动是否符合关系设定

### 输出要求

请输出 JSON 格式的检查结果:
```json
{{
  "is_consistent": true/false,
  "issues": ["具体的不一致问题"],
  "suggestions": ["修改建议"],
  "character_usage": {{
    "character_name": {{
      "appearances": 出现次数,
      "consistency_score": 一致性评分,
      "notes": "备注"
    }}
  }}
}}
```
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for character-related operations"""
        return [
            {
                "task_id": "character_design",
                "task_type": "人物设计",
                "description": "Design main and supporting characters with detailed profiles",
                "depends_on": ["大纲"],
                "metadata": {
                    "plugin": "character",
                    "operation": "design"
                }
            },
            {
                "task_id": "relationship_mapping",
                "task_type": "人物关系",
                "description": "Map relationships between characters",
                "depends_on": ["人物设计"],
                "metadata": {
                    "plugin": "character",
                    "operation": "relationships"
                }
            },
            {
                "task_id": "character_voice_check",
                "task_type": "对话检查",
                "description": "Check character voice consistency in dialogue",
                "depends_on": ["章节内容"],
                "metadata": {
                    "plugin": "character",
                    "operation": "voice_check"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate character data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Character data must be a dictionary"]
            )

        # Check required fields
        required_fields = ["character_id", "name", "role"]
        for field in required_fields:
            if field not in data:
                errors.append(f"Missing required field: {field}")

        # Validate role
        valid_roles = ["protagonist", "antagonist", "supporting", "minor"]
        if "role" in data and data["role"] not in valid_roles:
            errors.append(f"Invalid role: {data['role']}. Must be one of {valid_roles}")

        # Check for character completeness
        if "personality" not in data:
            warnings.append("Character missing personality traits")
        elif "traits" in data["personality"] and len(data["personality"]["traits"]) < 3:
            suggestions.append("Add more personality traits for depth")

        if "motivation" not in data:
            warnings.append("Character missing motivation/goals")
            suggestions.append("Define character motivation for better character development")

        # Check voice profile
        if "voice_profile" not in data:
            suggestions.append("Add voice profile for consistent dialogue")

        # Check relationships exist if this is not the first character
        character_count = len(self._characters)
        if character_count > 0 and "relationships" not in data:
            suggestions.append("Define relationships with existing characters")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Extract and store character data from task results"""
        task_type = task.get("task_type", "")

        if task_type == "人物设计":
            await self._extract_characters(result, context)
        elif task_type == "人物关系":
            await self._extract_relationships(result, context)
        elif task_type == "对话检查":
            await self._process_voice_check(result, context)

        return result

    async def _extract_characters(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract character profiles from design result"""
        try:
            # Try to parse as JSON
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                # Store characters
                if isinstance(data, dict):
                    if "characters" in data:
                        characters = data["characters"]
                    elif "主角" in data or "protagonist" in data:
                        characters = {"protagonist": data, "supporting": data.get("配角", [])}
                    else:
                        characters = data

                    for char_id, char_data in characters.items():
                        if isinstance(char_data, dict):
                            if "character_id" not in char_data:
                                char_data["character_id"] = char_id
                            self._characters[char_id] = char_data

                logger.info(f"Extracted {len(self._characters)} character profiles")

        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse character data as JSON: {e}")
        except Exception as e:
            logger.error(f"Error extracting characters: {e}")

    async def _extract_relationships(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract relationship data from result"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                # Store relationships
                if isinstance(data, dict) and "relationships" in data:
                    self._relationships = data["relationships"]
                    logger.info(f"Extracted relationship data for {len(self._relationships)} characters")

        except Exception as e:
            logger.error(f"Error extracting relationships: {e}")

    async def _process_voice_check(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Process voice consistency check results"""
        # Store check results in context for future reference
        if "voice_check_results" not in context.metadata:
            context.metadata["voice_check_results"] = []
        context.metadata["voice_check_results"].append({
            "timestamp": datetime.utcnow().isoformat(),
            "result": result
        })

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with character information"""
        task_type = task.get("task_type", "")

        # Add character summaries to context
        if self._characters:
            context["characters"] = self._get_character_summaries()

        # Add relationships to context
        if self._relationships:
            context["character_relationships"] = self._relationships

        # For dialogue-related tasks, add voice profiles
        if "对话" in task_type or "章节" in task_type:
            voice_profiles = self._get_voice_profiles()
            if voice_profiles:
                context["character_voices"] = voice_profiles

        return context

    def _get_character_summaries(self) -> List[Dict[str, Any]]:
        """Get brief summaries of all characters"""
        summaries = []
        for char_id, char_data in self._characters.items():
            summary = {
                "id": char_id,
                "name": char_data.get("name", char_id),
                "role": char_data.get("role", "unknown"),
                "traits": char_data.get("personality", {}).get("traits", [])[:3]
            }
            summaries.append(summary)
        return summaries

    def _get_voice_profiles(self) -> Dict[str, Dict[str, Any]]:
        """Get voice profiles for all characters"""
        profiles = {}
        for char_id, char_data in self._characters.items():
            voice = char_data.get("voice_profile")
            if voice:
                profiles[char_id] = {
                    "name": char_data.get("name", char_id),
                    "voice": voice
                }
        return profiles

    def get_characters(self) -> Dict[str, Dict[str, Any]]:
        """Get all stored character data"""
        return self._characters.copy()

    def get_character(self, character_id: str) -> Optional[Dict[str, Any]]:
        """Get a specific character by ID"""
        return self._characters.get(character_id)

    def get_relationships(self) -> Dict[str, List[Dict[str, Any]]]:
        """Get all relationship data"""
        return self._relationships.copy()

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize character plugin and persist data"""
        logger.info("CharacterPlugin finalized")
        # Store final state in context for persistence
        context.metadata["characters"] = self._characters
        context.metadata["relationships"] = self._relationships
        context.metadata["character_arcs"] = self._arcs

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.40 at 0x104c26750>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  [Previous line repeated 2 more times]
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Dialogue Plugin - Manages dialogue style and character voice consistency

This plugin handles:
- Character voice profiles
- Dialogue consistency checking
- Dialogue style validation
- Natural dialogue improvement suggestions
"""

import json
import re
from typing import Any, Dict, List, Optional
from datetime import datetime

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    ValidationResult,
    WritingContext,
)


class DialoguePlugin(NovelElementPlugin):
    """
    Plugin for managing dialogue quality and consistency

    Tracks character voices and validates dialogue consistency.
    """

    name = "dialogue"
    version = "1.0.0"
    description = "Manages dialogue style and character voice consistency"
    author = "Creative AutoGPT"

    # Dialogue state storage
    _voice_profiles: Dict[str, Dict[str, Any]] = {}
    _dialogue_samples: Dict[str, List[str]] = {}  # character_id -> sample dialogues
    _dialogue_issues: List[Dict[str, Any]] = []

    def __init__(self, config: Optional[PluginConfig] = None):
        super().__init__(config)
        self._voice_profiles = {}
        self._dialogue_samples = {}
        self._dialogue_issues = []

    async def on_init(self, context: WritingContext) -> None:
        """Initialize dialogue plugin with session context"""
        logger.info(f"DialoguePlugin initialized for session {context.session_id}")
        if "voice_profiles" in context.metadata:
            self._voice_profiles = context.metadata.get("voice_profiles", {})

    def get_schema(self) -> Dict[str, Any]:
        """Get JSON schema for dialogue/voice profile data"""
        return {
            "type": "object",
            "title": "Voice Profile Schema",
            "description": "Schema for character voice profiles",
            "properties": {
                "character_id": {
                    "type": "string",
                    "description": "Character identifier"
                },
                "speech_patterns": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Common speech patterns"
                },
                "vocabulary_level": {
                    "type": "string",
                    "enum": ["formal", "casual", "slang", "archaic", "technical", "childish"],
                    "description": "Vocabulary style"
                },
                "sentence_structure": {
                    "type": "string",
                    "description": "Typical sentence structure pattern"
                },
                "catchphrases": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Characteristic phrases"
                },
                "tone": {
                    "type": "string",
                    "enum": ["aggressive", "gentle", "sarcastic", "formal", "friendly", "cold", "enthusiastic"],
                    "description": "Default speaking tone"
                },
                "quirks": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Speech quirks and habits"
                },
                "topics": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Frequently discussed topics"
                }
            },
            "required": ["character_id"]
        }

    def get_prompts(self) -> Dict[str, str]:
        """Get prompt templates for dialogue-related tasks"""
        return {
            "dialogue_check": """## 任务: 检查对话一致性

### 角色声音档案
{voice_profiles}

### 检查内容
{content_to_check}

### 检查维度

1. **声音一致性**: 每个角色的对话是否符合其声音设定
2. **说话习惯**: 是否使用了角色特有的说话方式
3. **用词风格**: 词汇水平是否一致
4. **口头禅**: 标志性话语是否得到体现
5. **语气基调**: 整体语气是否符合设定
6. **对话自然度**: 对话是否自然流畅
7. **对话推动**: 对话是否有效推动情节或展现角色

### 输出要求

请输出 JSON 格式的检查结果:
```json
{{
  "overall_score": 85,
  "is_consistent": true,
  "character_scores": {{
    "character_name": {{
      "consistency": 90,
      "naturalness": 85,
      "voice_match": 88,
      "issues": ["具体问题"],
      "suggestions": ["改进建议"]
    }}
  }},
  "overall_issues": ["整体问题"],
  "improvement_suggestions": ["改进建议"]
}}
```
""",

            "dialogue_improvement": """## 任务: 改进对话质量

### 原始对话
{original_dialogue}

### 角色设定
{character_profiles}

### 发现的问题
{issues}

### 改进要求

请根据角色设定改进对话:
1. 保持情节内容不变
2. 使对话更符合角色声音
3. 提升对话自然度
4. 增强对话的表现力

请直接输出改进后的对话片段。
""",

            "voice_profile_creation": """## 任务: 创建角色声音档案

### 角色信息
{character_info}

### 声音档案要求

为每个角色创建详细的声音档案:

**1. 说话模式:**
- 句式特点: (短句/长句/复杂句/简单句)
- 语言风格: (正式/随意/俚语/古风/技术/幼稚)
- 语速感: (快/中/慢)
- 停顿习惯

**2. 用词特征:**
- 常用词汇类型
- 避免使用的词汇
- 专业术语/方言

**3. 口头禅:**
- 3-5个标志性话语
- 使用场景

**4. 语气基调:**
- 默认语气
- 情绪变化时的语气
- 特殊情况下的语气

**5. 语言怪癖:**
- 特殊的语言习惯
- 口吃/重复/其他
- 情绪相关的语言特征

**6. 话题偏好:**
- 经常谈论的话题
- 避免的话题
- 表达观点的方式

请以 JSON 格式输出声音档案。
"""
        }

    def get_tasks(self) -> List[Dict[str, Any]]:
        """Get task definitions for dialogue-related operations"""
        return [
            {
                "task_id": "dialogue_check",
                "task_type": "对话检查",
                "description": "Check dialogue consistency and quality",
                "depends_on": ["章节内容"],
                "metadata": {
                    "plugin": "dialogue",
                    "operation": "check"
                }
            }
        ]

    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """Validate dialogue/voice profile data"""
        errors = []
        warnings = []
        suggestions = []

        if not isinstance(data, dict):
            return ValidationResult(
                valid=False,
                errors=["Voice profile data must be a dictionary"]
            )

        if "character_id" not in data:
            errors.append("Missing character_id")

        # Check for voice elements
        if not data.get("speech_patterns"):
            suggestions.append("Add speech patterns for better voice definition")

        if not data.get("catchphrases"):
            warnings.append("No catchphrases defined - consider adding some")

        if not data.get("tone"):
            suggestions.append("Define default tone for consistency")

        return ValidationResult(
            valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions,
        )

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """Process dialogue-related task results"""
        task_type = task.get("task_type", "")

        if task_type == "对话检查":
            await self._process_dialogue_check(result, context)
        elif task_type == "人物设计":
            # Extract voice profiles from character design
            await self._extract_voice_profiles(result, context)

        return result

    async def _process_dialogue_check(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Process dialogue check results"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                # Store issues if any
                if "overall_issues" in data:
                    for issue in data.get("overall_issues", []):
                        self._dialogue_issues.append({
                            "issue": issue,
                            "timestamp": datetime.utcnow().isoformat()
                        })

                # Store character scores
                if "character_scores" in data:
                    for char_name, scores in data["character_scores"].items():
                        if char_name not in self._dialogue_samples:
                            self._dialogue_samples[char_name] = []

        except Exception as e:
            logger.error(f"Error processing dialogue check: {e}")

    async def _extract_voice_profiles(
        self,
        result: str,
        context: WritingContext,
    ) -> None:
        """Extract voice profiles from character design"""
        try:
            if "{" in result and "}" in result:
                json_start = result.find("{")
                json_end = result.rfind("}") + 1
                json_str = result[json_start:json_end]
                data = json.loads(json_str)

                # Look for voice_profile section
                if isinstance(data, dict) and "voice_profile" in data:
                    voice_data = data["voice_profile"]
                    character_id = data.get("character_id") or data.get("name", "unknown")
                    voice_data["character_id"] = character_id
                    self._voice_profiles[character_id] = voice_data

        except Exception as e:
            logger.error(f"Error extracting voice profiles: {e}")

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Enrich context with dialogue information"""
        task_type = task.get("task_type", "")

        if "对话" in task_type or "章节" in task_type:
            # Add voice profiles for dialogue generation
            if self._voice_profiles:
                context["voice_profiles"] = self._voice_profiles

        return context

    def set_voice_profile(self, character_id: str, profile: Dict[str, Any]) -> None:
        """Set a character's voice profile"""
        profile["character_id"] = character_id
        self._voice_profiles[character_id] = profile

    def get_voice_profile(self, character_id: str) -> Optional[Dict[str, Any]]:
        """Get a character's voice profile"""
        return self._voice_profiles.get(character_id)

    def get_all_voice_profiles(self) -> Dict[str, Dict[str, Any]]:
        """Get all voice profiles"""
        return self._voice_profiles.copy()

    def add_dialogue_sample(self, character_id: str, dialogue: str) -> None:
        """Add a dialogue sample for a character"""
        if character_id not in self._dialogue_samples:
            self._dialogue_samples[character_id] = []
        self._dialogue_samples[character_id].append(dialogue)

    def get_dialogue_samples(self, character_id: str) -> List[str]:
        """Get dialogue samples for a character"""
        return self._dialogue_samples.get(character_id, []).copy()

    def extract_dialogue_from_content(self, content: str) -> Dict[str, List[str]]:
        """Extract dialogue lines from content"""
        dialogue_pattern = re.compile(r'"([^"]+)"')
        matches = dialogue_pattern.findall(content)

        # This is a simple extraction - in production would need better parsing
        # to associate dialogue with specific characters
        return {"extracted": matches}

    async def on_finalize(self, context: WritingContext) -> None:
        """Finalize dialogue plugin and persist data"""
        logger.info("DialoguePlugin finalized")
        context.metadata["voice_profiles"] = self._voice_profiles
        context.metadata["dialogue_samples"] = self._dialogue_samples
        context.metadata["dialogue_issues"] = self._dialogue_issues

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.41 at 0x104b1b770>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Plugin Manager - Manages the plugin lifecycle and execution

Coordinates plugins, handles dependencies, and executes hooks.
"""

from collections import OrderedDict
from typing import Any, Dict, List, Optional, Type

from loguru import logger

from creative_autogpt.plugins.base import (
    NovelElementPlugin,
    PluginConfig,
    PluginPhase,
    ValidationResult,
    WritingContext,
)


class PluginDependencyError(Exception):
    """Raised when plugin dependencies are not met"""

    pass


class PluginNotFoundError(Exception):
    """Raised when a required plugin is not found"""

    pass


class PluginManager:
    """
    Manages the plugin system

    Responsibilities:
    - Register/unregister plugins
    - Enable/disable plugins
    - Resolve dependencies
    - Execute plugin hooks in correct order
    """

    def __init__(self):
        """Initialize plugin manager"""
        # Registered plugins (name -> plugin instance)
        self._plugins: Dict[str, NovelElementPlugin] = {}

        # Enabled plugins (name -> plugin instance)
        self._enabled: Dict[str, NovelElementPlugin] = {}

        # Load order (sorted by priority)
        self._load_order: List[str] = []

        logger.info("PluginManager initialized")

    def register(self, plugin: NovelElementPlugin) -> None:
        """
        Register a plugin

        Args:
            plugin: Plugin instance to register

        Raises:
            PluginDependencyError: If dependencies are not met
        """
        # Check for duplicate name
        if plugin.name in self._plugins:
            logger.warning(f"Plugin '{plugin.name}' already registered, replacing")

        # Check dependencies
        for dep in plugin.get_dependencies():
            if dep not in self._plugins:
                raise PluginDependencyError(
                    f"Plugin '{plugin.name}' requires '{dep}' which is not registered"
                )

        # Register the plugin
        self._plugins[plugin.name] = plugin

        # Re-calculate load order
        self._recalculate_load_order()

        # Auto-enable if config says so
        if plugin.is_enabled():
            self.enable(plugin.name)

        logger.info(
            f"Registered plugin: {plugin.name} v{plugin.version} "
            f"(priority: {plugin.get_priority()})"
        )

    def unregister(self, name: str) -> bool:
        """
        Unregister a plugin

        Args:
            name: Plugin name

        Returns:
            True if successful, False if plugin not found
        """
        if name not in self._plugins:
            return False

        # Disable first
        self.disable(name)

        # Remove from registry
        del self._plugins[name]

        # Re-calculate load order
        self._recalculate_load_order()

        logger.info(f"Unregistered plugin: {name}")
        return True

    def enable(self, name: str, config: Optional[PluginConfig] = None) -> None:
        """
        Enable a plugin

        Args:
            name: Plugin name
            config: Optional new configuration

        Raises:
            PluginNotFoundError: If plugin not found
        """
        if name not in self._plugins:
            raise PluginNotFoundError(f"Plugin '{name}' not found")

        plugin = self._plugins[name]

        # Update config if provided
        if config:
            plugin.config = config

        # Check dependencies
        for dep in plugin.get_dependencies():
            if dep not in self._enabled:
                logger.warning(
                    f"Enabling plugin '{name}' but dependency '{dep}' is not enabled"
                )

        # Enable the plugin
        self._enabled[name] = plugin

        logger.info(f"Enabled plugin: {name}")

    def disable(self, name: str) -> None:
        """
        Disable a plugin

        Args:
            name: Plugin name
        """
        if name in self._enabled:
            del self._enabled[name]
            logger.info(f"Disabled plugin: {name}")

    def is_enabled(self, name: str) -> bool:
        """Check if a plugin is enabled"""
        return name in self._enabled

    def get(self, name: str) -> Optional[NovelElementPlugin]:
        """Get a plugin by name"""
        return self._plugins.get(name)

    def list_all(self) -> List[str]:
        """List all registered plugin names"""
        return list(self._plugins.keys())

    def list_enabled(self) -> List[str]:
        """List enabled plugin names"""
        return list(self._enabled.keys())

    def get_load_order(self) -> List[str]:
        """Get the plugin load order"""
        return self._load_order.copy()

    def _recalculate_load_order(self) -> None:
        """Re-calculate plugin load order based on priority"""
        # Sort by priority (higher first), then by name for stability
        sorted_plugins = sorted(
            self._plugins.items(),
            key=lambda x: (-x[1].get_priority(), x[0])
        )

        self._load_order = [name for name, _ in sorted_plugins]

        logger.debug(f"Plugin load order: {self._load_order}")

    async def run_hook(
        self,
        hook_name: str,
        *args,
        **kwargs,
    ) -> List[Any]:
        """
        Run a hook on all enabled plugins

        Args:
            hook_name: Name of the hook method
            *args: Positional arguments for the hook
            **kwargs: Keyword arguments for the hook

        Returns:
            List of results from each plugin
        """
        results = []

        for name in self._load_order:
            if name not in self._enabled:
                continue

            plugin = self._enabled[name]

            # Check if plugin has the hook method
            if not hasattr(plugin, hook_name):
                continue

            hook = getattr(plugin, hook_name)

            # Skip if not callable
            if not callable(hook):
                continue

            try:
                # Execute the hook
                if hook_name in ("on_init", "on_finalize"):
                    # These hooks don't return values
                    await hook(*args, **kwargs)
                else:
                    # These hooks may return modified values
                    result = await hook(*args, **kwargs)
                    results.append(result)

            except Exception as e:
                logger.error(
                    f"Plugin '{name}' hook '{hook_name}' failed: {e}",
                    exc_info=True,
                )

        return results

    async def initialize_all(self, context: WritingContext) -> None:
        """
        Initialize all enabled plugins

        Args:
            context: Writing context
        """
        logger.info(f"Initializing {len(self._enabled)} plugins")

        await self.run_hook("on_init", context)

    async def finalize_all(self, context: WritingContext) -> None:
        """
        Finalize all enabled plugins

        Args:
            context: Writing context
        """
        logger.info("Finalizing all plugins")

        await self.run_hook("on_finalize", context)

    async def before_task(
        self,
        task: Dict[str, Any],
        context: WritingContext,
    ) -> Dict[str, Any]:
        """
        Run before-task hooks

        Args:
            task: Task configuration
            context: Writing context

        Returns:
            Modified task configuration
        """
        results = await self.run_hook("on_before_task", task, context)

        # Apply modifications in order (each plugin sees previous modifications)
        modified_task = task
        for result in results:
            if isinstance(result, dict):
                modified_task = result

        return modified_task

    async def after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """
        Run after-task hooks

        Args:
            task: Task configuration
            result: Generated content
            context: Writing context

        Returns:
            Modified content
        """
        results = await self.run_hook("on_after_task", task, result, context)

        # Apply modifications in order
        modified_result = result
        for plugin_result in results:
            if isinstance(plugin_result, str):
                modified_result = plugin_result

        return modified_result

    async def validate_all(
        self,
        data: Any,
        context: WritingContext,
    ) -> List[ValidationResult]:
        """
        Run validation on all enabled plugins

        Args:
            data: Data to validate
            context: Writing context

        Returns:
            List of validation results
        """
        results = []

        for name in self._load_order:
            if name not in self._enabled:
                continue

            plugin = self._enabled[name]

            try:
                result = await plugin.validate(data, context)
                results.append(result)

                if not result.valid:
                    logger.warning(
                        f"Plugin '{name}' validation failed: {result.errors}"
                    )

            except Exception as e:
                logger.error(f"Plugin '{name}' validation error: {e}")
                results.append(
                    ValidationResult(
                        valid=False,
                        errors=[f"Validation error: {str(e)}"],
                    )
                )

        return results

    def get_schemas(self) -> Dict[str, Dict[str, Any]]:
        """
        Get all plugin schemas

        Returns:
            Dict of plugin_name -> schema
        """
        schemas = {}

        for name, plugin in self._plugins.items():
            try:
                schema = plugin.get_schema()
                schemas[name] = schema
            except Exception as e:
                logger.error(f"Failed to get schema for '{name}': {e}")

        return schemas

    def get_prompts(self) -> Dict[str, Dict[str, str]]:
        """
        Get all plugin prompts

        Returns:
            Dict of plugin_name -> prompts
        """
        all_prompts = {}

        for name, plugin in self._plugins.items():
            try:
                prompts = plugin.get_prompts()
                all_prompts[name] = prompts
            except Exception as e:
                logger.error(f"Failed to get prompts for '{name}': {e}")

        return all_prompts

    def get_tasks(self) -> List[Dict[str, Any]]:
        """
        Get all plugin task definitions

        Returns:
            List of task definitions
        """
        all_tasks = []

        for name in self._load_order:
            if name not in self._enabled:
                continue

            plugin = self._enabled[name]

            try:
                tasks = plugin.get_tasks()
                all_tasks.extend(tasks)
            except Exception as e:
                logger.error(f"Failed to get tasks for '{name}': {e}")

        return all_tasks

    def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        Enrich context using all enabled plugins

        Args:
            task: Task configuration
            context: Current context

        Returns:
            Enriched context
        """
        for name in self._load_order:
            if name not in self._enabled:
                continue

            plugin = self._enabled[name]

            try:
                context = plugin.enrich_context(task, context)
            except Exception as e:
                logger.error(f"Plugin '{name}' context enrichment failed: {e}")

        return context

    def get_info(self, name: str) -> Optional[Dict[str, Any]]:
        """
        Get information about a plugin

        Args:
            name: Plugin name

        Returns:
            Plugin information dict
        """
        plugin = self._plugins.get(name)
        if not plugin:
            return None

        return {
            "name": plugin.name,
            "version": plugin.version,
            "description": plugin.description,
            "author": plugin.author,
            "enabled": self.is_enabled(name),
            "priority": plugin.get_priority(),
            "dependencies": plugin.get_dependencies(),
            "config": plugin.config.to_dict(),
        }

    def get_all_info(self) -> List[Dict[str, Any]]:
        """Get information about all plugins"""
        return [
            self.get_info(name)
            for name in self._plugins.keys()
        ]

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Plugin base classes and interfaces

Provides the foundation for the novel element plugin system.
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from loguru import logger


class PluginPhase(str, Enum):
    """Phases when a plugin can intervene"""

    PLANNING = "planning"  # During task planning
    GENERATION = "generation"  # During content generation
    EVALUATION = "evaluation"  # During quality evaluation
    POST_PROCESS = "post_process"  # After content generation


@dataclass
class PluginConfig:
    """Configuration for a plugin"""

    enabled: bool = True
    priority: int = 50  # Execution priority (0-100, higher first)
    phases: List[PluginPhase] = field(default_factory=list)
    settings: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "enabled": self.enabled,
            "priority": self.priority,
            "phases": [p.value for p in self.phases],
            "settings": self.settings,
        }


@dataclass
class ValidationResult:
    """Result of validation"""

    valid: bool
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "valid": self.valid,
            "errors": self.errors,
            "warnings": self.warnings,
            "suggestions": self.suggestions,
        }


@dataclass
class WritingContext:
    """Context shared across plugins during writing"""

    session_id: str
    goal: Dict[str, Any] = field(default_factory=dict)
    current_task: Optional[Dict[str, Any]] = None
    current_chapter: Optional[int] = None
    results: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def get_result(self, task_id: str) -> Optional[Any]:
        """Get a task result"""
        return self.results.get(task_id)

    def set_result(self, task_id: str, result: Any) -> None:
        """Set a task result"""
        self.results[task_id] = result

    def to_dict(self) -> Dict[str, Any]:
        return {
            "session_id": self.session_id,
            "goal": self.goal,
            "current_task": self.current_task,
            "current_chapter": self.current_chapter,
            "results": self.results,
            "metadata": self.metadata,
        }


class NovelElementPlugin(ABC):
    """
    Base class for novel element plugins

    Each plugin manages a specific element type:
    - Characters, Worldview, Events, etc.
    - Provides schema, prompts, validation
    - Can inject/modify content during generation
    """

    # Plugin metadata
    name: str = ""  # Unique plugin name
    version: str = "1.0.0"
    description: str = ""
    author: str = ""
    dependencies: List[str] = field(default_factory=list)  # Required plugins

    # Plugin configuration
    config: PluginConfig = field(default_factory=PluginConfig)

    def __init__(self, config: Optional[PluginConfig] = None):
        """
        Initialize plugin

        Args:
            config: Plugin configuration
        """
        if config:
            self.config = config
        logger.debug(f"Initialized plugin: {self.name}")

    @abstractmethod
    async def on_init(self, context: WritingContext) -> None:
        """
        Called when plugin is initialized

        Args:
            context: Writing context
        """
        pass

    async def on_before_task(
        self,
        task: Dict[str, Any],
        context: WritingContext,
    ) -> Dict[str, Any]:
        """
        Called before a task is executed

        Can modify the task configuration.

        Args:
            task: Task configuration
            context: Writing context

        Returns:
            Modified task configuration
        """
        return task

    async def on_after_task(
        self,
        task: Dict[str, Any],
        result: str,
        context: WritingContext,
    ) -> str:
        """
        Called after a task is executed

        Can modify the generated result.

        Args:
            task: Task configuration
            result: Generated content
            context: Writing context

        Returns:
            Modified content
        """
        return result

    async def on_finalize(self, context: WritingContext) -> None:
        """
        Called when writing session is complete

        Args:
            context: Writing context
        """
        pass

    @abstractmethod
    def get_schema(self) -> Dict[str, Any]:
        """
        Get the data schema for this element type

        Returns:
            Schema definition (JSON Schema compatible)
        """
        pass

    @abstractmethod
    def get_prompts(self) -> Dict[str, str]:
        """
        Get prompt templates for this element type

        Returns:
            Dict of prompt_name -> prompt_template
        """
        pass

    @abstractmethod
    def get_tasks(self) -> List[Dict[str, Any]]:
        """
        Get task definitions for this element type

        Returns:
            List of task definitions
        """
        pass

    @abstractmethod
    async def validate(
        self,
        data: Any,
        context: WritingContext,
    ) -> ValidationResult:
        """
        Validate data for this element type

        Args:
            data: Data to validate
            context: Writing context

        Returns:
            Validation result
        """
        pass

    async def enrich_context(
        self,
        task: Dict[str, Any],
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        Enrich context with element-specific information

        Args:
            task: Task configuration
            context: Current context

        Returns:
            Enriched context
        """
        return context

    async def generate_content(
        self,
        task_type: str,
        context: WritingContext,
    ) -> Optional[str]:
        """
        Optional: Generate content for this element type

        Args:
            task_type: Type of task
            context: Writing context

        Returns:
            Generated content, or None if not applicable
        """
        return None

    def get_dependencies(self) -> List[str]:
        """Get list of plugin dependencies"""
        return self.dependencies.copy()

    def is_enabled(self) -> bool:
        """Check if plugin is enabled"""
        return self.config.enabled

    def get_priority(self) -> int:
        """Get plugin execution priority"""
        return self.config.priority

    def get_phases(self) -> List[PluginPhase]:
        """Get phases when plugin should be invoked"""
        return self.config.phases.copy()

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 426, in infer_subscript
    for value in self.value.infer(context):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-31.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
File Store - Manages file-based content storage

Handles export of novels to various formats (TXT, DOCX, PDF, etc.)
"""

import json
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger

from creative_autogpt.utils.config import get_settings


class ExportFormat(str, Enum):
    """Supported export formats"""

    TXT = "txt"
    JSON = "json"
    MARKDOWN = "md"


class FileStore:
    """
    File-based storage for novel exports

    Manages:
    - Export to various formats
    - Chapter file organization
    - Backup management
    """

    def __init__(self, base_path: Optional[str] = None):
        """
        Initialize file store

        Args:
            base_path: Base directory for storage
        """
        settings = get_settings()
        self.base_path = Path(base_path or settings.local_storage_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"FileStore initialized at {self.base_path}")

    def _get_session_path(self, session_id: str) -> Path:
        """Get path for a session"""
        session_path = self.base_path / session_id
        session_path.mkdir(parents=True, exist_ok=True)
        return session_path

    async def save_chapter(
        self,
        session_id: str,
        chapter_index: int,
        content: str,
        title: Optional[str] = None,
    ) -> Path:
        """
        Save a chapter to a file

        Args:
            session_id: The session ID
            chapter_index: Chapter index
            content: Chapter content
            title: Optional chapter title

        Returns:
            Path to saved file
        """
        session_path = self._get_session_path(session_id)

        if title:
            filename = f"{chapter_index:03d}_{title}.txt"
        else:
            filename = f"{chapter_index:03d}.txt"

        file_path = session_path / "chapters" / filename
        file_path.parent.mkdir(parents=True, exist_ok=True)

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)

        logger.debug(f"Saved chapter {chapter_index} to {file_path}")
        return file_path

    async def save_full_novel(
        self,
        session_id: str,
        title: str,
        chapters: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """
        Save complete novel as a single file

        Args:
            session_id: The session ID
            title: Novel title
            chapters: List of chapter data
            metadata: Optional metadata

        Returns:
            Path to saved file
        """
        session_path = self._get_session_path(session_id)
        file_path = session_path / f"{title}.txt"

        with open(file_path, "w", encoding="utf-8") as f:
            # Title page
            f.write(f"{title}\n")
            f.write("=" * len(title) + "\n\n")

            if metadata:
                f.write(f"作者: {metadata.get('author', '未知')}\n")
                f.write(f"类型: {metadata.get('genre', '未知')}\n")
                f.write(f"创建时间: {metadata.get('created_at', '未知')}\n")
                f.write("\n" + "-" * 50 + "\n\n")

            # Chapters
            for chapter in chapters:
                chapter_index = chapter.get("chapter_index", 0)
                chapter_title = chapter.get("title", f"第{chapter_index}章")
                content = chapter.get("content", "")

                f.write(f"\n{chapter_title}\n")
                f.write("\n")
                f.write(content)
                f.write("\n\n")

        logger.info(f"Saved full novel to {file_path}")
        return file_path

    async def export_to_json(
        self,
        session_id: str,
        title: str,
        data: Dict[str, Any],
    ) -> Path:
        """
        Export session data as JSON

        Args:
            session_id: The session ID
            title: Novel title
            data: Session data to export

        Returns:
            Path to exported file
        """
        session_path = self._get_session_path(session_id)
        file_path = session_path / f"{title}.json"

        export_data = {
            "title": title,
            "exported_at": datetime.utcnow().isoformat(),
            **data,
        }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)

        logger.info(f"Exported to JSON: {file_path}")
        return file_path

    async def export_to_markdown(
        self,
        session_id: str,
        title: str,
        chapters: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """
        Export novel as Markdown

        Args:
            session_id: The session ID
            title: Novel title
            chapters: List of chapter data
            metadata: Optional metadata

        Returns:
            Path to exported file
        """
        session_path = self._get_session_path(session_id)
        file_path = session_path / f"{title}.md"

        with open(file_path, "w", encoding="utf-8") as f:
            # Title
            f.write(f"# {title}\n\n")

            if metadata:
                f.write("## 元信息\n\n")
                if metadata.get("author"):
                    f.write(f"- **作者**: {metadata['author']}\n")
                if metadata.get("genre"):
                    f.write(f"- **类型**: {metadata['genre']}\n")
                if metadata.get("description"):
                    f.write(f"- **简介**: {metadata['description']}\n")
                f.write("\n---\n\n")

            # Chapters
            for chapter in chapters:
                chapter_index = chapter.get("chapter_index", 0)
                chapter_title = chapter.get("title", f"第{chapter_index}章")
                content = chapter.get("content", "")

                f.write(f"\n## {chapter_title}\n\n")
                f.write(content)
                f.write("\n\n")

        logger.info(f"Exported to Markdown: {file_path}")
        return file_path

    async def export_full_creative_process(
        self,
        session_id: str,
        title: str,
        tasks: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """
        导出完整的创作过程，包含所有任务的输出
        
        格式：
        - 创意脑暴
        - 故事核心
        - 人物设计
        - 世界观规则
        - 主题确认
        - 风格元素
        - 市场定位
        - 事件设定
        - 场景物品冲突
        - 伏笔列表
        - 故事大纲
        - 章节大纲 + 章节内容 (每章)
        
        Args:
            session_id: 会话ID
            title: 小说标题
            tasks: 所有任务结果列表
            metadata: 元数据
            
        Returns:
            导出文件路径
        """
        session_path = self._get_session_path(session_id)
        timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S")
        file_path = session_path / f"{title}_完整创作_{timestamp}.md"
        
        # 定义任务类型的顺序和标题
        task_order = [
            ("创意脑暴", "# 🎯 创意脑暴"),
            ("故事核心", "# 📖 故事核心"),
            ("人物设计", "# 👥 人物设计"),
            ("世界观规则", "# 🌍 世界观规则"),
            ("主题确认", "# 🎭 主题确认"),
            ("风格元素", "# ✨ 风格元素"),
            ("市场定位", "# 📊 市场定位"),
            ("事件", "# ⚡ 事件设定"),
            ("场景物品冲突", "# 🎬 场景物品冲突"),
            ("伏笔列表", "# 🔮 伏笔列表"),
            ("大纲", "# 📋 故事大纲"),
            ("一致性检查", "# ✅ 一致性检查"),
        ]
        
        # 按任务类型整理结果
        task_results = {}
        chapter_outlines = {}  # 章节大纲
        chapter_contents = {}  # 章节内容
        
        for task in tasks:
            task_type = task.get("task_type", "")
            result = task.get("result", "")
            chapter_index = task.get("chapter_index")
            
            if task_type == "章节大纲" and chapter_index is not None:
                chapter_outlines[chapter_index] = result
            elif task_type in ("章节内容", "章节润色") and chapter_index is not None:
                # 如果已有内容且是润色后的，用润色后的替换
                if task_type == "章节润色" or chapter_index not in chapter_contents:
                    chapter_contents[chapter_index] = result
            elif task_type not in ("章节大纲", "章节内容", "章节润色", "场景生成"):
                if task_type not in task_results:
                    task_results[task_type] = result
        
        with open(file_path, "w", encoding="utf-8") as f:
            # 标题页
            f.write(f"# 📚 {title}\n\n")
            f.write(f"**导出时间**: {datetime.now().strftime('%Y年%m月%d日 %H:%M:%S')}\n\n")
            
            if metadata:
                f.write("## 📝 基本信息\n\n")
                if metadata.get("genre"):
                    f.write(f"- **类型**: {metadata['genre']}\n")
                if metadata.get("theme"):
                    f.write(f"- **主题**: {metadata['theme']}\n")
                if metadata.get("style"):
                    f.write(f"- **风格**: {metadata['style']}\n")
                if metadata.get("length"):
                    f.write(f"- **目标字数**: {metadata['length']}\n")
                f.write("\n---\n\n")
            
            # 按顺序输出准备阶段的任务结果
            f.write("# 第一部分：创作准备\n\n")
            f.write("> 以下是小说创作的准备工作，包含创意脑暴、人物设计、世界观构建等内容。\n\n")
            
            for task_type, section_title in task_order:
                if task_type in task_results and task_results[task_type]:
                    f.write(f"{section_title}\n\n")
                    f.write(task_results[task_type])
                    f.write("\n\n---\n\n")
            
            # 输出章节内容
            if chapter_contents:
                f.write("# 第二部分：正文内容\n\n")
                f.write("> 以下是小说的正文章节。\n\n")
                
                # 按章节顺序排序
                sorted_chapters = sorted(chapter_contents.keys())
                
                for chapter_index in sorted_chapters:
                    # 章节大纲（可选）
                    if chapter_index in chapter_outlines:
                        f.write(f"## 第{chapter_index}章 大纲\n\n")
                        f.write("```\n")
                        f.write(chapter_outlines[chapter_index])
                        f.write("\n```\n\n")
                    
                    # 章节内容
                    f.write(f"## 第{chapter_index}章\n\n")
                    f.write(chapter_contents[chapter_index])
                    f.write("\n\n---\n\n")
            
            # 统计信息
            f.write("# 📊 统计信息\n\n")
            total_words = sum(len(content) for content in chapter_contents.values())
            f.write(f"- **总章节数**: {len(chapter_contents)}\n")
            f.write(f"- **正文总字数**: 约{total_words}字\n")
            f.write(f"- **任务总数**: {len(tasks)}\n")
        
        logger.info(f"Exported full creative process to: {file_path}")
        return file_path

    async def load_chapter(
        self,
        session_id: str,
        chapter_index: int,
    ) -> Optional[str]:
        """
        Load a chapter from file

        Args:
            session_id: The session ID
            chapter_index: Chapter index

        Returns:
            Chapter content or None
        """
        session_path = self._get_session_path(session_id)
        chapter_dir = session_path / "chapters"

        # Try to find the chapter file
        for pattern in [f"{chapter_index:03d}.txt", f"{chapter_index:03d}_*.txt"]:
            matches = list(chapter_dir.glob(pattern))
            if matches:
                with open(matches[0], "r", encoding="utf-8") as f:
                    return f.read()

        return None

    async def list_sessions(self) -> List[str]:
        """
        List all session directories

        Returns:
            List of session IDs
        """
        return [d.name for d in self.base_path.iterdir() if d.is_dir()]

    async def delete_session_files(self, session_id: str) -> bool:
        """
        Delete all files for a session

        Args:
            session_id: The session ID

        Returns:
            True if successful
        """
        session_path = self._get_session_path(session_id)

        try:
            # Remove all contents
            for item in session_path.iterdir():
                if item.is_file():
                    item.unlink()
                elif item.is_dir():
                    for sub_item in item.iterdir():
                        sub_item.unlink()
                    item.rmdir()

            # Remove directory
            session_path.rmdir()

            logger.info(f"Deleted files for session {session_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to delete session files: {e}")
            return False

    async def get_session_size(self, session_id: str) -> int:
        """
        Get total size of session files in bytes

        Args:
            session_id: The session ID

        Returns:
            Size in bytes
        """
        session_path = self._get_session_path(session_id)

        if not session_path.exists():
            return 0

        total_size = 0
        for item in session_path.rglob("*"):
            if item.is_file():
                total_size += item.stat().st_size

        return total_size

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.94 at 0x1050030e0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  [Previous line repeated 1 more time]
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-32.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-32.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Prompt Manager - Manages prompt templates and style injection

Provides centralized prompt management with template system.
"""

import json
from pathlib import Path
from typing import Any, Dict, List, Optional

from jinja2 import Environment, FileSystemLoader, Template
from loguru import logger

from creative_autogpt.utils.config import get_settings


class PromptManager:
    """
    Manages prompt templates and style injection

    Responsibilities:
    - Load and render prompt templates
    - Inject style configurations
    - Manage prompt versions
    - Cache rendered prompts
    """

    def __init__(
        self,
        templates_dir: Optional[str] = None,
        styles_dir: Optional[str] = None,
    ):
        """
        Initialize prompt manager

        Args:
            templates_dir: Directory for template files
            styles_dir: Directory for style configuration files
        """
        settings = get_settings()

        # Set default directories
        if templates_dir is None:
            # Check if prompts directory exists in project root
            project_root = Path.cwd()
            templates_path = project_root / "prompts" / "tasks"
            if templates_path.exists():
                templates_dir = str(templates_path)
            else:
                templates_dir = str(Path(__file__).parent.parent / "prompts" / "tasks")

        if styles_dir is None:
            project_root = Path.cwd()
            styles_path = project_root / "prompts" / "styles"
            if styles_path.exists():
                styles_dir = str(styles_path)
            else:
                styles_dir = str(Path(__file__).parent.parent / "prompts" / "styles")

        self.templates_dir = Path(templates_dir)
        self.styles_dir = Path(styles_dir)

        # Create Jinja2 environment
        self.env = Environment(
            loader=FileSystemLoader(str(self.templates_dir)),
            autoescape=False,
            trim_blocks=True,
            lstrip_blocks=True,
        )

        # Cache for templates and styles
        self._template_cache: Dict[str, Template] = {}
        self._style_cache: Dict[str, Dict[str, Any]] = {}

        logger.info(
            f"PromptManager initialized (templates: {self.templates_dir}, "
            f"styles: {self.styles_dir})"
        )

    def get_template(self, name: str) -> Template:
        """
        Get a Jinja2 template by name

        Args:
            name: Template name (without extension)

        Returns:
            Jinja2 Template object
        """
        if name not in self._template_cache:
            try:
                template_path = f"{name}.jinja2"
                self._template_cache[name] = self.env.get_template(template_path)
                logger.debug(f"Loaded template: {name}")
            except Exception as e:
                logger.warning(f"Template '{name}' not found: {e}")
                # Return a simple template
                self._template_cache[name] = Template("{{ content }}")

        return self._template_cache[name]

    def render_template(
        self,
        name: str,
        context: Dict[str, Any],
    ) -> str:
        """
        Render a template with context

        Args:
            name: Template name
            context: Template variables

        Returns:
            Rendered prompt
        """
        template = self.get_template(name)
        return template.render(**context)

    def load_style(self, name: str) -> Dict[str, Any]:
        """
        Load a style configuration

        Args:
            name: Style name (e.g., "xuanhuan", "wuxia")

        Returns:
            Style configuration dict
        """
        if name not in self._style_cache:
            style_path = self.styles_dir / f"{name}.yaml"

            if not style_path.exists():
                logger.warning(f"Style '{name}' not found at {style_path}")
                self._style_cache[name] = self._get_default_style()
                return self._style_cache[name]

            try:
                import yaml

                with open(style_path, "r", encoding="utf-8") as f:
                    self._style_cache[name] = yaml.safe_load(f)

                logger.debug(f"Loaded style: {name}")

            except Exception as e:
                logger.error(f"Failed to load style '{name}': {e}")
                self._style_cache[name] = self._get_default_style()

        return self._style_cache[name]

    def _get_default_style(self) -> Dict[str, Any]:
        """Get default style configuration"""
        return {
            "narrative_style": "第三人称全知视角",
            "language_style": "通俗流畅，生动形象",
            "pacing": "张弛有度",
            "tone": "积极向上",
            "key_elements": [],
            "avoid_elements": [],
        }

    def inject_style(
        self,
        prompt: str,
        style_name: str,
    ) -> str:
        """
        Inject style configuration into a prompt

        Args:
            prompt: Base prompt
            style_name: Style to inject

        Returns:
            Prompt with style information
        """
        style = self.load_style(style_name)

        style_section = "\n\n## 风格要求\n\n"

        if style.get("narrative_style"):
            style_section += f"- 叙事风格: {style['narrative_style']}\n"

        if style.get("language_style"):
            style_section += f"- 语言风格: {style['language_style']}\n"

        if style.get("pacing"):
            style_section += f"- 节奏: {style['pacing']}\n"

        if style.get("tone"):
            style_section += f"- 基调: {style['tone']}\n"

        if style.get("key_elements"):
            style_section += f"- 核心元素: {', '.join(style['key_elements'])}\n"

        if style.get("avoid_elements"):
            style_section += f"- 避免元素: {', '.join(style['avoid_elements'])}\n"

        return prompt + style_section

    def get_available_styles(self) -> List[str]:
        """Get list of available style names"""
        if not self.styles_dir.exists():
            return []

        return [
            f.stem for f in self.styles_dir.glob("*.yaml")
            if f.is_file()
        ]

    def get_available_templates(self) -> List[str]:
        """Get list of available template names"""
        if not self.templates_dir.exists():
            return []

        return [
            f.stem for f in self.templates_dir.glob("*.jinja2")
            if f.is_file()
        ]


class PromptEnhancer:
    """
    Intelligently enhances user input into detailed configuration

    Uses LLM to expand simple user input into comprehensive novel settings.
    """

    def __init__(self, llm_client=None):
        """
        Initialize prompt enhancer

        Args:
            llm_client: LLM client for enhancement
        """
        self.llm_client = llm_client
        logger.info("PromptEnhancer initialized")

    async def enhance(
        self,
        user_input: str,
        current_config: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Enhance user input into detailed configuration

        Args:
            user_input: User's simple input (e.g., "写个玄幻小说")
            current_config: Current configuration to update

        Returns:
            Enhanced configuration
        """
        if not self.llm_client:
            # Return basic enhancement without LLM
            return self._basic_enhancement(user_input, current_config)

        prompt = self._build_enhancement_prompt(user_input, current_config)

        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                task_type="大纲",  # Use Qwen for comprehensive planning
                temperature=0.7,
                max_tokens=2000,
            )

            return self._parse_enhancement_response(response.content)

        except Exception as e:
            logger.error(f"Enhancement failed: {e}")
            return self._basic_enhancement(user_input, current_config)

    def _build_enhancement_prompt(
        self,
        user_input: str,
        current_config: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Build prompt for enhancement"""
        current_section = ""
        if current_config:
            current_section = f"\n### 当前配置\n```json\n{json.dumps(current_config, ensure_ascii=False, indent=2)}\n```\n"

        return f"""## 任务: 智能提示词增强

请将用户的简单输入扩展为详细的小说创作配置。

### 用户输入
{user_input}
{current_section}
### 输出要求

请以JSON格式输出扩展后的配置:

```json
{{
  "title": "小说标题",
  "genre": "类型（玄幻/武侠/都市/科幻/悬疑）",
  "theme": "核心主题",
  "style": "风格元素",
  "target_length": "目标字数（如：100万字）",
  "target_audience": "目标读者",
  "main_plot": "主线剧情概述",
  "key_elements": ["核心元素1", "核心元素2"],
  "avoid_elements": ["避免元素1"],
  "suggestions": ["创作建议1", "创作建议2"]
}}
```

请确保:
1. 标题吸引人
2. 类型准确
3. 主题鲜明
4. 情节完整
5. 元素符合类型特点

直接输出JSON，不需要其他说明。
"""

    def _parse_enhancement_response(self, response: str) -> Dict[str, Any]:
        """Parse LLM enhancement response"""
        try:
            # Extract JSON
            json_start = response.find("{")
            json_end = response.rfind("}") + 1

            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                config = json.loads(json_str)
                return config

        except Exception as e:
            logger.error(f"Failed to parse enhancement response: {e}")

        # Fallback to basic enhancement
        return self._basic_enhancement(response)

    def _basic_enhancement(
        self,
        user_input: str,
        current_config: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Basic enhancement without LLM"""
        config = current_config or {}

        # Try to extract genre from input
        genre_keywords = {
            "玄幻": "玄幻",
            "武侠": "武侠",
            "都市": "都市",
            "科幻": "科幻",
            "悬疑": "悬疑",
        }

        genre = "玄幻"  # Default
        for keyword, value in genre_keywords.items():
            if keyword in user_input:
                genre = value
                break

        config.update({
            "title": config.get("title") or f"{genre}小说",
            "genre": genre,
            "theme": config.get("theme") or user_input[:100],
            "style": config.get("style") or "标准网文风格",
            "target_length": config.get("target_length") or "100万字",
        })

        return config


class FeedbackTransformer:
    """
    Transforms user feedback into professional prompt modifications

    Converts casual user feedback into structured prompt improvements.
    """

    def __init__(self, llm_client=None):
        """
        Initialize feedback transformer

        Args:
            llm_client: LLM client for transformation
        """
        self.llm_client = llm_client
        logger.info("FeedbackTransformer initialized")

    async def transform(
        self,
        feedback: str,
        task_type: str,
        current_content: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Transform user feedback into prompt modification

        Args:
            feedback: User's feedback
            task_type: Type of task
            current_content: Current content being modified
            context: Additional context

        Returns:
            Transformed prompt instruction
        """
        if not self.llm_client:
            return self._basic_transformation(feedback, current_content)

        prompt = self._build_transformation_prompt(
            feedback,
            task_type,
            current_content,
            context,
        )

        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                task_type="修订",
                temperature=0.7,
                max_tokens=1000,
            )

            return response.content

        except Exception as e:
            logger.error(f"Feedback transformation failed: {e}")
            return self._basic_transformation(feedback, current_content)

    def _build_transformation_prompt(
        self,
        feedback: str,
        task_type: str,
        current_content: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """Build prompt for feedback transformation"""
        context_section = ""
        if context:
            context_section = f"\n### 上下文\n```json\n{json.dumps(context, ensure_ascii=False, indent=2)}\n```\n"

        return f"""## 任务: 反馈意见转换

请将用户的反馈意见转换为专业的修改指令。

### 任务类型
{task_type}

### 用户反馈
{feedback}
{context_section}
### 当前内容（前500字）
```
{current_content[:500]}
```

### 输出要求

请输出具体的修改指令，指导如何改进内容：

1. **问题识别**: 明确指出问题所在
2. **修改方向**: 具体的改进方向
3. **实施建议**: 可操作的修改建议

请以清晰的结构输出修改指令。
"""

    def _basic_transformation(
        self,
        feedback: str,
        current_content: str,
    ) -> str:
        """Basic feedback transformation without LLM"""
        return f"""请根据以下反馈意见改进内容：

## 反馈意见
{feedback}

## 修改要求
1. 保持原有结构和核心情节
2. 针对反馈意见进行修改
3. 确保修改后的内容与整体风格一致

请直接输出修改后的内容。
"""

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.243 at 0x1054cfbc0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  [Previous line repeated 1 more time]
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-32.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-32.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Feedback Transformer - Transforms user feedback into prompt modifications

Converts casual user feedback into structured prompt improvements.
"""

from typing import Any, Dict, List, Optional

from loguru import logger


class FeedbackTransformer:
    """
    Transforms user feedback into professional prompt modifications

    Converts casual user feedback like "主角太软弱" into structured
    prompt modifications that guide LLM to make specific improvements.
    """

    # Common feedback patterns and their transformations
    FEEDBACK_PATTERNS = {
        # Character-related feedback
        "主角.*太.*弱": {
            "issue": "主角性格不够强势",
            "direction": "增强主角的主角气场和决断力",
            "suggestions": [
                "增加主角主动做决策的情节",
                "让主角在关键时刻展现霸气",
                "减少犹豫和依赖他人的描写",
                "增加主角的内心强大描写",
            ],
        },
        "主角.*太.*强": {
            "issue": "主角过于强大，缺乏成长空间",
            "direction": "适当增加主角的挫折和成长",
            "suggestions": [
                "设置主角能力无法解决的困境",
                "增加主角内心的矛盾和挣扎",
                "让主角经历失败并从中学习",
                "平衡主角与配角的实力对比",
            ],
        },
        "人物.*不.*生动": {
            "issue": "人物形象单薄",
            "direction": "增加人物细节描写和个性特征",
            "suggestions": [
                "增加人物的外貌和动作细节",
                "通过对话展现人物性格",
                "增加人物的心理活动描写",
                "设置人物习惯性语言或动作",
            ],
        },

        # Plot-related feedback
        "情节.*太.*慢": {
            "issue": "故事节奏拖沓",
            "direction": "加快情节推进速度",
            "suggestions": [
                "减少冗长的环境描写",
                "增加冲突和转折",
                "快速推进主线剧情",
                "减少不必要的支线",
            ],
        },
        "情节.*太.*快": {
            "issue": "情节发展过快",
            "direction": "放慢节奏，增加铺垫",
            "suggestions": [
                "增加场景和对话描写",
                "深化人物关系发展",
                "增加情节铺垫和伏笔",
                "扩展关键情节的细节",
            ],
        },
        "逻辑.*问题": {
            "issue": "情节存在逻辑漏洞",
            "direction": "修复逻辑问题，确保合理性",
            "suggestions": [
                "检查因果关系是否合理",
                "确保人物行为符合其性格",
                "检查时间线是否连贯",
                "补充必要的过渡说明",
            ],
        },

        # Writing quality feedback
        "文笔.*差": {
            "issue": "文字表达需要改进",
            "direction": "提升文笔质量",
            "suggestions": [
                "使用更生动的词汇和比喻",
                "增加感官细节描写",
                "优化句式结构",
                "增强情感表达力度",
            ],
        },
        "对话.*不.*自然": {
            "issue": "人物对话不够自然",
            "direction": "使对话更符合人物身份和场景",
            "suggestions": [
                "根据人物性格设计对话风格",
                "增加口语化表达",
                "减少生硬的说教式对话",
                "通过对话展现情节而非说明",
            ],
        },
    }

    def __init__(self):
        """Initialize feedback transformer"""
        logger.info("FeedbackTransformer initialized")

    async def transform(
        self,
        feedback: str,
        task_type: str,
        current_content: str,
        context: Optional[Dict[str, Any]] = None,
        llm_client: Optional[Any] = None,
    ) -> str:
        """
        Transform user feedback into prompt modification

        Args:
            feedback: User's feedback (e.g., "主角太软弱了")
            task_type: Type of task being modified
            current_content: Current content being modified
            context: Additional context (genre, characters, etc.)
            llm_client: Optional LLM client for intelligent transformation

        Returns:
            Transformed prompt instruction
        """
        # Try pattern matching first
        pattern_result = self._match_patterns(feedback, context)
        if pattern_result:
            return self._format_instruction(pattern_result, current_content)

        # Use LLM for transformation if available
        if llm_client:
            return await self._llm_transform(
                feedback,
                task_type,
                current_content,
                context,
                llm_client,
            )

        # Fallback to basic transformation
        return self._basic_transformation(feedback, current_content)

    def _match_patterns(
        self,
        feedback: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> Optional[Dict[str, Any]]:
        """Try to match feedback against known patterns"""
        import re

        for pattern, result in self.FEEDBACK_PATTERNS.items():
            if re.search(pattern, feedback):
                return result

        return None

    def _format_instruction(
        self,
        pattern_result: Dict[str, Any],
        current_content: str,
    ) -> str:
        """Format pattern result into instruction"""
        instruction = f"""## 修改要求

### 问题识别
{pattern_result['issue']}

### 修改方向
{pattern_result['direction']}

### 具体建议
"""

        for i, suggestion in enumerate(pattern_result['suggestions'], 1):
            instruction += f"{i}. {suggestion}\n"

        instruction += """
### 实施要求
1. 保持原有结构和核心情节
2. 针对上述问题进行修改
3. 确保修改后与整体风格一致
4. 不要添加新的无关情节

请直接输出修改后的内容。
"""

        return instruction

    async def _llm_transform(
        self,
        feedback: str,
        task_type: str,
        current_content: str,
        context: Optional[Dict[str, Any]] = None,
        llm_client: Optional[Any] = None,
    ) -> str:
        """Use LLM to transform feedback"""
        import json

        context_section = ""
        if context:
            context_section = f"\n### 上下文信息\n```json\n{json.dumps(context, ensure_ascii=False, indent=2)}\n```\n"

        prompt = f"""## 任务: 反馈意见转换

请将用户的反馈意见转换为专业的修改指令。

### 任务类型
{task_type}

### 用户反馈
{feedback}
{context_section}
### 当前内容（前500字）
```
{current_content[:500]}
```

### 输出要求

请分析用户反馈并输出具体的修改指令，包含以下部分：

1. **问题识别**: 明确指出问题所在
2. **修改方向**: 具体的改进方向
3. **实施建议**: 3-5条可操作的修改建议
4. **注意事项**: 修改时需要注意的点

请以清晰的结构输出修改指令，不要输出修改后的内容。
"""

        try:
            response = await llm_client.generate(
                prompt=prompt,
                task_type="修订",
                temperature=0.7,
                max_tokens=1500,
            )

            return response.content

        except Exception as e:
            logger.error(f"LLM feedback transformation failed: {e}")
            return self._basic_transformation(feedback, current_content)

    def _basic_transformation(
        self,
        feedback: str,
        current_content: str,
    ) -> str:
        """Basic feedback transformation without LLM"""
        return f"""## 修改要求

### 用户反馈
{feedback}

### 修改要求
1. 针对上述反馈意见进行修改
2. 保持原有的结构和核心情节
3. 确保修改后与整体风格一致
4. 只修改需要改进的部分

请直接输出修改后的内容。
"""

    def add_pattern(
        self,
        pattern: str,
        issue: str,
        direction: str,
        suggestions: List[str],
    ) -> None:
        """
        Add a new feedback pattern

        Args:
            pattern: Regex pattern to match feedback
            issue: Description of the issue
            direction: Modification direction
            suggestions: List of specific suggestions
        """
        self.FEEDBACK_PATTERNS[pattern] = {
            "issue": issue,
            "direction": direction,
            "suggestions": suggestions,
        }
        logger.info(f"Added feedback pattern: {pattern}")

    def get_patterns(self) -> Dict[str, Dict[str, Any]]:
        """Get all feedback patterns"""
        return self.FEEDBACK_PATTERNS.copy()

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.118 at 0x10555ecf0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  [Previous line repeated 1 more time]
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
API Schemas for Task management
"""

from datetime import datetime
from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field


class TaskResultResponse(BaseModel):
    """Schema for task result response"""

    id: str
    task_id: str
    task_type: str
    status: str
    result: Optional[str] = None
    error: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)
    evaluation: Optional[Dict[str, Any]] = None
    created_at: datetime
    chapter_index: Optional[int] = None

    class Config:
        from_attributes = True


class TaskPreviewRequest(BaseModel):
    """Schema for task preview request"""

    task_id: str
    feedback: Optional[str] = Field(None, description="User feedback for modification")


class TaskPreviewResponse(BaseModel):
    """Schema for task preview response"""

    task_id: str
    task_type: str
    description: str
    preview: str
    metadata: Dict[str, Any] = Field(default_factory=dict)
    can_modify: bool = True
    estimated_time: Optional[int] = None  # in seconds


class ChatMessage(BaseModel):
    """Schema for chat message"""

    role: str = Field(..., description="Message role (user/assistant)")
    content: str = Field(..., description="Message content")
    timestamp: datetime = Field(default_factory=datetime.utcnow)


class ChatFeedbackRequest(BaseModel):
    """Schema for chat feedback request"""

    session_id: str
    task_id: Optional[str] = None
    message: str = Field(..., description="User feedback message")
    scope: Optional[str] = Field(None, description="Feedback scope (current_task, chapter, all)")

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.20 at 0x1057d21b0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
API Schemas for Session management
"""

from datetime import datetime
from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field
from enum import Enum


class SessionStatus(str, Enum):
    """Status of a writing session"""

    CREATED = "created"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


class SessionCreate(BaseModel):
    """Schema for creating a new session"""

    title: str = Field(..., description="Session title", min_length=1, max_length=200)
    mode: str = Field(default="novel", description="Writing mode")
    goal: Dict[str, Any] = Field(default_factory=dict, description="Creation goal")
    config: Dict[str, Any] = Field(default_factory=dict, description="Session configuration")


class SessionUpdate(BaseModel):
    """Schema for updating a session"""

    title: Optional[str] = Field(None, min_length=1, max_length=200)
    status: Optional[SessionStatus] = None
    goal: Optional[Dict[str, Any]] = None
    config: Optional[Dict[str, Any]] = None


class SessionResponse(BaseModel):
    """Schema for session response"""

    id: str
    title: str
    mode: str
    status: SessionStatus
    goal: Dict[str, Any]
    config: Dict[str, Any]
    created_at: datetime
    updated_at: datetime
    completed_at: Optional[datetime] = None
    total_tasks: int = 0
    completed_tasks: int = 0
    failed_tasks: int = 0
    llm_calls: int = 0
    tokens_used: int = 0

    class Config:
        from_attributes = True


class SessionListResponse(BaseModel):
    """Schema for session list response"""

    sessions: List[SessionResponse]
    total: int
    page: int
    page_size: int


class SessionProgress(BaseModel):
    """Schema for session progress"""

    session_id: str
    status: SessionStatus
    total_tasks: int
    completed_tasks: int
    failed_tasks: int
    percentage: float
    current_task: Optional[str] = None
    estimated_remaining: Optional[int] = None  # in seconds


class SessionExportRequest(BaseModel):
    """Schema for export request"""

    format: str = Field(default="txt", description="Export format (txt, json, md)")
    include_metadata: bool = Field(default=True, description="Include metadata")
    chapter_range: Optional[tuple[int, int]] = Field(None, description="Chapter range (start, end)")

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.36 at 0x1057ecf80>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
API Response schemas
"""

from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field


class ErrorResponse(BaseModel):
    """Schema for error response"""

    error: str = Field(..., description="Error message")
    detail: Optional[str] = Field(None, description="Detailed error information")
    code: Optional[str] = Field(None, description="Error code")


class SuccessResponse(BaseModel):
    """Schema for success response"""

    success: bool = True
    message: Optional[str] = None
    data: Optional[Any] = None


class HealthResponse(BaseModel):
    """Schema for health check response"""

    status: str = "healthy"
    version: str
    llm_providers: List[str] = Field(default_factory=list)
    storage_status: str = "ok"
    memory_status: str = "ok"


class StreamChunk(BaseModel):
    """Schema for streaming content chunk"""

    content: str
    done: bool = False
    metadata: Optional[Dict[str, Any]] = None

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-33.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
Prompts API routes

Provides endpoints for smart prompt enhancement and feedback transformation.
"""

from typing import Any, Dict, Optional

from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel, Field
from loguru import logger

from creative_autogpt.api.dependencies import (
    get_llm_client,
    get_prompt_manager,
)
from creative_autogpt.utils.llm_client import MultiLLMClient
from creative_autogpt.prompts.manager import PromptEnhancer, FeedbackTransformer, PromptManager


router = APIRouter(prefix="/prompts", tags=["prompts"])


class SmartEnhanceRequest(BaseModel):
    """Request schema for smart enhancement"""

    input: str = Field(..., description="User input text to enhance")
    current_config: Optional[Dict[str, Any]] = Field(None, description="Existing config to merge/update")


class SmartEnhanceResponse(BaseModel):
    """Response schema for smart enhancement"""

    config: Dict[str, Any]


class FeedbackTransformRequest(BaseModel):
    """Request schema for feedback transformation"""

    feedback: str = Field(..., description="User feedback text")
    task_type: str = Field(..., description="Task type context for transformation")
    current_content: str = Field(..., description="Current content to be modified")
    context: Optional[Dict[str, Any]] = Field(None, description="Additional context info")


class FeedbackTransformResponse(BaseModel):
    """Response schema for feedback transformation"""

    instruction: str


@router.post("/smart-enhance", response_model=SmartEnhanceResponse)
async def smart_enhance(
    data: SmartEnhanceRequest,
    llm_client: MultiLLMClient = Depends(get_llm_client),
):
    """
    Enhance a simple user input into a detailed creative configuration.

    - input: Required user input text
    - current_config: Optional existing configuration to merge
    """
    try:
        enhancer = PromptEnhancer(llm_client=llm_client)
        enhanced = await enhancer.enhance(
            user_input=data.input,
            current_config=data.current_config,
        )
        return SmartEnhanceResponse(config=enhanced)
    except Exception as e:
        logger.error(f"Smart enhance failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )


@router.post("/feedback-transform", response_model=FeedbackTransformResponse)
async def feedback_transform(
    data: FeedbackTransformRequest,
    llm_client: MultiLLMClient = Depends(get_llm_client),
):
    """
    Transform casual user feedback into a professional modification instruction.
    """
    try:
        transformer = FeedbackTransformer(llm_client=llm_client)
        instruction = await transformer.transform(
            feedback=data.feedback,
            task_type=data.task_type,
            current_content=data.current_content,
            context=data.context,
        )
        return FeedbackTransformResponse(instruction=instruction)
    except Exception as e:
        logger.error(f"Feedback transform failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e),
        )


@router.get("/styles", response_model=list[str])
async def list_styles(
    manager: PromptManager = Depends(get_prompt_manager),
):
    """List available style configuration names"""
    return manager.get_available_styles()


@router.get("/templates", response_model=list[str])
async def list_templates(
    manager: PromptManager = Depends(get_prompt_manager),
):
    """List available prompt template names"""
    return manager.get_available_templates()

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 38, in _inference_tip_cached
    result = _cache[func, node]
             ~~~~~~^^^^^^^^^^^^
KeyError: (<function infer_typing_attr at 0x102713e20>, <Subscript l.28 at 0x1057b28a0>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1370, in safe_infer
    value = next(infer_gen)
            ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 161, in infer
    results = list(self._explicit_inference(self, context, **kwargs))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference_tip.py", line 45, in _inference_tip_cached
    result = _cache[func, node] = list(func(*args, **kwargs))
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/brain/brain_typing.py", line 161, in infer_typing_attr
    value = next(node.value.infer())  # type: ignore[union-attr] # value shouldn't be None for Subscript.
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 171, in infer
    yield from self._infer(context=context, **kwargs)
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/bases.py", line 176, in _infer_stmts
    for inf in stmt.infer(context=context):  # type: ignore[union-attr]
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/node_ng.py", line 184, in infer
    for i, result in enumerate(self._infer(context=context, **kwargs)):
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 142, in raise_if_nothing_inferred
    yield next(generator)
          ^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/decorators.py", line 111, in wrapped
    for res in _func(node, context, **kwargs):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/inference.py", line 334, in infer_import_from
    module = self.do_import_module()
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 94, in walk
    self.walk(child)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 91, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3168, in visit_subscript
    inferred_slice = utils.safe_infer(node.slice)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/utils.py", line 1374, in safe_infer
    raise AstroidError from e
astroid.exceptions.AstroidError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
Can't write the issue template for the crash in /Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-34.txt because of: '[Errno 2] No such file or directory: '/Users/fanhailiang/Library/Caches/pylint/pylint-crash-2026-01-25-17-58-34.txt''
Here's the content anyway:
First, please verify that the bug is not already filled:
https://github.com/PyCQA/pylint/issues/

Then create a new crash issue:
https://github.com/PyCQA/pylint/issues/new?assignees=&labels=crash%2Cneeds+triage&template=BUG-REPORT.yml


Issue title:
Crash ```` (if possible, be more specific about what made pylint crash)
Content:
When parsing the following file:

<!--
 If sharing the code is not an option, please state so,
 but providing only the stacktrace would still be helpful.
 -->

```python
"""
WebSocket API routes for real-time communication
"""

import json
import uuid
from datetime import datetime
from typing import Dict, Any, Optional, Set

from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, status
from loguru import logger

from creative_autogpt.api.dependencies import (
    get_session_storage,
    get_llm_client,
    get_memory_manager,
    get_evaluator,
)
from creative_autogpt.storage.session import SessionStorage
from creative_autogpt.utils.llm_client import MultiLLMClient
from creative_autogpt.core.vector_memory import VectorMemoryManager
from creative_autogpt.core.evaluator import EvaluationEngine
from creative_autogpt.core.loop_engine import LoopEngine, ExecutionStatus

router = APIRouter(prefix="/ws", tags=["websocket"])


class ConnectionManager:
    """Manages WebSocket connections"""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.session_subscribers: Dict[str, Set[str]] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        """Connect a new client"""
        await websocket.accept()
        self.active_connections[client_id] = websocket
        logger.info(f"WebSocket client {client_id} connected")

    def disconnect(self, client_id: str):
        """Disconnect a client"""
        if client_id in self.active_connections:
            del self.active_connections[client_id]

        # Remove from all session subscriptions
        for session_id, subscribers in self.session_subscribers.items():
            subscribers.discard(client_id)

        logger.info(f"WebSocket client {client_id} disconnected")

    async def send_personal(self, message: dict, client_id: str):
        """Send message to a specific client"""
        if client_id in self.active_connections:
            websocket = self.active_connections[client_id]
            try:
                await websocket.send_json(message)
            except Exception as e:
                logger.error(f"Failed to send to client {client_id}: {e}")
                self.disconnect(client_id)

    async def broadcast_to_session(self, message: dict, session_id: str):
        """Broadcast message to all subscribers of a session"""
        if session_id not in self.session_subscribers:
            return

        for client_id in self.session_subscribers[session_id].copy():
            await self.send_personal(message, client_id)

    def subscribe_to_session(self, client_id: str, session_id: str):
        """Subscribe a client to session updates"""
        if session_id not in self.session_subscribers:
            self.session_subscribers[session_id] = set()

        self.session_subscribers[session_id].add(client_id)
        logger.info(f"Client {client_id} subscribed to session {session_id}")

    def unsubscribe_from_session(self, client_id: str, session_id: str):
        """Unsubscribe a client from session updates"""
        if session_id in self.session_subscribers:
            self.session_subscribers[session_id].discard(client_id)


manager = ConnectionManager()

# Store running engines
running_engines: Dict[str, LoopEngine] = {}


@router.websocket("/ws")
async def websocket_endpoint(
    websocket: WebSocket,
    storage: SessionStorage = Depends(get_session_storage),
):
    """
    Main WebSocket endpoint for real-time communication

    Events:
    - connect: Initial connection
    - subscribe: Subscribe to session updates
    - unsubscribe: Unsubscribe from session
    - start: Start session execution
    - pause: Pause session execution
    - resume: Resume session execution
    - stop: Stop session execution
    - feedback: Submit user feedback
    - preview: Request task preview
    """
    client_id = str(uuid.uuid4())

    await manager.connect(websocket, client_id)

    try:
        while True:
            # Receive message
            data = await websocket.receive_json()
            event_type = data.get("event")

            logger.debug(f"WebSocket event from {client_id}: {event_type}")

            # Handle different event types
            if event_type == "subscribe":
                await handle_subscribe(client_id, data, storage)

            elif event_type == "unsubscribe":
                await handle_unsubscribe(client_id, data)

            elif event_type == "start":
                await handle_start(client_id, data, storage)

            elif event_type == "pause":
                await handle_pause(client_id, data)

            elif event_type == "resume":
                await handle_resume(client_id, data)

            elif event_type == "stop":
                await handle_stop(client_id, data)

            elif event_type == "approve_task":
                await handle_approve_task(client_id, data)

            elif event_type == "feedback":
                await handle_feedback(client_id, data)

            elif event_type == "preview":
                await handle_preview(client_id, data, storage)

            elif event_type == "ping":
                # Respond to heartbeat ping
                await manager.send_personal(
                    {"event": "pong"},
                    client_id,
                )

            elif event_type == "connect":
                # Acknowledge connection
                await manager.send_personal(
                    {"event": "connected", "client_id": client_id},
                    client_id,
                )

            else:
                await manager.send_personal(
                    {
                        "event": "error",
                        "message": f"Unknown event type: {event_type}",
                    },
                    client_id,
                )

    except WebSocketDisconnect:
        manager.disconnect(client_id)
    except Exception as e:
        logger.error(f"WebSocket error for client {client_id}: {e}")
        await manager.send_personal(
            {
                "event": "error",
                "message": str(e),
            },
            client_id,
        )


async def handle_subscribe(
    client_id: str,
    data: dict,
    storage: SessionStorage,
):
    """Handle subscribe event"""
    session_id = data.get("session_id")
    logger.info(f"🔔 Subscribe request from {client_id[:8]} for session {session_id[:8] if session_id else 'None'}")
    
    if not session_id:
        logger.warning(f"❌ Subscribe failed: no session_id")
        await manager.send_personal(
            {"event": "error", "message": "session_id required"},
            client_id,
        )
        return

    # Verify session exists
    session = await storage.get_session(session_id)
    if not session:
        logger.warning(f"❌ Subscribe failed: session {session_id[:8]} not found")
        await manager.send_personal(
            {"event": "error", "message": f"Session {session_id} not found"},
            client_id,
        )
        return

    logger.info(f"✅ Subscribed to session {session_id[:8]}")
    manager.subscribe_to_session(client_id, session_id)

    # Get current progress if session is running
    progress = None
    if session_id in running_engines:
        engine = running_engines[session_id]
        progress = engine.planner.get_progress()
        # Add session_id and status to progress
        progress["session_id"] = session_id
        progress["status"] = session.get("status", "created")

    # Send current session state
    await manager.send_personal(
        {
            "event": "subscribed",
            "session_id": session_id,
            "session": session,
            "progress": progress,  # Include current progress
        },
        client_id,
    )


async def handle_unsubscribe(client_id: str, data: dict):
    """Handle unsubscribe event"""
    session_id = data.get("session_id")
    if session_id:
        manager.unsubscribe_from_session(client_id, session_id)

    await manager.send_personal(
        {"event": "unsubscribed", "session_id": session_id},
        client_id,
    )


async def handle_start(
    client_id: str,
    data: dict,
    storage: SessionStorage,
):
    """Handle start execution event"""
    session_id = data.get("session_id")
    logger.info(f"🚀 Start request from {client_id[:8]} for session {session_id[:8] if session_id else 'None'}")
    
    if not session_id:
        logger.warning(f"❌ Start failed: no session_id")
        await manager.send_personal(
            {"event": "error", "message": "session_id required"},
            client_id,
        )
        return

    # Verify session exists
    session = await storage.get_session(session_id)
    if not session:
        logger.warning(f"❌ Start failed: session {session_id[:8]} not found")
        await manager.send_personal(
            {"event": "error", "message": f"Session {session_id} not found"},
            client_id,
        )
        return

    # Check session status
    session_status = session.get("status", "created")
    logger.info(f"📊 Session {session_id[:8]} status: {session_status}")
    
    # If session is completed/failed, don't restart
    if session_status in ["completed", "failed"]:
        logger.info(f"ℹ️ Session {session_id[:8]} already {session_status}, not restarting")
        await manager.send_personal(
            {"event": "info", "message": f"Session already {session_status}"},
            client_id,
        )
        return

    # Check if already running in memory
    if session_id in running_engines:
        logger.info(f"ℹ️ Start ignored: session {session_id[:8]} already running (likely duplicate from React.StrictMode)")
        # Silently ignore duplicate start requests - don't send error to avoid user-facing warnings
        return
    
    # If session status is 'running' but not in running_engines (server restart case),
    # reset it to 'created' so we can restart from the beginning
    if session_status == "running":
        logger.warning(f"⚠️ Session {session_id[:8]} was running but engine not found (server restart?). Resetting to created.")
        from creative_autogpt.storage.session import SessionStatus
        await storage.update_session_status(session_id, SessionStatus.CREATED)
        session = await storage.get_session(session_id)

    try:
        logger.info(f"🔧 Creating engine for session {session_id[:8]}")
        
        # Create loop engine
        from creative_autogpt.modes.novel import NovelMode

        mode = NovelMode(config=session.get("config"))

        # Initialize components
        llm_client = MultiLLMClient()
        from creative_autogpt.storage.vector_store import VectorStore
        vector_store = VectorStore()
        memory = VectorMemoryManager(vector_store=vector_store)
        evaluator = EvaluationEngine(llm_client=llm_client)

        engine = LoopEngine(
            session_id=session_id,
            llm_client=llm_client,
            memory=memory,
            evaluator=evaluator,
            config=session.get("config", {}),
        )

        # Set callbacks for real-time updates
        def on_task_start(task):
            """Send task start notification"""
            provider = task.metadata.get("llm_provider", "unknown")
            model = task.metadata.get("llm_model", "unknown")
            logger.info(f"📋 Task started: {task.task_type.value} (using {provider})")
            import asyncio
            asyncio.create_task(
                manager.broadcast_to_session(
                    {
                        "event": "task_start",
                        "session_id": session_id,
                        "task": {
                            "id": task.task_id,  # For frontend key prop
                            "task_id": task.task_id,
                            "task_type": task.task_type.value,
                            "description": task.description,
                            "status": "running",
                            "llm_provider": provider,
                            "llm_model": model,
                            "created_at": datetime.utcnow().isoformat(),
                        },
                    },
                    session_id,
                )
            )

        def on_task_complete(task, result, evaluation):
            """Send task complete notification and save to database"""
            logger.info(f"✅ Task completed: {task.task_type.value}")
            import asyncio
            
            # Save to database for persistence
            async def save_and_broadcast():
                try:
                    # Save task result to database
                    await storage.save_task_result(
                        session_id=session_id,
                        task_id=task.task_id,
                        task_type=task.task_type.value,
                        status="completed",
                        result=result,
                        metadata={
                            "description": task.description,
                            "chapter_index": task.metadata.get("chapter_index"),
                            "started_at": task.started_at,
                            "completed_at": task.completed_at,
                            "execution_time_seconds": task.execution_time_seconds,
                            "total_tokens": task.total_tokens,
                            "prompt_tokens": task.prompt_tokens,
                            "completion_tokens": task.completion_tokens,
                            "cost_usd": round(task.cost_usd, 6) if task.cost_usd else 0,
                            "failed_attempts": task.failed_attempts,
                            "retry_count": task.metadata.get("final_retry_count", 0),
                            "llm_provider": task.metadata.get("llm_provider", "unknown"),
                            "llm_model": task.metadata.get("llm_model", "unknown"),
                        },
                        evaluation=evaluation.to_dict() if evaluation else None,
                    )
                    logger.debug(f"💾 Saved task result to database: {task.task_type.value}")
                except Exception as e:
                    logger.error(f"Failed to save task result: {e}")
                
                # Broadcast to clients
                await manager.broadcast_to_session(
                    {
                        "event": "task_complete",
                        "session_id": session_id,
                        "task": {
                            "id": task.task_id,  # For frontend key prop
                            "task_id": task.task_id,
                            "task_type": task.task_type.value,
                            "description": task.description,
                            "status": "completed",
                            "result": result,  # Send full result for proper display
                            "evaluation": evaluation.to_dict() if evaluation else None,
                            "created_at": datetime.utcnow().isoformat(),
                            # 🔥 添加任务统计信息
                            "started_at": task.started_at,
                            "completed_at": task.completed_at,
                            "execution_time_seconds": task.execution_time_seconds,
                            "total_tokens": task.total_tokens,
                            "prompt_tokens": task.prompt_tokens,
                            "completion_tokens": task.completion_tokens,
                            "cost_usd": round(task.cost_usd, 6) if task.cost_usd else 0,
                            "failed_attempts": task.failed_attempts,
                            "retry_count": task.metadata.get("final_retry_count", 0),
                        },
                    },
                    session_id,
                )
            
            asyncio.create_task(save_and_broadcast())

        def on_progress(progress):
            """Send progress update"""
            logger.info(f"📊 Progress: {progress.get('completed_tasks', 0)}/{progress.get('total_tasks', 0)}")
            # Add session_id and status to progress
            progress["session_id"] = session_id
            progress["status"] = "running"
            import asyncio
            asyncio.create_task(
                manager.broadcast_to_session(
                    {
                        "event": "progress",
                        "session_id": session_id,
                        "progress": progress,
                    },
                    session_id,
                )
            )

        def on_task_approval_needed(task, result, evaluation):
            """Send task approval request to frontend"""
            logger.info(f"⏸️  Task waiting approval: {task.task_type.value}")
            import asyncio
            asyncio.create_task(
                manager.broadcast_to_session(
                    {
                        "event": "task_approval_needed",
                        "session_id": session_id,
                        "task": {
                            "id": task.task_id,
                            "task_id": task.task_id,
                            "task_type": task.task_type.value,
                            "description": task.description,
                            "status": "pending_approval",
                            "result": result,  # Full result for preview
                            "evaluation": evaluation.to_dict() if evaluation else None,
                            "llm_provider": task.metadata.get("llm_provider", "unknown"),
                            "llm_model": task.metadata.get("llm_model", "unknown"),
                            "created_at": datetime.utcnow().isoformat(),
                        },
                    },
                    session_id,
                )
            )

        def on_task_fail(task, error):
            """Send task failure notification to frontend"""
            logger.error(f"❌ Task failed: {task.task_type.value} - {error}")
            import asyncio
            asyncio.create_task(
                manager.broadcast_to_session(
                    {
                        "event": "task_fail",
                        "session_id": session_id,
                        "task": {
                            "id": task.task_id,
                            "task_id": task.task_id,
                            "task_type": task.task_type.value,
                            "description": task.description,
                            "status": "failed",
                            "error": str(error),
                            "llm_provider": task.metadata.get("llm_provider", "unknown"),
                            "llm_model": task.metadata.get("llm_model", "unknown"),
                            "created_at": datetime.utcnow().isoformat(),
                        },
                    },
                    session_id,
                )
            )

        engine.set_callbacks(
            on_task_start=on_task_start,
            on_task_complete=on_task_complete,
            on_task_fail=on_task_fail,
            on_progress=on_progress,
            on_task_approval_needed=on_task_approval_needed,
        )

        # Store engine
        running_engines[session_id] = engine

        # Update session status
        from creative_autogpt.storage.session import SessionStatus
        await storage.update_session_status(session_id, SessionStatus.RUNNING)

        # Send start confirmation
        await manager.send_personal(
            {
                "event": "started",
                "session_id": session_id,
            },
            client_id,
        )

        # Run engine in background
        import asyncio

        async def run_engine():
            logger.info(f"🏃 run_engine started for session {session_id[:8]}")
            try:
                goal = session.get("goal", {})
                chapter_count = goal.get("chapter_count") or session.get("config", {}).get("chapter_count")
                logger.info(f"📚 Starting engine.run with goal: {goal.get('title', 'Untitled')}, chapters: {chapter_count}")
                
                result = await engine.run(
                    goal=goal,
                    chapter_count=chapter_count,
                )

                # Send completion event based on execution status
                event_type = "completed" if result.status == ExecutionStatus.COMPLETED else "failed"
                
                final_payload = {
                    "event": event_type,
                    "session_id": session_id,
                    "status": result.status.value if hasattr(result.status, 'value') else str(result.status),
                    "stats": result.stats.to_dict() if hasattr(result.stats, 'to_dict') else {},
                }

                # Broadcast to all subscribers
                await manager.broadcast_to_session(final_payload, session_id)

                # Also send directly to initiating client to ensure delivery
                await manager.send_personal(final_payload, client_id)

                # Update session status
                final_status = SessionStatus.COMPLETED if result.status == ExecutionStatus.COMPLETED else SessionStatus.FAILED
                await storage.update_session_status(session_id, final_status)

            except Exception as e:
                logger.error(f"❌ Error in run_engine for session {session_id}: {e}", exc_info=True)
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")
                # Still send failed event
                error_payload = {
                    "event": "failed",
                    "session_id": session_id,
                    "error": str(e),
                }
                await manager.broadcast_to_session(error_payload, session_id)
                await manager.send_personal(error_payload, client_id)
                await storage.update_session_status(session_id, SessionStatus.FAILED)
            
            finally:
                # Remove from running engines
                if session_id in running_engines:
                    del running_engines[session_id]

        asyncio.create_task(run_engine())

    except Exception as e:
        logger.error(f"Failed to start session {session_id}: {e}")
        await manager.send_personal(
            {
                "event": "error",
                "message": str(e),
            },
            client_id,
        )


async def handle_pause(client_id: str, data: dict):
    """Handle pause event"""
    session_id = data.get("session_id")
    if not session_id:
        return

    if session_id in running_engines:
        engine = running_engines[session_id]
        engine.pause()

        await manager.broadcast_to_session(
            {
                "event": "paused",
                "session_id": session_id,
            },
            session_id,
        )


async def handle_resume(client_id: str, data: dict):
    """Handle resume event"""
    session_id = data.get("session_id")
    if not session_id:
        return

    if session_id in running_engines:
        engine = running_engines[session_id]
        engine.resume()

        await manager.broadcast_to_session(
            {
                "event": "resumed",
                "session_id": session_id,
            },
            session_id,
        )


async def handle_stop(client_id: str, data: dict):
    """Handle stop event"""
    session_id = data.get("session_id")
    if not session_id:
        return

    if session_id in running_engines:
        engine = running_engines[session_id]
        engine.stop()

        await manager.broadcast_to_session(
            {
                "event": "stopped",
                "session_id": session_id,
            },
            session_id,
        )


async def handle_approve_task(client_id: str, data: dict):
    """Handle task approval event"""
    session_id = data.get("session_id")
    action = data.get("action", "approve")  # approve, reject, regenerate
    feedback = data.get("feedback")
    selected_idea = data.get("selected_idea")  # For brainstorm task: 1-4
    
    if not session_id:
        await manager.send_personal(
            {"event": "error", "message": "session_id required"},
            client_id,
        )
        return
    
    if session_id not in running_engines:
        await manager.send_personal(
            {"event": "error", "message": f"Session {session_id} not running"},
            client_id,
        )
        return
    
    engine = running_engines[session_id]
    engine.approve_task(action=action, feedback=feedback, selected_idea=selected_idea)
    
    logger.info(f"✅ Task approval from {client_id[:8]}: {action}" + 
                (f", selected idea: {selected_idea}" if selected_idea else ""))
    
    # Notify all subscribers
    await manager.broadcast_to_session(
        {
            "event": "task_approved",
            "session_id": session_id,
            "action": action,
            "selected_idea": selected_idea,
        },
        session_id,
    )


async def handle_feedback(client_id: str, data: dict):
    """Handle user feedback event"""
    session_id = data.get("session_id")
    message = data.get("message")
    task_id = data.get("task_id")
    scope = data.get("scope", "current_task")

    if not session_id or not message:
        return

    # Broadcast feedback to all subscribers
    await manager.broadcast_to_session(
        {
            "event": "feedback",
            "session_id": session_id,
            "feedback": {
                "task_id": task_id,
                "message": message,
                "scope": scope,
                "sender": client_id,
            },
        },
        session_id,
    )


async def handle_preview(
    client_id: str,
    data: dict,
    storage: SessionStorage,
):
    """Handle task preview request"""
    session_id = data.get("session_id")
    task_id = data.get("task_id")

    if not session_id or not task_id:
        await manager.send_personal(
            {"event": "error", "message": "session_id and task_id required"},
            client_id,
        )
        return

    # Get task result
    tasks = await storage.get_task_results(session_id)

    # Find the task
    task = None
    for t in tasks:
        if t["task_id"] == task_id:
            task = t
            break

    if not task:
        await manager.send_personal(
            {"event": "error", "message": f"Task {task_id} not found"},
            client_id,
        )
        return

    # Send preview
    await manager.send_personal(
        {
            "event": "preview",
            "session_id": session_id,
            "task_id": task_id,
            "preview": {
                "task_type": task["task_type"],
                "result": task.get("result", "")[:1000],  # Preview first 1000 chars
                "metadata": task.get("metadata", {}),
                "evaluation": task.get("evaluation"),
            },
        },
        client_id,
    )

```

pylint crashed with a ``AstroidError`` and with the following stacktrace:
```
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 798, in _lint_file
    check_astroid_module(module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1067, in check_astroid_module
    retval = self._check_astroid_module(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 1117, in _check_astroid_module
    walker.walk(node)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/utils/ast_walker.py", line 96, in walk
    callback(astroid)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 1328, in leave_module
    self._check_imports(not_consumed)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 3068, in _check_imports
    if _is_from_future_import(stmt, name):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/checkers/variables.py", line 143, in _is_from_future_import
    module = stmt.do_import_module(stmt.modname)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/_base_nodes.py", line 146, in do_import_module
    return mymodule.import_module(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/nodes/scoped_nodes/scoped_nodes.py", line 527, in import_module
    return AstroidManager().ast_from_module_name(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 232, in ast_from_module_name
    return self.ast_from_file(found_spec.location, modname, fallback=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/manager.py", line 124, in ast_from_file
    return AstroidBuilder(self).file_build(filepath, modname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 144, in file_build
    module, builder = self._data_build(data, modname, path)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/builder.py", line 204, in _data_build
    module = builder.visit_module(node, modname, node_file, package)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 254, in visit_module
    [self.visit(child, newnode) for child in node.body],
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/lib/python3.12/site-packages/astroid/rebuilder.py", line 603, in visit
    visit_method = getattr(self, visit_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'TreeRebuilder' object has no attribute 'visit_typealias'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 763, in _lint_files
    self._lint_file(fileitem, module, check_astroid_module)
  File "/opt/anaconda3/lib/python3.12/site-packages/pylint/lint/pylinter.py", line 800, in _lint_file
    raise astroid.AstroidError from e
astroid.exceptions.AstroidError
```
.
************* Module creative_autogpt.prompts.manager
src/creative_autogpt/prompts/manager.py:40:8: W0612: Unused variable 'settings' (unused-variable)
************* Module creative_autogpt.api.main
src/creative_autogpt/api/main.py:20:19: W0613: Unused argument 'app' (unused-argument)
src/creative_autogpt/api/main.py:26:4: W0612: Unused variable 'settings' (unused-variable)
src/creative_autogpt/api/main.py:98:39: W0613: Unused argument 'request' (unused-argument)
************* Module creative_autogpt.api.routes.sessions
src/creative_autogpt/api/routes/sessions.py:5:0: W0611: Unused import uuid (unused-import)
src/creative_autogpt/api/routes/sessions.py:21:0: W0611: Unused ErrorResponse imported from creative_autogpt.api.schemas.response (unused-import)
src/creative_autogpt/api/routes/sessions.py:23:0: W0611: Unused ExportFormat imported from creative_autogpt.storage.file_store (unused-import)
src/creative_autogpt/api/routes/sessions.py:25:0: W0611: Unused get_settings imported from creative_autogpt.utils.config (unused-import)
************* Module creative_autogpt.api.routes.websocket
src/creative_autogpt/api/routes/websocket.py:47:12: W0612: Unused variable 'session_id' (unused-variable)
src/creative_autogpt/api/routes/websocket.py:308:8: W0612: Unused variable 'mode' (unused-variable)
src/creative_autogpt/api/routes/websocket.py:579:23: W0613: Unused argument 'client_id' (unused-argument)
src/creative_autogpt/api/routes/websocket.py:598:24: W0613: Unused argument 'client_id' (unused-argument)
src/creative_autogpt/api/routes/websocket.py:617:22: W0613: Unused argument 'client_id' (unused-argument)
src/creative_autogpt/api/routes/websocket.py:5:0: W0611: Unused import json (unused-import)

-----------------------------------
Your code has been rated at 9.87/10

