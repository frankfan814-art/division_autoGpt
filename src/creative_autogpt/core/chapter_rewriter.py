"""
Chapter Rewriter - Single chapter rewrite service

è´Ÿè´£å•ç« é‡å†™çš„å®Œæ•´æµç¨‹ï¼š
1. åŠ è½½ç« èŠ‚ä¸Šä¸‹æ–‡ï¼ˆå‰é¢ç« èŠ‚ã€äººç‰©ã€ä¸–ç•Œè§‚ã€ä¼ç¬”ï¼‰
2. é‡æ–°ç”Ÿæˆç« èŠ‚å†…å®¹
3. è´¨é‡è¯„ä¼°
4. ä¿å­˜æ–°ç‰ˆæœ¬åˆ°ç‰ˆæœ¬å†å²
"""
from loguru import logger
from typing import Dict, Any, Optional

from creative_autogpt.storage.session import SessionStorage
from creative_autogpt.utils.llm_client import MultiLLMClient
from creative_autogpt.core.vector_memory import VectorMemoryManager, MemoryContext
from creative_autogpt.core.evaluator import EvaluationEngine


class ChapterRewriter:
    """
    å•ç« é‡å†™æœåŠ¡

    åŠŸèƒ½ï¼š
    1. åŠ è½½ç« èŠ‚ä¸Šä¸‹æ–‡ï¼ˆå‰é¢ç« èŠ‚ã€äººç‰©ã€ä¸–ç•Œè§‚ã€ä¼ç¬”ï¼‰
    2. é‡æ–°ç”Ÿæˆç« èŠ‚å†…å®¹
    3. è´¨é‡è¯„ä¼°
    4. ä¿å­˜æ–°ç‰ˆæœ¬åˆ°ç‰ˆæœ¬å†å²
    """

    def __init__(
        self,
        session_id: str,
        storage: SessionStorage,
        llm_client: MultiLLMClient,
        memory: VectorMemoryManager,
        evaluator: EvaluationEngine,
    ):
        """
        åˆå§‹åŒ–ç« èŠ‚é‡å†™å™¨

        Args:
            session_id: ä¼šè¯ID
            storage: ä¼šè¯å­˜å‚¨
            llm_client: å¤šLLMå®¢æˆ·ç«¯
            memory: å‘é‡è®°å¿†ç®¡ç†å™¨
            evaluator: è´¨é‡è¯„ä¼°å™¨
        """
        self.session_id = session_id
        self.storage = storage
        self.llm_client = llm_client
        self.memory = memory
        self.evaluator = evaluator

    async def rewrite_chapter(
        self,
        chapter_index: int,
        reason: Optional[str] = None,
        feedback: Optional[str] = None,
        max_retries: int = 3,
    ) -> Dict[str, Any]:
        """
        é‡å†™æŒ‡å®šç« èŠ‚

        Args:
            chapter_index: ç« èŠ‚ç´¢å¼•
            reason: é‡å†™åŸå› 
            feedback: ç”¨æˆ·åé¦ˆ
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆè´¨é‡ä¸é€šè¿‡æ—¶è‡ªåŠ¨é‡å†™ï¼‰

        Returns:
            Dict with:
                - version_number: æ–°ç‰ˆæœ¬å·
                - version_id: ç‰ˆæœ¬ID
                - score: è´¨é‡åˆ†æ•°
                - passed: æ˜¯å¦é€šè¿‡è¯„ä¼°
                - content: ç« èŠ‚å†…å®¹
                - evaluation: å®Œæ•´è¯„ä¼°ç»“æœ
                - retry_count: é‡è¯•æ¬¡æ•°
        """
        logger.info(f"ğŸ”„ å¼€å§‹é‡å†™ç¬¬ {chapter_index} ç« ")

        # 1. è·å–ç« èŠ‚ä»»åŠ¡
        tasks = await self.storage.get_task_results(
            self.session_id,
            chapter_index=chapter_index,
        )

        if not tasks:
            raise ValueError(f"Chapter {chapter_index} not found in session {self.session_id}")

        task = tasks[0]
        task_id = task["task_id"]

        # 2. è·å–ä¼šè¯ä¿¡æ¯
        session = await self.storage.get_session(self.session_id)
        if not session:
            raise ValueError(f"Session {self.session_id} not found")

        goal = session.get("goal", {})

        # 3. è·å–ç°æœ‰ç‰ˆæœ¬æ•°
        versions = await self.storage.get_chapter_versions(self.session_id, chapter_index)
        next_version = len(versions) + 1

        # 4. è·å–ä¸Šä¸‹æ–‡
        context = await self.memory.get_context(
            task_id=task_id,
            task_type="ç« èŠ‚å†…å®¹",
            chapter_index=chapter_index,
            recent_count=10,  # è·å–å‰10ç« 
        )

        # 5. é‡å†™å¾ªç¯ï¼ˆæœ€å¤š max_retries æ¬¡é‡è¯•ï¼‰
        best_content = None
        best_evaluation = None
        best_score = 0.0
        passed = False
        retry_count = 0

        for attempt in range(max_retries):
            retry_count = attempt

            # æ„å»ºé‡å†™æç¤ºè¯
            prompt = await self._build_rewrite_prompt(
                chapter_index=chapter_index,
                context=context,
                old_content=task["result"],
                reason=reason,
                feedback=feedback,
                attempt=attempt,
                previous_evaluation=best_evaluation,
            )

            # è°ƒç”¨ LLM ç”Ÿæˆæ–°å†…å®¹
            response = await self.llm_client.generate(
                task_type="ç« èŠ‚å†…å®¹",
                prompt=prompt,
            )

            # è¯„ä¼°æ–°å†…å®¹
            evaluation = await self.evaluator.evaluate(
                content=response.content,
                task_type="ç« èŠ‚å†…å®¹",
                context=context,
                goal=goal,
            )

            # è®°å½•åˆ†æ•°
            score = evaluation.score
            logger.info(f"ğŸ“Š ç¬¬ {chapter_index} ç« é‡å†™ (å°è¯• {attempt + 1}/{max_retries}) å¾—åˆ†: {score:.2f}")

            # ä¿å­˜è¿™ä¸ªç‰ˆæœ¬
            token_stats = {
                "total_tokens": response.usage.get("total_tokens", 0) if response.usage else 0,
                "prompt_tokens": response.usage.get("prompt_tokens", 0) if response.usage else 0,
                "completion_tokens": response.usage.get("completion_tokens", 0) if response.usage else 0,
                "cost": response.usage.get("cost_usd", 0.0) if response.usage else 0.0,
            }

            version_id = await self.storage.create_chapter_version(
                session_id=self.session_id,
                task_id=task_id,
                chapter_index=chapter_index,
                content=response.content,
                version_number=next_version + attempt,
                is_current=evaluation.passed,  # å¦‚æœé€šè¿‡åˆ™è®¾ä¸ºå½“å‰ç‰ˆæœ¬
                evaluation=evaluation.to_dict(),
                created_by="manual" if attempt == 0 else "rewrite",
                rewrite_reason=reason or feedback or "ç”¨æˆ·æ‰‹åŠ¨é‡å†™",
                token_stats=token_stats,
            )

            # æ›´æ–°æœ€ä½³ç‰ˆæœ¬
            if score > best_score:
                best_content = response.content
                best_evaluation = evaluation
                best_score = score

                # å¦‚æœè¿™æ˜¯æ›´å¥½çš„ç‰ˆæœ¬ï¼Œæ ‡è®°ä¸ºå½“å‰
                await self.storage.restore_chapter_version(
                    session_id=self.session_id,
                    task_id=task_id,
                    version_id=version_id,
                )

            # å¦‚æœé€šè¿‡è¯„ä¼°ï¼Œç»“æŸé‡å†™
            if evaluation.passed:
                passed = True
                logger.info(f"âœ… ç¬¬ {chapter_index} ç« é‡å†™é€šè¿‡è¯„ä¼° (åˆ†æ•°: {score:.2f})")
                break

            logger.warning(f"âš ï¸ ç¬¬ {chapter_index} ç« é‡å†™æœªé€šè¿‡è¯„ä¼° (åˆ†æ•°: {score:.2f})")

        # å¦‚æœéƒ½ä¸é€šè¿‡ï¼Œä¿ç•™æœ€åä¸€æ¬¡
        if not passed:
            logger.warning(f"âŒ ç¬¬ {chapter_index} ç« ç»è¿‡ {max_retries} æ¬¡é‡å†™ä»æœªé€šè¿‡è¯„ä¼°")

        # æ›´æ–°ç‰ˆæœ¬è®¡æ•°
        await self.storage.update_task_version_count(
            task_id=task_id,
            version_count=next_version + retry_count,
        )

        return {
            "version_number": next_version + retry_count,
            "version_id": version_id,
            "score": best_score,
            "passed": passed,
            "content": best_content,
            "evaluation": best_evaluation.to_dict() if best_evaluation else None,
            "retry_count": retry_count,
        }

    async def _build_rewrite_prompt(
        self,
        chapter_index: int,
        context: MemoryContext,
        old_content: str,
        reason: Optional[str],
        feedback: Optional[str],
        attempt: int = 0,
        previous_evaluation: Optional[Any] = None,
    ) -> str:
        """
        æ„å»ºé‡å†™æç¤ºè¯

        Args:
            chapter_index: ç« èŠ‚ç´¢å¼•
            context: è®°å¿†ä¸Šä¸‹æ–‡
            old_content: åŸæœ‰å†…å®¹
            reason: é‡å†™åŸå› 
            feedback: ç”¨æˆ·åé¦ˆ
            attempt: å½“å‰å°è¯•æ¬¡æ•°
            previous_evaluation: ä¹‹å‰çš„è¯„ä¼°ç»“æœ

        Returns:
            å®Œæ•´çš„é‡å†™æç¤ºè¯
        """
        # è·å– session goal
        session = await self.storage.get_session(self.session_id)
        goal = session.get("goal", {})

        prompt_parts = [
            f"# ä»»åŠ¡ï¼šé‡å†™ç¬¬ {chapter_index} ç« \n",
        ]

        # æ·»åŠ åˆ›ä½œç›®æ ‡
        if goal:
            prompt_parts.append("## åˆ›ä½œç›®æ ‡\n")
            if goal.get("genre"):
                prompt_parts.append(f"- ç±»å‹ï¼š{goal['genre']}")
            if goal.get("theme"):
                prompt_parts.append(f"- ä¸»é¢˜ï¼š{goal['theme']}")
            if goal.get("style"):
                prompt_parts.append(f"- é£æ ¼ï¼š{goal['style']}")
            prompt_parts.append("")

        # æ·»åŠ åŸæœ‰å†…å®¹
        prompt_parts.extend([
            "## åŸæœ‰å†…å®¹\n",
            old_content[:2000] + "..." if len(old_content) > 2000 else old_content,
            "\n",
        ])

        # æ·»åŠ é‡å†™åŸå› 
        if reason:
            prompt_parts.extend([
                "## é‡å†™åŸå› \n",
                reason,
                "\n",
            ])

        # æ·»åŠ ç”¨æˆ·åé¦ˆ
        if feedback:
            prompt_parts.extend([
                "## ç”¨æˆ·åé¦ˆ\n",
                feedback,
                "\n",
            ])

        # æ·»åŠ ä¹‹å‰çš„è¯„ä¼°é—®é¢˜
        if previous_evaluation and attempt > 0:
            prompt_parts.extend([
                "## ä¸Šæ¬¡è¯„ä¼°é—®é¢˜\n",
                f"å¾—åˆ†ï¼š{previous_evaluation.score:.2f}\n",
            ])
            if previous_evaluation.issues:
                prompt_parts.append("é—®é¢˜ï¼š\n")
                for issue in previous_evaluation.issues:
                    prompt_parts.append(f"- {issue}\n")
            prompt_parts.append("\n")

        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        prompt_parts.extend([
            "## ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
            "è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯é‡å†™ç« èŠ‚ï¼š\n",
        ])

        # æ·»åŠ å‰ç½®ä»»åŠ¡ç»“æœ
        if context.predecessor_results:
            prompt_parts.append("\n### å‰ç½®ä»»åŠ¡ç»“æœ\n")
            for task_type, result in list(context.predecessor_results.items())[:5]:
                prompt_parts.append(f"**{task_type}**:\n")
                content = result.get("content", "")[:500]
                prompt_parts.append(content + "...\n" if len(result.get("content", "")) > 500 else content + "\n")

        # æ·»åŠ ç›¸å…³è®°å¿†
        if context.related_memories:
            prompt_parts.append("\n### ç›¸å…³è®°å¿†\n")
            for memory in context.related_memories[:5]:
                prompt_parts.append(f"- {memory.item.content[:200]}...\n")

        prompt_parts.extend([
            "\n## è¦æ±‚\n",
            "1. ä¿æŒä¸åŸæœ‰å†…å®¹çš„åŸºæœ¬æƒ…èŠ‚ä¸€è‡´\n",
            "2. æ ¹æ®é‡å†™åŸå› å’Œç”¨æˆ·åé¦ˆè¿›è¡Œæ”¹è¿›\n",
            "3. ç¡®ä¿ä¸å‰ç½®ç« èŠ‚çš„å†…å®¹è¡”æ¥è‡ªç„¶\n",
            "4. ä¿æŒäººç‰©æ€§æ ¼å’Œä¸–ç•Œè§‚è§„åˆ™çš„ä¸€è‡´æ€§\n",
            "5. æå‡æ–‡ç¬”å’Œæå†™è´¨é‡\n",
            "\nè¯·é‡å†™ç¬¬ {} ç« ï¼š\n".format(chapter_index)
        ])

        return "\n".join(prompt_parts)
