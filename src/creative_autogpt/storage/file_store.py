"""
File Store - Manages file-based content storage

Handles export of novels to various formats (TXT, DOCX, PDF, etc.)
"""

import json
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger

from creative_autogpt.utils.config import get_settings


class ExportFormat(str, Enum):
    """Supported export formats"""

    TXT = "txt"
    JSON = "json"
    MARKDOWN = "md"


class FileStore:
    """
    File-based storage for novel exports

    Manages:
    - Export to various formats
    - Chapter file organization
    - Backup management
    """

    def __init__(self, base_path: Optional[str] = None):
        """
        Initialize file store

        Args:
            base_path: Base directory for storage
        """
        settings = get_settings()
        self.base_path = Path(base_path or settings.local_storage_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"FileStore initialized at {self.base_path}")

    def _get_session_path(self, session_id: str) -> Path:
        """Get path for a session"""
        session_path = self.base_path / session_id
        session_path.mkdir(parents=True, exist_ok=True)
        return session_path

    async def save_chapter(
        self,
        session_id: str,
        chapter_index: int,
        content: str,
        title: Optional[str] = None,
    ) -> Path:
        """
        Save a chapter to a file

        Args:
            session_id: The session ID
            chapter_index: Chapter index
            content: Chapter content
            title: Optional chapter title

        Returns:
            Path to saved file
        """
        session_path = self._get_session_path(session_id)

        if title:
            filename = f"{chapter_index:03d}_{title}.txt"
        else:
            filename = f"{chapter_index:03d}.txt"

        file_path = session_path / "chapters" / filename
        file_path.parent.mkdir(parents=True, exist_ok=True)

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)

        logger.debug(f"Saved chapter {chapter_index} to {file_path}")
        return file_path

    async def save_full_novel(
        self,
        session_id: str,
        title: str,
        chapters: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """
        Save complete novel as a single file

        Args:
            session_id: The session ID
            title: Novel title
            chapters: List of chapter data
            metadata: Optional metadata

        Returns:
            Path to saved file
        """
        session_path = self._get_session_path(session_id)
        file_path = session_path / f"{title}.txt"

        with open(file_path, "w", encoding="utf-8") as f:
            # Title page
            f.write(f"{title}\n")
            f.write("=" * len(title) + "\n\n")

            if metadata:
                f.write(f"ä½œè€…: {metadata.get('author', 'æœªçŸ¥')}\n")
                f.write(f"ç±»åž‹: {metadata.get('genre', 'æœªçŸ¥')}\n")
                f.write(f"åˆ›å»ºæ—¶é—´: {metadata.get('created_at', 'æœªçŸ¥')}\n")
                f.write("\n" + "-" * 50 + "\n\n")

            # Chapters
            for chapter in chapters:
                chapter_index = chapter.get("chapter_index", 0)
                chapter_title = chapter.get("title", f"ç¬¬{chapter_index}ç« ")
                content = chapter.get("content", "")

                f.write(f"\n{chapter_title}\n")
                f.write("\n")
                f.write(content)
                f.write("\n\n")

        logger.info(f"Saved full novel to {file_path}")
        return file_path

    async def export_to_json(
        self,
        session_id: str,
        title: str,
        data: Dict[str, Any],
    ) -> Path:
        """
        Export session data as JSON

        Args:
            session_id: The session ID
            title: Novel title
            data: Session data to export

        Returns:
            Path to exported file
        """
        session_path = self._get_session_path(session_id)
        file_path = session_path / f"{title}.json"

        export_data = {
            "title": title,
            "exported_at": datetime.utcnow().isoformat(),
            **data,
        }

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)

        logger.info(f"Exported to JSON: {file_path}")
        return file_path

    async def export_to_markdown(
        self,
        session_id: str,
        title: str,
        chapters: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """
        Export novel as Markdown

        Args:
            session_id: The session ID
            title: Novel title
            chapters: List of chapter data
            metadata: Optional metadata

        Returns:
            Path to exported file
        """
        session_path = self._get_session_path(session_id)
        file_path = session_path / f"{title}.md"

        with open(file_path, "w", encoding="utf-8") as f:
            # Title
            f.write(f"# {title}\n\n")

            if metadata:
                f.write("## å…ƒä¿¡æ¯\n\n")
                if metadata.get("author"):
                    f.write(f"- **ä½œè€…**: {metadata['author']}\n")
                if metadata.get("genre"):
                    f.write(f"- **ç±»åž‹**: {metadata['genre']}\n")
                if metadata.get("description"):
                    f.write(f"- **ç®€ä»‹**: {metadata['description']}\n")
                f.write("\n---\n\n")

            # Chapters
            for chapter in chapters:
                chapter_index = chapter.get("chapter_index", 0)
                chapter_title = chapter.get("title", f"ç¬¬{chapter_index}ç« ")
                content = chapter.get("content", "")

                f.write(f"\n## {chapter_title}\n\n")
                f.write(content)
                f.write("\n\n")

        logger.info(f"Exported to Markdown: {file_path}")
        return file_path

    async def export_full_creative_process(
        self,
        session_id: str,
        title: str,
        tasks: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Path:
        """
        å¯¼å‡ºå®Œæ•´çš„åˆ›ä½œè¿‡ç¨‹ï¼ŒåŒ…å«æ‰€æœ‰ä»»åŠ¡çš„è¾“å‡º

        æ ¼å¼ï¼š
        - åˆ›æ„è„‘æš´
        - å¤§çº²
        - äººç‰©è®¾è®¡
        - ä¸–ç•Œè§‚è§„åˆ™
        - ä¸»é¢˜ç¡®è®¤
        - é£Žæ ¼å…ƒç´ 
        - å¸‚åœºå®šä½
        - äº‹ä»¶è®¾å®š
        - åœºæ™¯ç‰©å“å†²çª
        - ä¼ç¬”åˆ—è¡¨
        - ç« èŠ‚å¤§çº² + ç« èŠ‚å†…å®¹ (æ¯ç« )

        Args:
            session_id: ä¼šè¯ID
            title: å°è¯´æ ‡é¢˜
            tasks: æ‰€æœ‰ä»»åŠ¡ç»“æžœåˆ—è¡¨
            metadata: å…ƒæ•°æ®

        Returns:
            å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        """
        session_path = self._get_session_path(session_id)
        timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S")
        file_path = session_path / f"{title}_å®Œæ•´åˆ›ä½œ_{timestamp}.md"
        
        # å®šä¹‰ä»»åŠ¡ç±»åž‹çš„é¡ºåºå’Œæ ‡é¢˜
        task_order = [
            ("åˆ›æ„è„‘æš´", "# ðŸŽ¯ åˆ›æ„è„‘æš´"),
            ("å¤§çº²", "# ðŸ“‹ æ•…äº‹å¤§çº²"),
            ("äººç‰©è®¾è®¡", "# ðŸ‘¥ äººç‰©è®¾è®¡"),
            ("ä¸–ç•Œè§‚è§„åˆ™", "# ðŸŒ ä¸–ç•Œè§‚è§„åˆ™"),
            ("ä¸»é¢˜ç¡®è®¤", "# ðŸŽ­ ä¸»é¢˜ç¡®è®¤"),
            ("é£Žæ ¼å…ƒç´ ", "# âœ¨ é£Žæ ¼å…ƒç´ "),
            ("å¸‚åœºå®šä½", "# ðŸ“Š å¸‚åœºå®šä½"),
            ("äº‹ä»¶", "# âš¡ äº‹ä»¶è®¾å®š"),
            ("åœºæ™¯ç‰©å“å†²çª", "# ðŸŽ¬ åœºæ™¯ç‰©å“å†²çª"),
            ("ä¼ç¬”åˆ—è¡¨", "# ðŸ”® ä¼ç¬”åˆ—è¡¨"),
            ("ä¸€è‡´æ€§æ£€æŸ¥", "# âœ… ä¸€è‡´æ€§æ£€æŸ¥"),
        ]
        
        # æŒ‰ä»»åŠ¡ç±»åž‹æ•´ç†ç»“æžœ
        task_results = {}
        chapter_outlines = {}  # ç« èŠ‚å¤§çº²
        chapter_contents = {}  # ç« èŠ‚å†…å®¹
        
        for task in tasks:
            task_type = task.get("task_type", "")
            result = task.get("result", "")
            chapter_index = task.get("chapter_index")
            
            if task_type == "ç« èŠ‚å¤§çº²" and chapter_index is not None:
                chapter_outlines[chapter_index] = result
            elif task_type in ("ç« èŠ‚å†…å®¹", "ç« èŠ‚æ¶¦è‰²") and chapter_index is not None:
                # å¦‚æžœå·²æœ‰å†…å®¹ä¸”æ˜¯æ¶¦è‰²åŽçš„ï¼Œç”¨æ¶¦è‰²åŽçš„æ›¿æ¢
                if task_type == "ç« èŠ‚æ¶¦è‰²" or chapter_index not in chapter_contents:
                    chapter_contents[chapter_index] = result
            elif task_type not in ("ç« èŠ‚å¤§çº²", "ç« èŠ‚å†…å®¹", "ç« èŠ‚æ¶¦è‰²", "åœºæ™¯ç”Ÿæˆ"):
                if task_type not in task_results:
                    task_results[task_type] = result
        
        with open(file_path, "w", encoding="utf-8") as f:
            # æ ‡é¢˜é¡µ
            f.write(f"# ðŸ“š {title}\n\n")
            f.write(f"**å¯¼å‡ºæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            
            if metadata:
                f.write("## ðŸ“ åŸºæœ¬ä¿¡æ¯\n\n")
                if metadata.get("genre"):
                    f.write(f"- **ç±»åž‹**: {metadata['genre']}\n")
                if metadata.get("theme"):
                    f.write(f"- **ä¸»é¢˜**: {metadata['theme']}\n")
                if metadata.get("style"):
                    f.write(f"- **é£Žæ ¼**: {metadata['style']}\n")
                if metadata.get("length"):
                    f.write(f"- **ç›®æ ‡å­—æ•°**: {metadata['length']}\n")
                f.write("\n---\n\n")
            
            # æŒ‰é¡ºåºè¾“å‡ºå‡†å¤‡é˜¶æ®µçš„ä»»åŠ¡ç»“æžœ
            f.write("# ç¬¬ä¸€éƒ¨åˆ†ï¼šåˆ›ä½œå‡†å¤‡\n\n")
            f.write("> ä»¥ä¸‹æ˜¯å°è¯´åˆ›ä½œçš„å‡†å¤‡å·¥ä½œï¼ŒåŒ…å«åˆ›æ„è„‘æš´ã€äººç‰©è®¾è®¡ã€ä¸–ç•Œè§‚æž„å»ºç­‰å†…å®¹ã€‚\n\n")
            
            for task_type, section_title in task_order:
                if task_type in task_results and task_results[task_type]:
                    f.write(f"{section_title}\n\n")
                    f.write(task_results[task_type])
                    f.write("\n\n---\n\n")
            
            # è¾“å‡ºç« èŠ‚å†…å®¹
            if chapter_contents:
                f.write("# ç¬¬äºŒéƒ¨åˆ†ï¼šæ­£æ–‡å†…å®¹\n\n")
                f.write("> ä»¥ä¸‹æ˜¯å°è¯´çš„æ­£æ–‡ç« èŠ‚ã€‚\n\n")
                
                # æŒ‰ç« èŠ‚é¡ºåºæŽ’åº
                sorted_chapters = sorted(chapter_contents.keys())
                
                for chapter_index in sorted_chapters:
                    # ç« èŠ‚å¤§çº²ï¼ˆå¯é€‰ï¼‰
                    if chapter_index in chapter_outlines:
                        f.write(f"## ç¬¬{chapter_index}ç«  å¤§çº²\n\n")
                        f.write("```\n")
                        f.write(chapter_outlines[chapter_index])
                        f.write("\n```\n\n")
                    
                    # ç« èŠ‚å†…å®¹
                    f.write(f"## ç¬¬{chapter_index}ç« \n\n")
                    f.write(chapter_contents[chapter_index])
                    f.write("\n\n---\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            f.write("# ðŸ“Š ç»Ÿè®¡ä¿¡æ¯\n\n")
            total_words = sum(len(content) for content in chapter_contents.values())
            f.write(f"- **æ€»ç« èŠ‚æ•°**: {len(chapter_contents)}\n")
            f.write(f"- **æ­£æ–‡æ€»å­—æ•°**: çº¦{total_words}å­—\n")
            f.write(f"- **ä»»åŠ¡æ€»æ•°**: {len(tasks)}\n")
        
        logger.info(f"Exported full creative process to: {file_path}")
        return file_path

    async def load_chapter(
        self,
        session_id: str,
        chapter_index: int,
    ) -> Optional[str]:
        """
        Load a chapter from file

        Args:
            session_id: The session ID
            chapter_index: Chapter index

        Returns:
            Chapter content or None
        """
        session_path = self._get_session_path(session_id)
        chapter_dir = session_path / "chapters"

        # Try to find the chapter file
        for pattern in [f"{chapter_index:03d}.txt", f"{chapter_index:03d}_*.txt"]:
            matches = list(chapter_dir.glob(pattern))
            if matches:
                with open(matches[0], "r", encoding="utf-8") as f:
                    return f.read()

        return None

    async def list_sessions(self) -> List[str]:
        """
        List all session directories

        Returns:
            List of session IDs
        """
        return [d.name for d in self.base_path.iterdir() if d.is_dir()]

    async def delete_session_files(self, session_id: str) -> bool:
        """
        Delete all files for a session

        Args:
            session_id: The session ID

        Returns:
            True if successful
        """
        session_path = self._get_session_path(session_id)

        try:
            # Remove all contents
            for item in session_path.iterdir():
                if item.is_file():
                    item.unlink()
                elif item.is_dir():
                    for sub_item in item.iterdir():
                        sub_item.unlink()
                    item.rmdir()

            # Remove directory
            session_path.rmdir()

            logger.info(f"Deleted files for session {session_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to delete session files: {e}")
            return False

    async def get_session_size(self, session_id: str) -> int:
        """
        Get total size of session files in bytes

        Args:
            session_id: The session ID

        Returns:
            Size in bytes
        """
        session_path = self._get_session_path(session_id)

        if not session_path.exists():
            return 0

        total_size = 0
        for item in session_path.rglob("*"):
            if item.is_file():
                total_size += item.stat().st_size

        return total_size
